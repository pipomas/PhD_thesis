% !TeX spellcheck = de_DE
% ===================================================================================
% P R E A M B E L 
% ===================================================================================
% Basic document settings -----------------------------------------------------------
\documentclass[11pt, twoside, a4paper]{book}		% option draft for no images and overfull hbox markers
\linespread{1.3}\selectfont							% use one and a half line spaces
%\renewcommand{\familydefault}{\sfdefault}			% sets file in sans serif
%\setlength{\marginparwidth}{0pt}					% removes margin notes area O_o
%\setlength{\parskip}{1.5ex plus 0.5ex minus 0.2ex}	% https://en.wikibooks.org/wiki/LaTeX/Page_Layout#Widows_and_orphans
\AtBeginDocument{\setlength{\parindent}{2em}}		% parindent 2 em units for new paragraph
%\usepackage{indentfirst}							% use if first paragraph should be indented
\usepackage[pass]{geometry}							% ’pass’ disregards the package layout, so the original ’book’ layout is memorized here
\usepackage{layout}									% show layout on page 1
%\usepackage{showframe}								% show frame on pages
%\usepackage{url}									% loaded internally by hyperref
%\usepackage{booktabs}								% Nicely formatted tables
%\usepackage{topcapt}								% Be able to put captions above tables 
%\usepackage{chngpage}								% Be able to change margins on the fly for big tables
%\usepackage{longtable}								% For tables that go over sereral pages
\usepackage[utf8]{inputenc}							% this is needed for umlauts
\usepackage[T1]{fontenc}							% this is needed for correct output of umlauts in pdf
\usepackage[ngerman, showlanguages]{babel}			% set document language to new german
\usepackage[german=swiss]{csquotes}					% enquote{} makes quoting in swiss german easy
\usepackage{pdflscape}								% https://en.wikibooks.org/wiki/LaTeX/Page_Layout#cite_ref-4
\usepackage{longtable}								% a multi-page environment for tabular
\usepackage{listings}								% for R code snippets
\usepackage{graphicx}								% needed for graphics
\renewcommand{\textfraction}	{.001}				% minimum fraction text per side
\renewcommand{\topfraction}		{.999}				% fraction of float on top page
\renewcommand{\bottomfraction}	{.999}				% fraction of float on bottum page
\usepackage[hang, bottom]{footmisc}					% footnotes are indented and always on bottom of the page
\setlength{\footnotesep}{.9\baselineskip}			% controls spacing between multiple footnotes
\usepackage{cancel}									% for \cancel{expression} 
\usepackage{pifont}									% for "itemize" symbols (dinglist environment)
\usepackage{color}									% \textcolor{color}{text} for coloring text
\usepackage{todonotes}								% for todo notes
\usepackage{pdfpages}								% simplifies the insertion of external multi-page PDF

% Mathpackages ---------------------------------------------------------------------
\usepackage{mathtools}								% handy tools for mathematical typesetting
\usepackage{amsmath}								% miscellaneous enhancements for mathematical formulas
\usepackage{amsfonts}								% - for certain mathematical fonts
\usepackage{amssymb}								% - for certain mathematical symbols
\usepackage{fixltx2e} 								% needed when $ and $ are used in section titles
\usepackage{array}    								% für >{}, d.h. fügt den Inhalt vor jeder Zelle ein. oder >{$}c{$}< 
\usepackage[Euler]{upgreek}							% for non-italic greek letters

% Setup for fancyhdr package -------------------------------------------------------
\usepackage{fancyhdr}								% customize the page layout of  LaTeX documents
\pagestyle{fancy}									% select pagestyle
%\renewcommand{\sectionmark}[1]{\markright{\thesection}}	% renew the sectionmark command
%\renewcommand{\chaptermark}[1]{\markboth{#1}{#1}}			% <- works as single line
\renewcommand{\chaptermark}[1]{\markboth{\small\textsc{#1}}{}}
\renewcommand{\sectionmark}[1]{\markright{\small\textsc{#1}}{}}
\fancyhf{}  										% delete current header and footer
\fancyhead[LE,RO]{\thepage}							% ...
\fancyhead[LO]{\normalfont\nouppercase{\rightmark}}	% ... tiefer als leftmark
\fancyhead[RE]{\normalfont\nouppercase{\leftmark}} 	% ... höher als rightmark
\renewcommand{\headrulewidth}{.1pt}					% set head rule width
\renewcommand{\footrulewidth}{0pt}					% set foot rule width
\addtolength{\headheight}{0.5pt} 					% space between header and page

% pagestyle for plain pages (chapters, titles etc.)
\fancypagestyle{plain}{%							
   \fancyfoot[C]{\thepage}							% show page number centered
   \fancyhead{}										% get rid of headers on plain pages
   \renewcommand{\headrulewidth}{0pt}				% and the line
}
\usepackage{emptypage}								% removes headers from plain pages


% Check this style, found on http://tex.stackexchange.com/questions/132469/showcase-of-nice-looking-headers
%\pagestyle{fancy}
%\fancyhead{}
%
%\renewcommand{\chaptermark}[1]{\markboth{\small\textsc{#1}}{}}
%\renewcommand{\sectionmark}[1]{\markright{\small\textsc{#1}}{}}
%\fancyhead[LE]{\rightmark}
%\fancyhead[RO]{\leftmark}

% Backup code in case setup doesn't work anymore ------------------------------
%\usepackage{emptypage}  % removes headers of empty pages

%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
%\renewcommand{\sectionmark}[1]{%
%        \markright{\thesection\ #1}}
%\fancyhf{}  % delete current header and footer
%\fancyhead[LE,RO]{\thepage}
%\fancyhead[LO]{\normalfont\nouppercase{\rightmark}}
%\fancyhead[RE]{\normalfont\nouppercase{\leftmark}}
%\renewcommand{\headrulewidth}{0.5pt}
%\renewcommand{\footrulewidth}{0pt}
%\addtolength{\headheight}{0.5pt} % space for the rule
%\fancypagestyle{plain}{%
%   \fancyfoot[C]{\thepage}
%   \fancyhead{} % get rid of headers on plain pages
%   \renewcommand{\headrulewidth}{0pt} % and the line
%}

% setup for tables--------------------------------------------------------------
\usepackage{rotating}								% performs most sorts of rotation floating figures and tables
\usepackage{threeparttable}							% this package facilitates tables with titles (captions) and notes.
\usepackage{adjustbox}								% this package allows to adjust general (LA)TEX material
\usepackage{multirow}								% for \multirow command in tabular environment

% Make landscape mode rotate properly in a twosided book -----------------------
% see http://stackoverflow.com/questions/4982219/how-to-make-landscape-mode-rotate-properly-in-a-twoside-book/5320962
\makeatletter	
\global\let\orig@begin@landscape=\landscape%
\global\let\orig@end@landscape=\endlandscape%
\gdef\@true{1}
\gdef\@false{0}
\gdef\landscape{%
    \global\let\within@landscape=\@true%
    \orig@begin@landscape%
}%
\gdef\endlandscape{%
    \orig@end@landscape%
    \global\let\within@landscape=\@false%
}%
\@ifpackageloaded{pdflscape}{%
    \gdef\pdf@landscape@rotate{\PLS@Rotate}%
}{
    \gdef\pdf@landscape@rotate#1{}%
}
\let\latex@outputpage\@outputpage
\def\@outputpage{
    \ifx\within@landscape\@true%
        \if@twoside%
            \ifodd\c@page%
                \gdef\LS@rot{\setbox\@outputbox\vbox{%
                    \pdf@landscape@rotate{-90}%
                    \hbox{\rotatebox{90}{\hbox{\rotatebox{180}{\box\@outputbox}}}}}%
                }%
            \else%
                \gdef\LS@rot{\setbox\@outputbox\vbox{%
                    \pdf@landscape@rotate{+90}%
                    \hbox{\rotatebox{90}{\hbox{\rotatebox{0}{\box\@outputbox}}}}}%
                }%
            \fi%
        \else%
            \gdef\LS@rot{\setbox\@outputbox\vbox{%
                \pdf@landscape@rotate{+90}%
                \hbox{\rotatebox{90}{\hbox{\rotatebox{0}{\box\@outputbox}}}}}%
            }%
        \fi%
    \fi%
    \latex@outputpage%
}
\makeatother

% Setup for figures ------------------------------------------------------------
\usepackage{tikz}					% load package
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,positioning,fit,petri} % load options
\tikzstyle{every picture}+=[font=\sffamily]			% use sans serif font for tikz pictures -> http://tex.stackexchange.com/questions/4887/pgf-tikz-and-sans-serif-fonts
\usepackage[lofdepth=1]{subfig}															% for subfigures. Loads caption package internally. 
\usepackage[singlelinecheck = off,labelsep = period]{caption} 							% -> caption is aligned with table
\captionsetup[subfigure]{labelformat=simple, labelsep = period, listofformat=subsimple} % (a) -> a.
\captionsetup[figure]{labelfont=it, labelsep = period}									% italic labelfont in figures
\captionsetup[table]{labelsep = none}													% no . after table label
\usepackage[leftcaption]{sidecap}	% for side caption: outercaption, innercaption, leftcaption, rightcaption
\usepackage[section]{placeins}		% http://tex.stackexchange.com/questions/35125/how-to-use-the-placement-options-t-h-with-figures
\usepackage{float}					% for better floating of floats

% Setup for figures and tables -------------------------------------------------
\usepackage{chngcntr}							% package for avoiding the counter reset per chapter when using figs and tbls
\counterwithout{figure}{chapter}				% -> does it for figures
\counterwithout{table}{chapter}					% -> does it for tables
\counterwithout{footnote}{chapter}				% -> does it for tables
%\numberwithin{equation}{section}				% equations start with 1.1 1.2, 2.1 2.2 etc.
%\numberwithin{figure}{section} 				% the same with figures
\usepackage{siunitx}							% for decimal aligned columns in tables
\setlength{\abovecaptionskip}{3pt plus 3pt minus 2pt}	% modifiy vertical space between figure and caption
\setcounter{lofdepth}{2}			% include minicaptions in LOF (list of figures)

% Removes "Chapter X" string in chapters ---------------------------------------
\makeatletter
\def\@makechapterhead#1{%
  \vspace*{50\p@}%
  {\parindent \z@ \raggedright \normalfont
    \interlinepenalty\@M
    \Huge\bfseries  \thechapter\quad #1\par\nobreak
    \vskip 40\p@
  }}
\makeatother

% Removes spacing in list of figures and tables -------------------------------
% see http://tex.stackexchange.com/questions/69321/spacing-between-chapters-in-list-of-tables
\makeatletter
\def\@chapter[#1]#2{\ifnum \c@secnumdepth >\m@ne
	\if@mainmatter
	\refstepcounter{chapter}%
	\typeout{\@chapapp\space\thechapter.}%
	\addcontentsline{toc}{chapter}%
	{\protect\numberline{\thechapter}#1}%
	\else
	\addcontentsline{toc}{chapter}{#1}%
	\fi
	\else
	\addcontentsline{toc}{chapter}{#1}%
	\fi
	\chaptermark{#1}%
	%                    \addtocontents{lof}{\protect\addvspace{10\p@}}% NEW
	%                    \addtocontents{lot}{\protect\addvspace{10\p@}}% NEW
	\if@twocolumn
	\@topnewpage[\@makechapterhead{#2}]%
	\else
	\@makechapterhead{#2}%
	\@afterheading
	\fi}
\makeatother

% Setup for bibliography with the 'apacite' package ----------------------------
\usepackage[tocbib, natbibapa, nosectionbib]{apacite}	% enable options
%\newcommand\citepos[1]{\citeauthor{#1}s\ (\citeyear{#1})} % see http://tex.stackexchange.com/questions/137511/how-to-put-a-s-after-citing-author
\bibliographystyle{apacite-mod}							% see apacite-mod in directory http://tex.stackexchange.com/questions/304217/reference-list-suppressing-dots-after-company-names-apacite
%\bibliographystyle{apacite}
\usepackage{doi}										% turns doi's into hyperlinks
\renewcommand\doiprefix{\ignorespaces}					% removes white space in front of doi
\AtBeginDocument{\urlstyle{APACsame}}					% removes monospaced font in url's
\AtBeginDocument{\renewcommand{\BRetrievedFrom}{Verfügbar unter\ }} % replaces  "Zugriff auf" with "Verfügbar unter

% Allow URL breaks after all letters
\AtBeginDocument{\renewcommand{\UrlBreaks}{\do\/\do\a\do\b\do\c\do\d\do\e\do\f\do\g\do\h\do\i\do\j\do\k\do\l\do\m\do\n\do\o\do\p\do\q\do\r\do\s\do\t\do\u\do\v\do\w\do\x\do\y\do\z\do\A\do\B\do\C\do\D\do\E\do\F\do\G\do\H\do\I\do\J\do\K\do\L\do\M\do\N\do\O\do\P\do\Q\do\R\do\S\do\T\do\U\do\V\do\W\do\X\do\Y\do\Z}}


% Correction in bilbiography: Removal of whitespace between volume and issue (APA vs DGPs) ------------
%\makeatletter                                    % removes white space between vol and issue		---
%\AtBeginDocument{%                               % uncomment for apa format  						---
%  \renewcommand{\APACjournalVolNumPages}[4]{%    % with ngerman, apacite switches to DGP rules...	---
%    \Bem{#1}%             journal																	---
%    \ifx\@empty#2\@empty																			---
%    \else																							---
%      \unskip, \Bem{#2}%  volume																	---
%    \fi																							---
%    \ifx\@empty#3\@empty																			---
%    \else																							---
%      \unskip({#3})%      issue number																---
%    \fi																							---
%    \ifx\@empty#4\@empty																			---
%    \else																							---
%      \unskip, {#4}%      pages																	---
%    \fi																							---
%  }																								---
%}																									---
%\makeatother																						---

% Setup for hyperref -----------------------------------------------------------
\usepackage{hyperref}		% load package
\hypersetup{colorlinks,		% define options
			citecolor=blue,
			filecolor=black,
			linkcolor=black,
			urlcolor=blue,
			pdfauthor={Philipp Thomas},
			pdfsubject={Dissertation},
			pdftitle={Der Zusammenhang zwischen Spatial-Suppression, Mental-Speed und psychometrischer Intelligenz},
			pdfkeywords={psychometric intelligence, spatial suppression, mental speed, hick task, R, LaTeX}
			}
			
%\usepackage[all]{hypcap}	% http://tex.stackexchange.com/questions/77816/hyperref-not-jumping-to-the-appropriate-location

%\usepackage{cleveref}		% see http://tex.stackexchange.com/questions/62611/how-to-make-ref-references-include-the-word-figure	

% Setup for glossaries (must be placed AFTER the hyperref setup) ---------------------------
\usepackage[xindy, toc, automake, acronym, shortcuts]{glossaries}		% load options (what is 'xindy' for?)
\makeglossary							% to generate the glossary

% Glossary entries --------------------------------------------------------
% Glossaries -------------------------------
\newglossaryentry{zft}
{	name=Zwei-Fak\-to\-ren-Theo\-rie,
	description={Test}}

\newglossaryentry{ssans}
{	name=Spa\-tial-Sup\-pres\-sion-An\-satz,
	description={is}}

\newglossaryentry{ssauf}
{	name=Spa\-tial-Sup\-pres\-sion-Auf\-gabe,
	description=}

\newglossaryentry{ss}
{	name=Spa\-tial-Sup\-pres\-sion,
	description=}

\newglossaryentry{si}
{	name=Sup\-pres\-sion-In\-dex,
	description=}

\newglossaryentry{ms}
{	name=Men\-tal-Speed,
	description=}

\newglossaryentry{msa}
{name=Men\-tal-Speed-An\-satz,
	description=is}

\newglossaryentry{msm}
{name=Men\-tal-Speed-Mass,
	plural=Men\-tal-Speed-Mas\-se,
	description=is}

\newglossaryentry{zua}
{	name=Zen\-trum-Um\-feld-Ant\-ago\-nis\-mus,
	description=}

\newglossaryentry{flm}
{	name=Fixed-Links-Mo\-dell,
	plural=Fixed-Links-Mo\-del\-le,
	description=}

\newglossaryentry{ha}
{	name=Hick-Auf\-ga\-be,
	description=}

\newglossaryentry{ip}
{	name=Im\-pu\-ri\-ty-Pro\-blem,
	description=}

\newglossaryentry{ita}
{	name=In\-spec\-tion-Time-Auf\-ga\-be,
	description=}

\newglossaryentry{gfaktor}
{	name= \textit{g}-Fak\-tor,
	description=}

\newglossaryentry{zwert}
{	name= \textit{z}-Wert,
	description=}

%\newglossaryentry{tst}
%{	name=Three-Stratum-Theorie,
%	description=}
%
%\newglossaryentry{}
%{	name=,
%	description=}

% Acronyms -------------------------------
\newacronym{tst}{TS-Theorie}{Three-Stratum-Theorie}

\newacronym{Gf}{Gf}{flu\-ide Intelligenz}
\newacronym{Gc}{Gc}{kristalline Intelligenz}
\newacronym{Gy}{Gy}{allgemeines Gedächtnis und Lernen}
\newacronym{Gv}{Gv}{allgemeine visuelle Wahrnehmung}
\newacronym{Gu}{Gu}{allgemeine akustische Wahrnehmung}
\newacronym{Gr}{Gr}{allgemeine Zugriffsfähigkeit}
\newacronym{Gs}{Gs}{allgemeine kognitive Geschwindigkeit}
\newacronym{Gt}{Gt}{Verarbeitungsgeschwindigkeit}








\newacronym{chct}{CHC-Theorie}{Cattell-Horn-Carroll-Theorie}






%\newacronym{ect}{EKA}{elementaren kognitiven Aufgabe}
\newacronym[
plural=ECTs,
longplural={},
]
{ect}{ECT}{\textit{elementary cognitive task}}


\newacronym[
	plural=Vpn,
	firstplural={Versuchspersonen (Vpn)},
	longplural={Versuchspersonen},
%	\glsshortpluralkey=Vpn,	
	]
	{vp}{Vp}{Versuchsperson}

\newacronym[
	plural=RZn,
	longplural={Reaktionszeiten}]
	{rz}{RZ}{Reaktionszeit}

\newacronym{mta}{MT-Areal}{me\-dio\-tem\-po\-ral\-en Areal}


\newacronym{bist}{BIS-Test}{Berliner Intelligenzstruktur-Test}
\newacronym{bism}{BIS}{Berliner Intelligenzstrukturmodell}

\newacronym{ai}{AI}{Allgemeine Intelligenz}

\newacronym{k}{K}{Verarbeitungskapazität}
\newacronym{b}{B}{Bearbeitungsgeschwindigkeit}
\newacronym{M}{M}{Merkfähigkeit}
\newacronym{e}{E}{Einfallsreichtum}

\newacronym{v}		{V}				{sprach\-ge\-bund\-enes Denken}
\newacronym{n}		{N}				{zahl\-enge\-bund\-enes Denken}
\newacronym{f}		{F}				{an\-schau\-ungs\-ge\-bun\-denes, fi\-gural-bildhaftes Denken}

\newacronym{bd}		{BD}			{Buchstaben-Durchstreichen}
\newacronym{kw}		{KW}			{Klassifizieren von Wörtern}
\newacronym{oe}		{OE}			{Old English}
\newacronym{RZ}		{RZ}			{Rechen-Zeichen}
\newacronym{tg}		{TG}			{Teil-Ganzes}
\newacronym{uw}		{UW}			{Unvollständige Wörter}
\newacronym{xg}		{XG}			{X-Grösser}

\newacronym{soa}	{SOA}			{Stim\-u\-lus-On\-set-Asyn\-chrony}

%\newacronym{kfa}	{KFA}			{Konfirmatorischer Faktorenanalyse}
\newacronym{cst}	{$\upchi^2$-Test}{Chi-Qua\-drat-Test}
\newacronym{cfi}	{CFI}			{Com\-par\-a\-tive-Fit-In\-dex}
\newacronym{rmsea}	{RMSEA}			{Root-Mean-Square-Er\-ror-of-Ap\-prox\-i\-ma\-tion}
\newacronym{rmse}	{\textit{RMSE}}	{Root-Mean-Square-Er\-ror}
\newacronym{srmr}	{SRMR}			{Stan\-dard\-ized-Root-Mean-Square-Resid\-u\-al}

\newacronym{m}		{\textit{M}}	{Mittelwert}
\newacronym{sd}		{\textit{SD}}	{Standardabweichung}
\newacronym{sds}	{\textit{SDs}}	{Standardabweichungen}

\newacronym{epq-rk}	{EPQ-RK}		{Eysenck-Per\-son\-al\-i\-ty-Ques\-tion\-naire}
\newacronym{dii}	{DII}			{Dickman-Im\-pul\-si\-vi\-ty-In\-ven\-tory}


%\usepackage[pagewise]{lineno}		% line numbering for reviewing
%\linenumbers						% do it :)



\raggedbottom			% o_o http://tex.stackexchange.com/questions/36423/random-unwanted-space-between-paragraphs ?
%\widowpenalty=300		% avoid single lines (values 0-1000)
%\clubpenalty=300		% avoid single lines (values 0-1000)

%\usepackage[all]{nowidow}

%\usepackage[nottoc]{tocbibind}


% Hyphenation patterns for Swiss German words -------------------------------
\hyphenation{%
	Ab-schlies-send
	ab-schlies-send
	Ant-wort-al-ter-na-ti-ve
	Ant-wort-al-ter-na-ti-ven
	auf-ga-ben-re-le-van-te
	auf-ga-ben-re-le-van-ter
	auf-ga-ben-re-le-van-ten
	Aus-mass
	aus-schlie-s-s-lich
	Aus-ser-dem
	aus-ser-halb
	au-s-ser-or-dent-lich
	be-kan-nter-mas-sen
	Bi-fak-t-o-ri-el-le
	bi-fak-t-o-ri-el-len
	Dif-fe-renz-mass
	Dif-fe-renz-mas-ses
	Dis-kri-mi-na-ti-ons-fä-hig-keit
	Ef-fekt-stär-ke
	Ef-fekt-stärk-en
	er-war-tungs-ge-mäss
	Fak-to-ren-ana-ly-se
	Fak-to-ren-ana-ly-sen
	fak-to-ren-ana-ly-tisch
	fak-to-ren-ana-ly-tisch-en
	Fak-tor-la-dung
	Fak-tor-la-dung-en
	Fak-tor-wer-te
	Fak-tor-wer-ten
	flie-sst
	ganz-heit-lich-er-en
	ganz-heit-lich-er-es
	ge-mäss
	gross
	gros-se
	gros-sen
	gros-sem
	grös-se-re
	grös-ste
	grös-sten
	Haupt-kom-po-nen-ten-ana-ly-se
	heis-st
	in-fe-renz-sta-tis-ti-sch
	in-fe-renz-sta-tis-ti-scher
	in-ter-in-di-vi-du-el-le
	kon-fun-diert
	Kon-fun-die-rung
	kon-ge-ne-rische
	Kri-te-ri-ums-va-li-di-tät
	liess
	lies-sen
	lo-ga-rith-mie-rten
	man-i-fold
	Mass
	mas-s-geb-lich
	Mas-s-nah-me
	Merk-mals-aus-prä-gung
	Merk-mals-aus-prä-gung-en
	Merk-mals-ver-tei-lung
	Me-ta-ana-ly-se
	Mit-tel-wert-un-ter-schied
	Mo-del-lie-rungs-tech-nik
	Mus-ter-grös-se
	Mus-ter-grös-sen
	mut-mas-sli-che
	mut-mas-sli-chen
	My-el-in-is-ier-ung
	Os-zil-la-ti-ons-ra-te
	Os-zil-la-ti-ons-theo-rie
	per-zep-tu-ell
	pos-i-tive
	Prä-dik-tor
	Prä-dik-tor-en
	psy-cho-me-trische
	psy-cho-me-trisch-er
	psy-cho-me-trisch-en
	re-ak-ti-ons-zeit-ba-siert-en
	re-li-a-bel
	Se-mi-par-ti-al-kor-re-la-ti-on
	Se-mi-par-ti-al-kor-re-la-ti-on-en
	stich-pro-ben-ab-hän-gig
	Struk-tur-glei-chungs-mo-dell
	Struk-tur-glei-chungs-mo-del-le
	Sub-trak-ti-ons-me-tho-de
	test-spe-zi-fische
	un-stan-dar-di-siert-en
	va-li-de
	va-li-de-re
	va-li-de-ren
	ver-hält-nis-mäs-sig
	ver-tei-lungs-freie
	Ver-un-rei-ni-gungs-pro-blem
	zu-liess
}


% ==========================================================================================
% ==========================================================================================
% ==========================================================================================
%
% B E G I N   D O C U M E N T 
%
% ==========================================================================================
% ==========================================================================================
% ==========================================================================================

\begin{document}
%\layout							% prints layout page at the beginning of the document
\frontmatter						% triggers roman numerals 

% =================================================================
% T I T L E   P A G E
% =================================================================
% Declare new goemetry for the title and copyright page only ------
\newgeometry{top=2in,bottom=2in,right=1.5in,left=1.5in}

\begin{titlepage}

	\centering
		\huge Der Zusammenhang zwischen Spatial-Suppression, Mental-Speed und psychometrischer Intelligenz 
	
	\noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}
	
	\vspace{1.2cm}
	
	\centering{
		\Large \textit{Inauguraldissertation}
		
		\vspace{1cm}
		
		der Philosophisch-humanwissenschaftlichen Fakultät der Universität Bern zur Erlangung der Doktorwürde
		
		\vspace{1cm}
		
		vorgelegt von\\
		Philipp Thomas\\
		aus St. Gallen
		
		\vspace{1cm}

		\Large Bern, Januar 2017
	}

		\vspace*{\fill}
		\small
	\flushleft Originaldokument gespeichert auf dem Webserver der Universitätsbibliothek Bern.

	\vspace{.2cm}
	\centering{\includegraphics[width=.3\textwidth]{png/CC_licence}}
	\vspace{0cm}

	\RaggedRight Dieses Werk ist unter einem Creative Commons Namensnennung - Keine kommerzielle Nutzung - Keine Bearbeitung 2.5 Schweiz Lizenzvertrag lizenziert. Um die Lizenz anzusehen, gehen Sie bitte zu \url{http://creativecommons.org/licenses/by-nc-nd/2.5/ch} oder schicken Sie einen Brief an Creative Commons, 171 Second Street, Suite 300, San Francisco, California 94105, USA.

% =================================================================
% C O P Y R I G H T   P A G E
% =================================================================
	\clearpage
	\pagestyle{empty}
	\mbox{}
	\clearpage
	\pagestyle{empty}
	\centering
	
	\textbf{Urheberrechtlicher Hinweis}

	\hspace{1cm}

	Dieses Dokument steht unter einer Lizenz der Creative Commons Namensnennung - Keine kommerzielle Nutzung - Keine Bearbeitung 2.5 Schweiz.\\ \url{http://creativecommons.org/licenses/by-nc-nd/2.5/ch}
	
	\hspace{1cm}

	\RaggedRight Sie dürfen dieses Werk zu den folgenden Bedingungen vervielfältigen, verbreiten und öffentlich zugänglich machen:

	\begin{table}[h]
		\centering
		\small
		\begin{tabular}{c m{.7\textwidth}}
%			\hline
			\raisebox{-.47\height} 	{\includegraphics[width=.1\textwidth]{png/CC_by_me}}
			&
			\textbf{Namensnennung}. Sie müssen den Namen des Autors/Rechteinhabers in der von ihm festgelegten Weise nennen (wodurch aber nicht der Eindruck entstehen darf, Sie oder die Nutzung des Werkes durch Sie würden entlohnt). \\
%			\hline
			\rule{0pt}{9ex}%  EXTRA vertical height
			\raisebox{-.5\height} {\includegraphics[width=.1\textwidth]{png/CC_nc_me}}
			&
			\textbf{Keine kommerzielle Nutzung}. Dieses Werk darf nicht für kommerzielle Zwecke verwendet werden. \\
%			\hline
			\rule{0pt}{9ex}%  EXTRA vertical height
			\raisebox{-.5\height} {\includegraphics[width=.1\textwidth]{png/CC_nd_me}}
			&
			\textbf{Keine Bearbeitung}. Dieses Werk darf nicht bearbeitet oder in anderer Weise verändert werden. \\
%			\hline
		\end{tabular}
	\end{table}
	
	\RaggedRight Im Falle einer Verbreitung müssen Sie anderen die Lizenzbedingungen, unter welche dieses Werk fällt, mitteilen. Jede der vorgenannten Bedingungen kann aufgehoben werden, sofern Sie die Einwilligung des Rechteinhabers dazu erhalten. Diese Lizenz lässt die Urheberpersönlichkeitsrechte nach Schweizer Recht unberührt. 
	
	\hspace{1cm}
	
	Eine ausführliche Fassung des Lizenzvertrags befindet sich unter \url{http://creativecommons.org/licenses/by-nc-nd/2.5/ch/legalcode.de}.

\end{titlepage}
% Ends the declared geometry for the titlepage
\restoregeometry





% =================================================================
% A C K N O W L E D G M E N T S
% =================================================================
\clearpage
\chapter*{\LARGE Danksagung}
%\addcontentsline{toc}{chapter}{Danksagung}
\vspace{-.7cm}
Diese Arbeit stellt das Produkt meiner dreijährigen Forschungstätigkeit dar. Mein Dank gilt allen Personen, die mit ihrer Unterstützung zum Erfolg dieser Arbeit beigetragen haben.

Namentlich möchte ich mich bei Herr \mbox{Prof. Dr. Stefan Troche} bedanken, der mich während der ganzen Arbeit eng betreut hat und mir mit zahlreichen Tipps und Hinweisen das Schreiben dieser Arbeit erleichtert hat.

\mbox{Prof. Dr. Thomas Rammsayer} möchte ich dafür danken, dass er mir jederzeit als Ansprechperson zur Verfügung stand und mit hilfreichen Anregungen und Vorschlägen zum Gelingen dieser Arbeit beigetragen hat.

\mbox{Prof. Dr. Duje Tadin} gilt mein Dank, weil er mich mit grossem Engagement dabei unterstützt hat, die \gls{ssauf} an der Universität Bern einzurichten und sich immer die Zeit nahm, meine Fragen zur Aufgabe zu beantworten. 

Nicht zuletzt möchte ich mich bei all jenen Personen aus meinem privaten Umfeld bedanken, die mich während dieser Zeit liebevoll unterstützt haben.
%\citep{Upper1974} 




\vspace{5 mm}

\begin{quote}
Philipp Thomas\\
\today
\end{quote}


% =================================================================
% S U M M A R Y
% =================================================================
\chapter*{Zusammenfassung \label{cha:Zusammenfassung}}
\addcontentsline{toc}{chapter}{Zusammenfassung}
\noindent
DGP Richtlinien weisen auf folgende Punkte hin:
\begin{itemize}
	\item \textit{Vollständigkeit}
	\item \textit{Genauigkeit}
	\item \textit{Objektivität}
	\item \textit{Kürze}
	\item \textit{Verständlichkeit}
	\item Trotz Kürze sollte über die zu prüfenden psychologischen Hypothesen, die Methode, die Ergebnisse
	und die Interpretation informiert werden
\end{itemize}

\noindent Generelle Hinweise:
\begin{itemize}
	\item Fragestellung und die zu prüfenden Hypothesen sollten dargestellt werden
	\item Zentrale Merkmale der Teilnehmer sollen angegeben werden (Anzahl, Alter, Geschlecht)
	\item Die experimentelle Methode inklusive verwendeter Apparaturen und Formen der Datenerhebung
	\item Zentrale Befunde angeben
	\item Schlussfolgerung aus den Befunden inklusive deren Bedeutung für die psychologische Hypothese
\end{itemize}
\pagebreak

% =================================================================
% T A B L E   O F   C O N T E N T S
% =================================================================
\renewcommand{\contentsname}{Inhalte}			% define name of toc
\setcounter{tocdepth}{3}						% set toc depth
\tableofcontents								% insert toc
%\addcontentsline{toc}{chapter}{Inhalte}		% add toc to toc? :D




\mainmatter				% page numbers in arabic
% =================================================================
% I N T R O D U C T I O N
% =================================================================
\chapter{Einleitung \label{cha:Einleitung}}

\section{Konzept der allgemeinen Intelligenz}

Die Annahme eines Generalfaktors der Intelligenz, kurz \gls{gfaktor} genannt, stellt eine der einflussreichsten Ideen in der Psychologie dar. \citet{Spearman1904, Spearman1927} machte mit seinen Untersuchungen zu Beginn des zwanzigsten Jahrhunderts die Entdeckung, dass zwischen Tests zur Erfassung kognitiver Leistung positive Zusammenhänge bestanden. Diesen sogenannten \textit{positive manifold} erklärte \citeauthor{Spearman1927} mit dem \gls{gfaktor} seiner \gls{zft}. Gemäss der \gls{zft} setzt sich eine kognitive Leistung aus zwei unabhängigen Anteilen zusammen: dem \gls{gfaktor}, der alle Bereiche intellektueller Fähigkeit beeinflusst, und einem spezifischen Faktor ($s$), der das Spezifische einer kognitiven Leistung repräsentiert und keiner anderen kognitiven Leistung gemeinsam ist. Weil die verschiedenen spezifischen Faktoren gemäss der \gls{zft} ebenfalls unabhängig voneinander sind, kann der positive manifold zwischen verschiedenen Tests folglich nur aufgrund des \gls{gfaktor}s zustande kommen.
Individuelle Differenzen in der allgemeinen Fähigkeit, kognitive Leistung zu erbringen, sind somit auf individuelle Unterschiede auf dem \gls{gfaktor} zurückzuführen.
%Individuelle Unterschiede auf diesem \gls{gfaktor} können somit als Ausdruck individueller Differenzen in der allgemeinen Fähigkeit angesehen werden, kognitive Leistung zu erbringen.

Es folgte eine jahrzehntelange Auseinandersetzung unter Forschern, ob der \gls{gfaktor}, wie ihn \citeauthor{Spearman1927} annahm, existiert oder nicht. So sah zum Beispiel \citet{Thurstone1938} den \gls{gfaktor} vielmehr als die Folge von mehreren, relativ unabhängigen mentalen Fähigkeiten. 
Andere Modelle wie das von \citet{Vernon1950}, das von \citet{Cattell1971} oder das von \citet{Jaeger1984} postulierten eine hierarchische Struktur mit spezifischen Fähigkeiten auf tieferer Ebene und dem \gls{gfaktor} auf höchster Ebene. 
Die Vielzahl an unterschiedlichen Auffassungen und Modellen von Intelligenz veranlasste \citet{Carroll1993} dazu, eine umfassende, meta\-ana\-ly\-tisch begründete Taxonomie der menschlichen kognitiven Fähigkeiten zu entwickeln. Er reanalysierte dafür nahezu alle Datensätze, die für die Entwicklung früherer Modelle verwendet wurden und versuchte ein Modell zu finden, das den Daten am besten entsprach. Seine Ergebnisse formulierte \citeauthor{Carroll1993} in der \gls{tst}.
Das faktorenanalytisch bestimmte Modell unterscheidet zwischen drei Ebenen kognitiver Fähigkeiten, die in der \gls{tst} als Schichten bezeichnet werden. Die erste Schicht beinhaltet $69$ spezifische kognitive Fähigkeiten. Diese $69$ spezifischen Fähigkeiten können in der zweiten Schicht acht übergeordneten Faktoren zugewiesen werden: \gls{Gf}, \gls{Gc}, \gls{Gy}, \gls{Gv}, \gls{Gu}, \gls{Gr}, \gls{Gs} und \gls{Gt}.
Auf höchster Hierarchiestufe lässt sich der \gls{gfaktor} wiederfinden, welcher aus der dritten Schicht alle kognitiven Fähigkeiten beeinflusst.
\citeauthor{Carroll1993} stellte mit der \gls{tst} eine wichtige Integration bestehender Modelle dar. 
Sie vereint viele der bis dahin postulierten Modellstrukturen und Differenzierungsgrade, mit der Intelligenz betrachtet werden kann, namentlich die Idee des \gls{gfaktor}s \citep{Spearman1904, Spearman1927}, die mehreren Faktoren von \citet{Thurstone1938}, \gls{Gf} und \gls{Gc} aus dem Modell von \citet{Cattell1971} und den hierarchischen Aufbau wie er zum Beispiel in den Modellen von \citet{Vernon1950} oder \citet{Jaeger1984} zu finden ist \citep[für eine Erweiterung der \gls{tst} siehe][]{McGrew2005, McGrew2009}.

Alternative Theorien, welche die positiven Zusammenhänge zwischen verschiedenen Tests zur Erfassung von kognitiver Leistung nicht mit dem \gls{gfaktor} erklären, sind selten. 
So geht zum Beispiel das Bond-Modell \citep{Thomson1916} davon aus, dass das Bearbeiten einer kognitiven Aufgabe spezifische Module (kognitive Prozesse, sogenannte \textit{bonds}) benötigt, die unkorreliert sind. Werden die Module während der Erfassung kognitiver Fähigkeiten mit unterschiedlichen Tests aktiviert, kann es vorkommen, dass ein Modul von mehreren Tests beansprucht wird. Ein Modul fliesst folglich in die Leistung mehrerer Tests ein, was schlussendlich zu positiven Korrelationen zwischen verschiedenen Tests führen kann. Unter dieser Betrachtungsweise stellt der \gls{gfaktor} somit ein Artefakt dar, das auf die unzureichende Messgüte von kognitiven Tests zurückzuführen ist \citep[für eine Gegenüberstellung zwischen dem \gls{gfaktor} und dem Bond-Modell siehe][]{Bartholomew2013}.
Die Mutualism-theory-of-\textit{g} \citep{VanDerMaas2006} erklärt die positiven Zusammenhänge zwischen kognitiven Tests auf eine andere Weise. Die Theorie geht davon aus, dass kognitive Prozesse zu Beginn ihrer Entwicklung unabhängig sind. Mit zunehmender Ausbildung der kognitiven Prozesse entwickeln sich allerdings reziproke vorteilhafte Abhängigkeiten zwischen einzelnen Prozessen, womit sich positive Zusammenhänge zwischen kognitiven Tests ebenso gut erklären lassen wie mit dem \gls{gfaktor}. \citet{Gignac2014, Gignac2016} zeigte mit seinen kürzlich erschienen Untersuchungen jedoch, dass der \gls{gfaktor} zum jetzigen Zeitpunkt die zu bevorzugende Erklärung für das Auftreten des positive manifold ist. \todo[color=green!40, fancyline]{wieso?}

Um den \gls{gfaktor} aus einer Korrelationsmatrix kognitiver Tests zu extrahieren, müssen zwei Bedingungen erfüllt sein \citep[][S. 73]{Jensen1998a}. Zum einen muss die Anzahl kognitiver Tests genügend gross sein, damit der extrahierte Faktor reliabel ist, und zum anderen muss eine genügend grosse Bandbreite unterschiedlicher Tests kognitiver Fähigkeiten verwendet werden. Der \gls{gfaktor} tritt dann unabhängig von der eingesetzten Testbatterie auf \citep{Johnson2004, Johnson2008}. Weiter haben Untersuchungen gezeigt, dass der \gls{gfaktor} von der eingesetzten faktorenanalytischen Methode (Hauptachsen- oder Hauptkomponentenanalyse) so gut wie nicht beeinflusst wird \citep{Jensen1994, Ree1991}.
Diese Robustheit des \gls{gfaktor}s gegenüber der eingesetzten Testbatterie und der verwendeten Analysemethode lässt sich gut mit der Annahme vereinen, dass der \gls{gfaktor} die allgemeine Fähigkeit widerspiegelt, kognitive Leistung zu erbringen \citep{Spearman1904, Spearman1927}.
%Der \gls{gfaktor} erfasst kognitive Leistungsfähigkeit folglich so generell, dass die verwendete Testbatterie respektive die eingesetzte faktorenanalytische Methode zu vernachlässigen sind.
%\todo[color=green!40, fancyline]{Jensen Weng 1994, Jensen 1998? g und Mittelwert sind fast dasselbe. psychometrische intelligenz ist das, was der Test erfasst. es gibt differenziertere Betrachtungsweisen, ich meine mit pi allgemeine intelligenz}

Mit zahlreichen Untersuchungen zur Kriteriumsvalidität des \gls{gfaktor}s wurde seine Bedeutsamkeit belegt. So konnten zum Beispiel zwischen dem \gls{gfaktor} und der Lernfähigkeit \citep{Christal1991}, der schulischen Leistung \citep{Jensen1998a} oder der beruflichen Leistung \citep{Schmidt2004} Zusammenhänge beobachtet werden. Aber auch mit generelleren Variablen wie der Gesundheit, dem Sozialverhalten, der Straffälligkeit, der Neigung zu Rassismus oder Alkoholismus konnten Zusammenhänge festgestellt werden \citep[für eine Übersicht siehe][]{Brand1987}. 
Neben diesen Beispielen für die praktische Bedeutsamkeit des Konzepts der allgemeinen Intelligenz kommt dem \gls{gfaktor} eine zentrale Rolle zu, wenn es um die Bestimmung der kognitiven Grundlagen für Intelligenzunterschiede geht (siehe \autoref{sec:Kognitive_Korrelate_von_Intelligenz}).
%\todo[color=green!40, fancyline]{g-Faktor, allgemeine Int., psychomoetrische Int? Definiert?}

Bis hierhin wurde ausschliesslich von der allgemeinen Intelligenz und deren Erfassung mittels dem \gls{gfaktor} gesprochen. Für den weiteren Verlauf der vorliegenden Arbeit ist es hilfreich zu definieren, wofür die beiden Begriffe stehen, in welchem Kontext sie verwendet werden und wie sie sich von verwandten Begriffen unterscheiden \citep[für eine ähnliche Begriffsverwendung siehe][]{Rabaglia2011}:
\textit{Intelligenz} oder \textit{allgemeine Intelligenz} bezieht sich in der vorliegenden Arbeit auf die globale Fähigkeit einer einzelnen Person, kognitive Leistung zu erbringen. Sie beschreibt ein hypothetisches Konstrukt, welches nicht direkt erfasst werden kann.
Der Begriff \textit{psychometrische Intelligenz} hingegen wird immer dann verwendet, wenn damit ein aus einem Intelligenztest abgeleiteter Testwert gemeint ist. Er kann sich sowohl auf einen (manifesten) IQ- beziehungweise Summenwert als auch auf den (latenten) \gls{gfaktor} beziehen \citep[die beiden Werte sind stark korreliert, siehe][S. 90]{Jensen1998a}.





\section{Kognitive Korrelate von Intelligenz \label{sec:Kognitive_Korrelate_von_Intelligenz}}

Auf kognitiver Ebene können Intelligenzunterschiede mit unterschiedlichen Ansätzen erklärt werden. Konstrukte wie sensorische Diskriminationsfähigkeit \citep[z. B.][]{Galton1883, Spearman1904, Deary2004, Meyer2010}, Zeitverarbeitung \citep[z. B.][]{Rammsayer2002}, Aufmerksamkeit \citep[z. B.][]{Schweizer2004} oder Arbeitsgedächtniskapazität \citep[für eine Metaanalyse siehe][]{Ackerman2005} hängen alle mit Intelligenz zusammen und können als kognitive Grundlagen für individuelle Unterschiede in kognitiver Leistung angesehen werden. 

%Einer der ältesten und einer der neusten Ansätze zur Erklärung individueller Intelligenzunterschiede stellen der Mental-Speed- respektive der \gls{ssans} dar.
Einer der ältesten Ansätze zur Erklärung individueller Intelligenzunterschiede stellt \gls{ms} dar, während \gls{ss} als einer der neusten Ansätze gilt. Diese zwei Ansätze stehen im Zentrum der vorliegenden Arbeit und werden in den folgenden Abschnitten besprochen.\todo[color=green!40, fancyline]{flüssig?}


\subsection{Der Mental-Speed-Ansatz \label{subsec:Der_Mental-Speed-Ansatz}}

Untersuchungen der letzten Jahrzehnte  haben gezeigt, dass Verarbeitungsgeschwindigkeit (\gls{ms}) und Intelligenz zusammenhängen \citep[für Übersichtsarbeiten siehe][]{Deary2000a, Jensen2006, Sheppard2008}. \gls{ms} wird dabei oft mit Hilfe einer sogenannten \gls{ect} erfasst.

Eine \gls{ect} (\citealp[S. 11]{Carroll1993}; \citealp[S. 203--209]{Jensen1998a}) ist eine Aufgabe, die Personen mit genügend Zeit ohne grosse mentale Anstrengung und Erfahrung fehlerfrei lösen können. Die Stimuli sind gross abgebildet und klar erkennbar, sodass sie von allen Personen mit normalem Sehvermögen gut wahrzunehmen sind. 
Bei einer reaktionszeitbasierten \gls{ect} werden Personen aufgefordert, so schnell wie möglich eine Antwort abzugeben und dabei Fehler zu vermeiden. 
Weil das Lösen der Aufgabe nur sehr simple mentale Prozesse beansprucht, sind individuelle Strategien, die das Lösen der Aufgabe erleichtern, nicht effektiv. Unterschiede in der Reaktionszeit zwischen Personen können nur durch die Geschwindigkeit verursacht werden, mit welcher die Personen die Aufgabe verarbeiten und auf Stimuli reagieren.
Beispiele für solche reaktionszeitbasierte\textcolor{red}{n?} \glspl{ect} sind
die Coincidence-Timing-Aufgabe \citep[bei welcher ein räumliches Zusammentreffen von zwei Stimuli so rasch als möglich erkannt werden muss;][]{Smith1987a}, 
die \gls{ha} \citep[zur Erfassung einfacher Reaktionszeit und der Reaktionszeit für eine Mehrfachauswahl;][]{Hick1952}, 
die Odd-Man-Out-Aufgabe \citep[zur Erfassung der Reaktionszeit für eine Mehrfachauswahl;][]{Frearson1986}, das Short-Term-Memory-Scan-Paradigma \citep[zur Erfassung der benötigten Zeit für einen Zugriff auf das Kurzzeitgedächtnis;][]{Sternberg1966, Sternberg1969}
oder die Posner-Aufgabe \citep[zur Erfassung der benötigten Zeit für einen Zugriff auf das Langzeitgedächtnis;][]{Posner1969}.

%\glspl{ect} erfassen die generelle Geschwindigkeit, mit der Information verarbeitet wird und weisen nicht nur mit  \citep{Neubauer1996}
%\begin{itemize}
%	\item geht es nicht auch darum, dass möglichst wenig motorik beteiligt ist?
%	\item resp. nur ein prozess beansprucht wird?
%	\item Geschwindigkeit für diese Prozesse wird ermittelt (beim namen nennen)
%	\item allgemeine geschwindigkeit (neubauer bucik, ceci arbeit) eher, nicht einzelne aspekte
%	\item wie stark hängen geschwindigkeit mit intelligenz zusammen? (neubauer, latent - hoch) sheppard vernon (gering)
%	\item jensen 1998? motorische aspekte sollten reduziert werden
%\end{itemize}


Eine der ältesten und am häufigsten benutzte \gls{ect} ist die \gls{ha} \citep{Hick1952}. Die \gls{ha} erfasst einfache Reaktionszeit und die Reaktionszeit für eine Mehrfachauswahl.
Personen sitzen dafür vor einem Computermonitor und müssen so rasch als möglich mit einem Tastendruck auf einer Tastatur entscheiden, an welcher Position ein Stimulus auf dem Monitor erschienen ist. Die Bedingungen der \gls{ha} unterscheiden sich dabei durch die möglichen Positionen, an welchen der Stimulus auftreten kann. 
In der simpelsten Bedingung (zur Erfassung einfacher Reaktionszeit) kann der Stimulus nur an einer Position auftreten und Personen müssen so schnell wie möglich die Antworttaste drücken, sobald der Stimulus auf dem Monitor erscheint.
In der zweiten, leicht komplexeren Bedingung (zur Erfassung der Reaktionszeit für eine Mehrfachauswahl) kann der Stimulus an zwei Positionen auftreten. Personen werden aufgefordert, beim Auftreten des Stimulus an einer der beiden Positionen so rasch als möglich die korrekte Antworttaste zu drücken.
Die Komplexität der Bedingung kann beliebig bestimmt werden, indem mögliche Antwortalternativen hinzugefügt oder weggelassen werden 
(für eine ausführliche Beschreibung der in der vorliegenden Arbeit verwendeten \gls{ha} siehe \autoref{sec:Hick}). 
Die Reaktionszeit in der \gls{ha} kann für jede Person mit der linearen Funktion \textit{Reaktionszeit}~$=a+b\log_{2}n$ beschrieben werden, wobei $a$ durch den y-Achsen\-ab\-schnitt, $b$ durch die Steigung der Regres\-sions\-geraden und $\log_{2}\,n$ durch den Logarithmus zur Basis 2 der Anzahl Antwortalternativen ($n$) bestimmt ist \citep[S. 105]{Jensen1987a}. Der Term $\log_{2}\,n$ wurde von \citet{Hick1952} als \textit{Bit} bezeichnet und entspricht derjenigen Menge an Information, welche die Entscheidung zwischen zwei gleich wahrscheinlichen Antwortalternativen ermöglicht\footnote{Entsprechend dieser Definition gab das Bit den Bedingungen der \gls{ha} ihre Namen: In der 0-bit-Bedingung steht eine Antwortalternative zur Verfügung ($\log_{2}\,1=0$), in der 1-bit-Bedingung zwei Antwortalternativen ($\log_{2}\,2=1$), in der 2-bit-Bedingung vier Antwortalternativen ($\log_{2}\,4=2$) und in der 2.58-bit-Bedingung stehen sechs Antwortalternativen zur Verfügung ($\log_{2}\,6=2.58$), usw.} \citep[siehe auch][S. 27]{Jensen2006}.
Gemäss der Erkenntnis von \citet{Hick1952} steigt die Reaktionszeit in der \gls{ha} folglich beim Hinzufügen von Antwortalternativen linear an, wenn die Anzahl Antwortalternativen in Bits ausgedrückt wird.


Für die Differentielle Psychologie wurde die \gls{ha} mit der Untersuchung von \citet{Roth1964} interessant. Er berichtete über einen Zusammenhang von $r=-.39$ zwischen der aus den Reaktionszeiten abgeleiteten Steigung ($b$) und psychometrischer Intelligenz. Intelligentere Personen zeigten demnach mit zunehmender Anzahl Ant\-wort\-alt\-er\-na\-ti\-ven einen weniger starken Anstieg ihrer Reaktionszeit als weniger intelligente Personen. 
Diese ersten Resultate legten die Vermutung nahe, dass mit Intelligenztests erfasste Unterschiede in komplexer kognitiver Leistung mitunter von der Geschwindigkeit abhängen, mit der Information verarbeitet wird.
Während \citeauthor{Roth1964} keinen Zusammenhang zwischen dem y-Ach\-sen\-ab\-schnitt ($a$) und psychometrischer Intelligenz festgestellte, haben spätere Untersuchungen dann gezeigt, dass auch der y-Ach\-sen\-ab\-schnitt negativ mit psychometrischer Intelligenz zusammenhängt \citep[z. B.][]{Jensen1982b, Jensen1987a, Neubauer1997a, Neubauer1997b}. Intelligentere Personen zeigten folglich kürzere einfache Reaktionszeiten als weniger intelligente Personen. Im Gegensatz zur Steigung, welche die Verarbeitungsgeschwindigkeit von Informationen abbildet \citep{Jensen1998b, Roth1964}, wird beim y-Ach\-sen\-ab\-schnitt angenommen, dass er ein Mass für die Zeitdauer ist, welche sensorische und motorische Prozesse benötigen, um den Reiz im Kortex wahrzunehmen und die Muskeln über efferente Nerven anzusteuern \citep{Jensen1998b}.

Neben dem negativen Zusammenhang zwischen diesen regressionsanalytisch abgeleiteten Aufgabenparametern und psychometrischer Intelligenz hängen sämtliche  Reaktionszeiten der \gls{ha} negativ mit psychometrischer Intelligenz zusammen \citep[$r=-.22$ bis $-.40$;][]{Sheppard2008}. Zusätzlich wurde beobachtet, dass der negative Zusammenhang zwischen der Reaktionszeit und psychometrischer Intelligenz stärker wird, je mehr Antwortalternativen zur Verfügung stehen \citep{Vernon1984}. Komplexere Bedingungen hängen demnach stärker mit Intelligenz zusammen als weniger komplexe Bedingungen und intelligentere Personen zeigen tendenziell kürzere Reaktionszeiten als weniger intelligente Personen \citep{Sheppard2008}.

Erklärt wurde der Zusammenhang zwischen \gls{ms} und Intelligenz unter anderem mit Eigenschaften des Kurz- und Arbeitsgedächtnisses \citep[z. B.][]{Jensen1982a, Jensen1982b, Jensen2006, Vernon1983}. 
Die Kapazität dieser beiden Speicher ist begrenzt und aufgenommene respektive zu verarbeitende Information zerfällt ohne Aktualisierung oder Überführung ins Langzeitgedächtnis \citep{Baddeley2009}. Je schneller nun ein kognitiver Prozess abläuft und daraus eine Aktion abgeleitet wird (sei das die Überführung der Information in das Langzeitgedächtnis oder eine Antwortabgabe), umso geringer ist die Wahrscheinlichkeit, dass die Kapazitätsgrenze der Speicher erreicht wird und Information verloren geht \citep{Jensen2006}.
Eine Person mit tiefem \gls{ms} stösst bei einer komplexen kognitiven Aufgabe (wie sie im Rahmen eines Intelligenztests vorgelegt wird) schneller an den Punkt, an welchem Information im Arbeitsgedächtnis verloren geht und neu aufgenommen werden muss \citep{Lehrl1988, Lehrl1990}. Umgekehrt hilft hoher \gls{ms} dabei, eine Aktion abzuleiten, bevor die Menge an Information die Kapazitätsgrenze erreicht respektive der Zerfall von Information einsetzt.

Andere Autoren erklären den Zusammenhang zwischen \gls{ms} und Intelligenz mit biologischen Bot\-tom-Up-Mech\-an\-is\-men. So gehen \citet{Bates1995}, \citet{Hendrickson1980} oder \citet{Reed1992} davon aus, dass intelligentere Personen Informationen neuronal effizienter verarbeiten. \citet{Miller1994} vermutet, dass die Myelinisierung der Neuronen die Ursache für den Zusammenhang ist, während \citet{Garlick2002} die höhere neuronale Plastizität von intelligenteren Personen für die Beziehung verantwortlich sieht. Ungeachtet dieser verschiedenen Erklärungsmöglichkeiten für den Zusammenhang zwischen \gls{ms} und Intelligenz kann festgehalten werden, dass zwischen der Geschwindigkeit, mit der Information verarbeitet wird, und komplexer kognitiver Leistung eine bedeutsame Verbindung besteht  \citep[sowohl auf manifester als auch auf latenter Ebene, siehe][]{Neubauer1996, Sheppard2008}.




\subsection{Der Spatial-Suppression-Ansatz \label{subsec:Der_Spatial-Suppression-Ansatz}}

%Der \gls{msa} wird nicht nur verwendet, um individuelle Intelligenzunterschiede direkt zu erklären. Er liefert auch eine Erklärungsgrundlage für den von \citet{Melnick2013} berichteten Zusammenhang zwischen \gls{ss} und psychometrischer Intelligenz.
%\footnote{Bei geringem Kontrast dreht sich dieser Effekt um: Für die Erkennung der horizontalen Bewegungsrichtung von kleinen Mustern wird mehr Zeit benötigt, als für die Erkennung der horizontalen Bewegungsrichtung von grossen Mustern. Dieses Phänomen wird Spatial-Summation genannt \citep{Kapadia1999, Levitt1997, Pack2005}}

Das Phänomen der \gls{ss} wurde von \citet{Tadin2003} unabhängig von  Intelligenz beschrieben. \citet{Tadin2003} untersuchten, mit welcher zeitlichen Dauer ein sich horizontal bewegendes Streifenmuster präsentiert werden muss, damit die Bewegungsrichtung des Musters korrekt wahrgenommen wird.
Sie haben dafür Personen vor einen Computermonitor gesetzt und ihnen für eine kurze Zeit im Millisekundenbereich (beispielsweise $100$~ms) ein rundes, vertikal gestreiftes Muster dargeboten. Die vertikalen Streifen des Musters bewegten sich im Zentrum ihres Sehfelds nach links oder nach rechts. Nach der Darbietungszeit konnte jede Person ohne Zeitdruck entscheiden, ob sich die Streifen nach links oder nach rechts bewegt haben. Bei einer korrekten Antwort verkürzte sich die Darbietungszeit und bei einer falschen Antwort erhöhte sich die Darbietungszeit des nächsten Musters. 
\citet{Tadin2003} haben unterschiedliche Mustergrössen verwendet und konnten so nach mehreren Durchgängen für jede Mustergrösse eine Erkennungsschwelle schätzen. Die Erkennungsschwelle widerspiegelt diejenige Zeit, mit der ein Muster präsentiert werden muss, damit die Person die Bewegungsrichtung des Musters (in $82\,\%$ der Durchgänge) korrekt erkennt (für eine ausführliche Beschreibung der Aufgabe siehe \autoref{sec:Die_Spatial-Suppression-Aufgabe}).
\citet{Tadin2003} haben mit Erstaunen festgestellt, dass die Bewegungsrichtung mit zunehmender Grösse des Streifenmusters schwieriger zu erkennen war. Für die Erkennung der horizontalen Bewegungsrichtung von kleinen Mustern wurde folglich weniger Zeit benötigt, als für die Erkennung der horizontalen Bewegungsrichtung von grossen Mustern. Dieses perzeptuelle Phänomen wurde von \citet{Tadin2003} \gls{ss} genannt. 

\citet{Tadin2003} erklärten ihre Beobachtung mit dem bewegungsbezogenen \gls{zua} von Neuronen im \gls{mta} des Okzipitallappens \citep{Allman1985a}. 
Der Okzipitallappen ist der hinterste Teil des Grosshirns und beinhaltet den visuellen Kortex, der die visuelle Wahrnehmung ermöglicht. 
Das \gls{mta} ist Teil des visuellen Kortex und ist auf die Verarbeitung von Bewegungsinformation spezialisiert. Es beinhaltet viele bewegungssensitive Neuronen, welche die Wahrnehmung von Bewegung ermöglichen \citep{Goldstein2015}.
Das Zentrum und das Umfeld eines bewegungssensitiven Neurons im \gls{mta} reagieren entgegengesetzt \citep{Allman1985a}: Fällt eine Bewegung auf das erregende Zentrum des Neurons, reagiert die Zelle mit einer erhöhten Feuerungsrate. Wird bei einer Bewegung auch das hemmende Umfeld des Neurons stimuliert, führt der \gls{zua} dazu, dass sich die Feuerungsrate des Neurons reduziert. Die Zelle reagiert folglich maximal bei einer Bewegung, die auf das Zentrum des rezeptiven Felds fällt und minimal, wenn die Bewegung das Umfeld des rezeptiven Felds stimuliert. Einen starken Hinweis für die Beteiligung des \gls{mta}s am Phänomen \gls{ss} lieferte einige Jahre später eine Untersuchung, die mit transkranieller Magnetstimulation Neuronen im \gls{mta} gehemmt hat \citep{Tadin2011}. Dabei hat sich eine direkte Abhängigkeit zwischen Bewegungswahrnehmungsleistung und Hemmung der Neuronen gezeigt. Die Hemmung der Neuronen mittels transkranieller Magnetstimulation führte verglichen mit der Kontrollbedingung zu einer besseren Erkennung der Bewegungsrichtung von grossen Streifenmustern,  weil der \gls{zua} bewegungssensitiver Neuronen gehemmt wurde \citep{Tadin2011}. Diese Resultate können als Beleg dafür gesehen werden, dass den Neuronen im \gls{mta} eine zentrale Funktion beim Phänomen der \gls{ss} zuzuschreiben ist.

Mit Intelligenz in Verbindung gebracht wurde \gls{ss} von \citet{Melnick2013}.
Das Ausmass an \gls{ss} wurde von \citeauthor{Melnick2013} mit dem \gls{si} quantifiziert, wobei dieser als Differenz zwischen der Erkennungsschwelle für grosse Muster und der Erkennungsschwelle für kleine Muster gebildet wurde. 

Eine stark ausgeprägte \gls{ss} ist somit mit einem hohen \gls{si} verbunden, welcher für eine starke Verschlechterung der Wahrnehmungsleistung bei zunehmender Mustergrösse steht \citep{Melnick2013}.
\todo[color=green!40, fancyline]{gut so?}

%Ein grosser \gls{si} steht somit relativ betrachtet für eine starke Verschlechterung der Wahrnehmungsleistung bei zunehmender Mustergrösse \citep[das heisst einer stark ausgeprägten \gls{ss};][]{Tadin2006}. 

\citeauthor{Melnick2013} berichteten über stark\footnote{In der vorliegenden Arbeit werden Effektstärken von Zusammenhangsmassen inhaltlich gemäss Cohen (1988, S. 79--80) interpretiert, der bei $r~=~.10$ von einem schwachen, bei $r~=~.30$ von einem mittleren und bei $r~=~.50$ von einem starken Effekt sprach.}\textcolor{red}{e?} positive Zusammenhänge zwischen dem \gls{si} und psychometrischer Intelligenz (Studie 1 [$N=12$]: $r~=~.64$ und Studie 2 [$N=53$]: $r~=~.71$). Diese Korrelationen kamen durch zwei Effekte zustande. Zum einen benötigten intelligentere Personen weniger Zeit, um die Bewegungsrichtung eines kleinen Musters zu erkennen und zum anderen zeigten intelligentere Personen mit zunehmender Mustergrösse eine stärkere Verschlechterung ihrer Wahrnehmungsleistung. Keiner dieser beiden Effekte war in der Lage, den aufgetretenen Zusammenhang zwischen dem \gls{si} und psychometrischer Intelligenz alleine zu erklären. Sowohl die rasche Verarbeitung der Bewegungsrichtung von kleinen Mustern als auch die verminderte Fähigkeit, die Bewegungsrichtung von grossen Mustern zu erkennen, stellten wichtige Bestandteile des \gls{si} dar. 

Warum korrelierte der \gls{si} deutlich stärker \citep[Studie 1: $r~=~.64$ und Studie~2: $r~=~.71$;][]{Melnick2013} als herkömmliche \glspl{msm} \citep[$r~=~-.24$;][]{Sheppard2008} mit  psychometrischer Intelligenz? Diesen vergleichsweise starken Zusammenhang erklärten \citet{Melnick2013} mit den zwei Bestandteilen des \gls{si}, ($1$) der Geschwindigkeit der Verarbeitung kleiner Muster und ($2$) der Verschlechterung der Wahrnehmungsleistung bei zunehmender Mustergrösse. Die schnellere Verarbeitung von kleinen Mustern bei intelligenteren Personen lässt sich in Übereinstimmung mit dem \gls{msa} (siehe \autoref{subsec:Der_Mental-Speed-Ansatz}) erklären. Die stärkere Verschlechterung der Wahrnehmungsleistung bei intelligenteren Personen hingegen beherbergt einen Aspekt, der auf den ersten Blick kontraintuitiv erscheint: 
Warum sollten intelligentere Personen mit zunehmender Mustergrösse eine stärkere Wahrnehmungsverschlechterung erfahren als weniger intelligente Personen, wo sich doch die Wahrnehmungsleistung in der Regel mit zunehmender Stimulusgrösse verbessert \citep{Anderson1987, Henrie2001}? Die Antwort auf diese Frage liefern Untersuchungen, die an Primaten gezeigt haben, dass eine Bewegung, die auf das erregende Zentrum eines Neurons im \gls{mta} fällt, mit der Wahrnehmung von Objekten in Verbindung steht, während eine Bewegung, die auch das hemmende Umfeld des Neurons stimuliert, mit der Bewegung eines Hintergrunds assoziiert wird \citep{Born2000, Churan2008, Regan2000}. 
Ein stark ausgeprägter \gls{zua} hilft folglich dabei, Bewegung in bestimmte Bereiche oder Objekte zu trennen --\todo[color=green!40, fancyline]{komma?} das heisst, sie perzeptuell zu segmentieren \citep{Braddick1993}.
\citeauthor{Melnick2013} argumentieren, dass die schnelle Verarbeitung relevanter Information und Unterdrückung irrelevanter Information sowohl in der visuellen Wahrnehmung \citep[Trennung zwischen bewegtem Objekt und Hintergrund; siehe][]{Born2000, Churan2008} als auch bei der Erbringung komplexer kognitiver Leistung \citep[Aufmerksamkeitslenkung auf relevante Information und Unterdrückung von Interferenzen; siehe][]{Burgess2011, Engle1999, Zanto2009} vorteilhaft ist. 
Die schnelle Verarbeitung relevanter Information bei gleichzeitiger Unterdrückung irrelevanter Information sehen \citeauthor{Melnick2013} als eine für das Funktionieren des Menschen wichtige Fähigkeit an. Weil der \gls{si} genau diese Fähigkeit durch die Erfassung von \gls{ms} und der Ausbildung\todo[color=green!40, fancyline]{Ausmass?} des \gls{zua} quantifiziert, besteht gemäss \citeauthor{Melnick2013} zwischen dem \gls{si} und psychometrischer Intelligenz ein stärkerer Zusammenhang als zwischen herkömmlichen \glspl{msm}n und psychometrischer Intelligenz.





Der \gls{ssans} zur Erklärung individueller Intelligenzunterschiede \citep{Melnick2013} bietet eine interessante Erweiterungsmöglichtkeit, wenn es um die Bestimmung der kognitiven Grundlagen für Intelligenzunterschiede geht. Er weist aber auch einige Stellen auf, die anfechtbar oder klärungsbedürftig sind.
($1$) Der \gls{ssans} beruht auf einer einzigen Untersuchung, die mit kleinen Stichproben gearbeitet hat \citep[Studie 1: $N=12$ und Studie 2: $N=53$;][]{Melnick2013}. Es kann deshalb nicht ausgeschlossen werden, dass Stichprobenfehler die Zusammenhänge beeinflusst haben. Um \gls{ss} als Prädiktor von psychometrischer Intelligenz zu festigen, bedarf es einer Bestätigung der Resultate von \citet{Melnick2013} mit einer grossen Stichprobe.
($2$) Mit dem \gls{si} liegt eine Variable vor, die als Differenz zwischen zwei Erkennungsschwellen gebildet wurde \citep{Melnick2013, Tadin2006, Tadin2011}. Dabei wurde nicht berücksichtigt, dass Differenzmasse unter bestimmten, in empirischen Untersuchungen oft vorliegenden Bedingungen problematisch sind: Weist der Minuend  beziehungsweise der Subtrahend keine perfekte Reliabilität auf und hängen sie zusammen, reduziert sich die Reliabilität des Differenzmasses. Beträgt beispielsweise die Reliabilität des Minuends $r_{xx} = .80$, die Reliabilität des Subtrahends $r_{yy} = .80$ und die Korrelation von Minuend und Subtrahend $r_{xy} = .50$, reduziert sich die Reliabilität der Differenz auf $r_{DD} = .60$ \citep[][S. 145]{Murphy2005}. Wird der \gls{si} als Differenzmass gebildet, kann folglich nicht ausgeschlossen werden, dass ein verhältnismässig wenig reliables Mass vorliegt. Um valide Schlussfolgerungen über den Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz zu treffen, wäre ein alternatives Mass zur Quantifizierung von \gls{ss} (das nicht auf einer Differenz beruht) dem \gls{si} vorzuziehen.
($3$) Aufschlussreich wäre zudem eine Analyse des Zusammenhangs zwischen der \gls{ssauf} und psychometrischer Intelligenz auf latenter Ebene. \citeauthor{Melnick2013} haben bereits in ihrer Untersuchung darauf hingewiesen, dass eine Analyse zwischen Variablen auf latenter Ebene der Analyse auf manifester Ebene vorzuziehen ist, weil sie die der manifesten Korrelationen zugrunde liegende Beziehung zutage bringt. Damit wäre gleichzeitig die Problematik der Differenzbildung zur Ableitung des \gls{si} angegangen, was ebenfalls zu valideren Schlussfolgerungen beitragen kann.
($4$) Darüber hinaus lässt eine Analyse auf latenter Ebene zu, die an der Beobachtung von \citeauthor{Melnick2013} beteiligten kognitiven Prozesse mithilfe sogenannter \glspl{flm} \citep[z. B.][]{Schweizer2006a, Schweizer2006b, Schweizer2007, Schweizer2008, Schweizer2009a} auf statistischer Ebene voneinander zu trennen. Damit könnte sich ein besseres Verständnis darüber ergeben, welche Aspekte der \gls{ssauf} in welcher Weise mit psychometrischer Intelligenz zusammenhängen.
($5$) \citeauthor{Melnick2013} nahmen an, dass die \gls{ssauf} auch \gls{ms} erfasst. Um diese Annahme zu prüfen, muss der Zusammenhang zwischen der \gls{ssauf}
und psychometrischer Intelligenz im Sinne eines nomologischen Netzwerks \citep{Cronbach1955} um \gls{ms} erweitert werden. 
%Damit kann die Frage beantwortet werden, ob der \gls{ssans} einen Aspekt der menschlichen Informationsverarbeitung erfasst, der neuartig ist und nicht bereits vom \gls{msa} erklärt wird.
%\todo[color=green!40, fancyline]{Ein teil des zusammenhangs über ms erklären lassen?}
Damit kann die Frage beantwortet werden, ob der \gls{ssans} zur Aufklärung individueller Intelligenzunterschiede neuartige Erklärungsmöglichkeiten bietet oder ob der \gls{msa} den Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz vollständig zu erklären vermag.

Die unter Punkt vier angesprochenen \glspl{flm} \citep[z. B.][]{Schweizer2006a, Schweizer2006b, Schweizer2007, Schweizer2008, Schweizer2009a} nehmen in der vorliegenden Arbeit eine wichtige Rolle ein. Die Modellierungstechnik, deren Zweck und deren zugrundeliegende Logik werden deshalb im nächsten Abschnitt ausführlich erklärt.


\section{Messung kognitiver Prozesse}

\subsection{Ausgangslage}

Die Messung kognitiver Prozesse ist anspruchsvoller als sie auf den ersten Blick erscheint. Wenn im Rahmen von Untersuchungen experimentell manipulierte Aufgaben eingesetzt werden, um kognitive Prozesse zu erfassen, sind Unterschiede zwischen Personen (Varianz in der abhängigen Variable) nicht nur auf die experimentelle Manipulation zurückzuführen, sondern auch auf Prozesse, die nichts mit der experimentellen Manipulation zu tun haben \citep[]{Jensen1982b, Miller2013, Neubauer1997a, Schweizer2007, Unsworth2007, vanZomeren1994}.
Wenn man beispielsweise annimmt, dass die Wachsamkeit, die Motivation oder die Motorik jeder einzelnen Person einen Einfluss auf die Reaktionszeiten in der \gls{ha} haben, ist bei der Analyse bivariater Zusammenhänge zwischen den Reaktionszeiten und psychometrischer Intelligenz auf Gruppenebene nicht klar, was die Ursache für den mit zunehmender Anzahl Antwortalternativen stärker werdenden negativen Zusammenhang zwischen den Bedingungen der \gls{ha} und psychometrischer Intelligenz ist \citep{Sheppard2008}. Waren intelligentere Personen wacher, motivierter oder einfach motorisch schneller als weniger intelligente Personen? Oder weisen intelligentere Personen tatsächlich (wie theoretisch vermutet) einen höheren \gls{ms} auf?

Mit diesem Beispiel sollte verdeutlicht werden, dass abhängige Variablen, die aus experimentell manipulierten Aufgaben abgeleitet werden, keine reinen Masse sind. Vielmehr bilden sie ein Gemisch von Prozessen ab, die an der Antwortabgabe beteiligt waren. Diese Verunreinigung von Massen zur Erfassung kognitiver Prozesse bezeichnete \citet{Schweizer2007} als \gls{ip}.


\subsection{Lösungsansätze \label{subsec:Loesungsansaetze}}

Ideen zur Bewältigung des \gls{ip}s gibt es mehrere. Diese lassen sich nach Ansätzen auf manifester und latenter Ebene unterscheiden. 

%\subsubsection{Auf manifester Ebene}

Auf manifester Ebene hat \citet{Donders1969} mit seiner Subtraktionsmethode ein Verfahren vorgeschlagen, mit dem die Zeit für einen einzelnen kognitiven Prozess, beispielsweise die Entscheidung für eine korrekte Antwort bei einer Mehrfachauswahl in der \gls{ha}, aus der Reaktionszeit herausgerechnet werden kann. Er ging davon aus, dass einfache Reaktionszeit hauptsächlich durch physiologische Prozesse determiniert ist, während die Reaktionszeit für eine Mehrfachauswahl neben denselben physiologischen Prozessen auch mentale Prozesse beansprucht. Seine Idee war, einfache Reaktionszeit von der Reaktionszeit für eine Mehrfachauswahl zu subtrahieren, womit die Differenz ein Mass für die Geschwindigkeit der mentalen Prozesse darstellt \citep{Donders1969}.
Spätere Untersuchungen haben jedoch gezeigt, dass sich kognitive Komponenten nicht additiv verhalten und die Subtraktionsmethode eine zu starke Vereinfachung darstellt \citep[z. B.][]{Friston1996, Ilan1994}.

\citet{Jensen1979} haben eine Methode entwickelt, mit der bei der Erfassung der Reaktionszeit in der \gls{ha} motorische Prozesse von kognitiven Prozessen getrennt werden können. Personen mussten dafür vor Präsentation der Stimuli ihren Antwortfinger auf eine Art Home-Taste der Tastatur legen. Erst danach wurden die Stimuli eingeblendet. Sobald die korrekte Antwort erkannt wurde, lösten die Personen ihren Finger von der Home-Taste und betätigten daraufhin die entsprechende Antworttaste. Durch diese Versuchsanordnung konnte die Zeitdauer, welche die Motorik in Anspruch nahm, von der Zeitdauer getrennt werden, die benötigt wurde, um die Reize wahrzunehmen und eine Entscheidung zu treffen. Dabei hat sich allerdings herausgestellt, dass die motorische Komponente mit der kognitiven Komponente konfundiert ist \citep{Jensen1979} und Antwortstrategien der Personen die Interpretation der isolierten Komponenten erschweren \citep{Smith1987b}.

Eine auf manifester Ebene häufig angewandte Methode zur Trennung von Prozessen stellt die Regressionsanalyse dar. Das Prinzip der Analyse lässt sich gut am Beispiel des linearen Zusammenhangs zwischen der Anzahl Bits und den Reaktionszeiten der \gls{ha} erklären (siehe \autoref{subsec:Der_Mental-Speed-Ansatz}): Modelliert man eine lineare Abhängigkeit zwischen der Anzahl Bits und den Reaktionszeiten, resultiert ein y-Achsen\-ab\-schnitt und eine Steigung. Nach dem diese Aufgabenparameter bestimmt wurden, kann jede beliebige Reaktionszeit durch die Verrechnung des y-Achsen\-ab\-schnitts, der Steigung und der Anzahl Bits beschrieben werden \citep[S. 105]{Jensen1987a}. 
Der y-Achsen\-ab\-schnitt und die Steigung bilden damit zwei Komponenten der Reaktionszeit, die unterschiedliche Prozesse repräsentieren. Beim y-Achsen\-ab\-schnitt wird angenommen, dass er ein Mass für die Zeitdauer ist, welche sensorische und motorische Prozesse benötigen, um den Reiz im Kortex wahrzunehmen und die Muskeln über efferente Nerven anzusteuern \citep{Jensen1998b}, während die Steigung die Verarbeitungsgeschwindigkeit von Information abbildet \citep{Jensen1998b, Roth1964}.
Im Rahmen von experimentell manipulierten Aufgaben mit Messwiederholung bietet die Regressionsanalyse folglich eine Möglichkeit Prozesse voneinander zu trennen, womit sich schlussendlich Zusammenhänge differenzierter betrachten lassen.

%\subsubsection{Auf latenter Ebene}

Im Gegensatz zu den Analysen, die bis hierhin besprochen wurden und auf manifester Ebene durchgeführt werden, ergibt sich bei einer Analyse auf latenter Ebene ein Vorteil. 
Genauer gesagt berücksichtigt eine latente Analyse, dass sich ein beobachteter Messwert (beispielsweise die Reaktionszeit in der \gls{ha}) immer aus einem wahren Anteil der Merkmalsausprägung und einem Fehleranteil, der nichts mit der wahren Merkmalsausprägung zu tun hat oder zufällig zustande kam, besteht \citep[S. 9]{Kline2011}.
Auf Gruppenebene lässt sich dann die Varianz des beobachteten Messwerts (die Unterschiede zwischen Personen) in wahre Varianz und Fehlervarianz, auch Messfehler genannt, trennen \citep{Moosbrugger2007}.
Mit Hilfe der Faktorenanalyse wird die Fehlervarianz von der Analyse ausgeschlossen. Übrig bleibt auf Gruppenebene die wahre Varianz von Prozessen, die an der abhängigen Variable beteiligt waren und auf ein latentes Konstrukt zurückzuführen sind. Damit lassen sich Zusammenhänge zwischen Variablen valider bestimmen als auf manifester Ebene.

Eine Faktorenanalyse trennt folglich wahre Varianz von Fehlervarianz. Damit ist das \gls{ip} aber nicht gelöst. Die in einer latenten Variable gebundene wahre Varianz kann immer noch durch eine Vielzahl von unterschiedlichen Prozessen entstanden sein. Genau an diesem Punkt setzen \glspl{flm} an \citep[z. B.][]{Schweizer2006a, Schweizer2006b, Schweizer2007, Schweizer2008, Schweizer2009a}. \glspl{flm} gehören zur Klasse der konfirmatorischen Faktorenanalysen und sind besonders interessant für die Analyse von experimentell manipulierten Aufgaben mit Messwiederholung (wie sie z. B. die Hick- oder die \gls{ssauf} darstellen). Während klassische Faktorenanalysen gemeinsame Varianz von manifesten Variablen mit einer latenten Variable erklären, trennen \glspl{flm} gemeinsame Varianz in zwei systematische Varianzquellen (Faktoren) auf: 
Ein erster Faktor bindet Varianz aufgabenrelevanter Prozesse, deren Einflüsse sich über die experimentellen Bedingungen hinweg nicht verändern. Dieser erste Faktor bildet folglich Prozesse ab, die für das Lösen der Aufgabe in jeder experimentellen Bedingung benötigt werden und einen gleichbleibenden konstanten Einfluss auf die Leistung in den Bedingungen ausüben. 
Ein zweiter Faktor bindet Varianz aufgabenrelevanter Prozesse, deren Einflüsse sich über die experimentellen Bedingungen hinweg verändern. In diesem zweiten Faktor werden somit Prozesse abgebildet, die für das Lösen der Aufgabe benötigt werden und einen sich mit der experimentellen Manipulation verändernden Einfluss auf die Leistung in den Bedingungen haben.

%Die Idee der \glspl{flm} ist, dass sich mit diesen zwei latenten Variablen die Prozesse der experimentellen Manipulation von allen anderen (konstanten) Prozessen trennen lassen.

\begin{figure}[b]
	\centering
	
	\begin{tikzpicture}
	[font=\sffamily, scale=2, inner sep=0pt,
	latent/.style	= {circle,draw,inner sep=0pt,minimum size=12mm},
	manifest/.style	= {rectangle,draw,inner sep=0pt,minimum width=12mm,minimum height=12mm},
	paths/.style	= {->, >=stealth, shorten >= 1pt},
	error/.style	= {circle, draw=none, fill=white, minimum size=5mm},
	covar/.style	= {<->, >=stealth, shorten >= 1pt, shorten <= 1pt}]
	
	\node at (1, 2.4)		[latent]	(lv1)	{LV1};
	\node at (1, 1)			[latent]	(lv2)	{LV2};
	
	\node at (-1.5, 2.9)	[manifest]	(ind1)	{Ind1};
	\node at (-1.5, 2.1)	[manifest]	(ind2)	{Ind2};
	\node at (-1.5, 1.3)	[manifest]	(ind3)	{Ind3};
	\node at (-1.5, 0.5)	[manifest]	(ind4)	{Ind4};
	
	\draw [paths] (lv1.west) -- (ind1.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize $\lambda^{v}$};
	\draw [paths] (lv1.west) -- (ind2.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize $\lambda^{v}$};
	\draw [paths] (lv1.west) -- (ind3.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize $\lambda^{v}$};
	\draw [paths] (lv1.west) -- (ind4.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize $\lambda^{v}$};
	
	\draw [paths] (lv2.west) -- (ind1.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize $\lambda^{w}$};
	\draw [paths] (lv2.west) -- (ind2.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize $\lambda^{x}$};
	\draw [paths] (lv2.west) -- (ind3.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize $\lambda^{y}$};
	\draw [paths] (lv2.west) -- (ind4.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize $\lambda^{z}$};
	
	\path [covar] (lv1.east) edge [bend left=45] node[minimum size = 4mm, draw=none, fill=white, midway]     {\footnotesize 0} (lv2.east);
	
	\end{tikzpicture}
	
	\vspace{.2cm}
	\caption[lol?]{Das Prinzip eines \gls{flm}s. Gemeinsame Varianz von Bedingungen (\textsf{Ind1} -- \textsf{Ind4}) wird in zwei latente Variablen getrennt (\textsf{LV1} und \textsf{LV2}). Die unstandardisierten Faktorladungen der Bedingungen auf \textsf{LV1} sind konstant ($\lambda^{v}$). Die unstandardisierten Faktorladungen der Bedingungen auf \textsf{LV2} folgen einem Verlauf, der sich aus theoretischen Überlegungen zum Einfluss der in \textsf{LV2} gebundenen Prozesse auf die vier Indikatoren ergibt ($\lambda^{w}$, $\lambda^{x}$, $\lambda^{y}$, $\lambda^{z}$). \textsf{LV1} und \textsf{LV2} werden unabhängig voneinander gehalten. Fehlervarianzen sind in diesem Beispiel nicht eingezeichnet.}
	\label{fig:fixed-links_model}
\end{figure} 

Erreicht wird die Trennung dieser Prozesse in zwei Schritten. Zum einen werden vor der Modellschätzung die unstandardisierten Faktorladungen der manifesten Indikatoren auf die beiden latenten Variablen fixiert. Die unstandardisierten Faktorladungen ($\lambda$) der manifesten Indikatoren auf die erste latente Variable werden dabei alle auf den gleichen Wert gesetzt (z. B. $\lambda^{v}$; siehe \autoref{fig:fixed-links_model}). 
Die unstandardisierten Faktorladungen der manifesten Indikatoren auf die zweite latente Variable folgen einem Verlauf, der sich aus theoretischen Überlegungen zum Einfluss der erfassten, experimentell manipulierten Prozesse \textcolor{red}{auf die Leistung in den Bedingungen?} ergibt (z. B. $\lambda^{w}$, $\lambda^{x}$, $\lambda^{y}$, $\lambda^{z}$; siehe \autoref{fig:fixed-links_model}). Analysiert man beispielsweise die Reaktionszeiten der \gls{ha} und hat man Grund zur Annahme, dass die Verarbeitungsgeschwindigkeit mit zunehmender Anzahl Antwortalternativen einen immer stärker werdenden (linearen) Einfluss auf die Reaktionszeit hat, fixiert man die Faktorladungen auf $\lambda^{w}=1$, $\lambda^{x}=2$, $\lambda^{y}=3$ und $\lambda^{z}=4$. 
Zum anderen wird die Korrelation zwischen den beiden latenten Variablen auf $0$ fixiert. Damit werden die Varianzen statistisch vollständig voneinander getrennt.
Weil durch die Fixierung der unstandardisierten Faktorladungen im Rahmen der Parameterschätzung die Matrix der Faktorladungen nicht mehr geschätzt wird (sie wird a priori bestimmt), müssen die Varianzen der latenten Variablen auf Signifikanz geprüft werden. 
Damit wird sichergestellt, dass die latenten Variablen einen substanziellen Varianzanteil gebunden haben und sich die Interpretation der latenten Variablen nicht auf ein statistisches Artefakt bezieht. Verfehlt die Varianz einer latenten Variable das Signifikanzniveau, wurden darin keine bedeutsamen Prozesse abgebildet und das gesamte Modell muss verworfen werden \citep[z. B.][]{Schweizer2006a, Schweizer2006b, Schweizer2007, Schweizer2008, Schweizer2009a}.

\glspl{flm} stellen eine Möglichkeit dar, dem \gls{ip} entgegenzutreten und Prozesse voneinander zu trennen. Sie haben gegenüber anderen Methoden zur Analyse von experimentell manipulierten Aufgaben mit Messwiederholung entscheidende Vorteile.
Im Vergleich mit Analysemethoden auf manifester Ebene berücksichtigen \glspl{flm}, dass ein beobachteter Messwert Messfehler enthält \citep{Moosbrugger2007}. Dieser Messfehler wird bei einer latenten Analyse isoliert, womit die den manifesten Zusammenhängen zugrunde liegende Beziehung aufgedeckt wird und validere Schlussfolgerungen gezogen werden können \citep[S. 9]{Kline2011}.
\textcolor{red}{
Im Vergleich mit klassischen Faktorenanalysen, welche gemeinsame Varianz von manifesten Indikatoren auf einen einzigen Faktor zurückführen, trennen \glspl{flm} Varianz von Prozessen, die über die experimentelle Manipulation hinweg einen gleichbleibenden Einfluss auf die manifesten Variablen ausüben, von Varianz von Prozessen, die sich mit der experimentellen Manipulation verändern.}
Dadurch lässt sich auf statistischer Ebene die an der experimentellen Manipulation beteiligten Prozesse von allen andere Prozessen trennen.
Darin unterscheiden sich \glspl{flm} auch von bifaktoriellen Modellen \citep[z. B.][]{Moosbrugger2006, Schweizer2010}. Bifaktorielle Modelle trennen wie \glspl{flm} gemeinsame Varianz von manifesten Indikatoren in zwei latente Variablen, die Faktorladungen werden jedoch nicht a priori aufgrund theoretischer Überlegungen zum Einfluss der Prozesse auf die manifesten Indikatoren fixiert, sondern frei geschätzt. Mit bifaktoriellen Modellen lässt sich folglich die von der experimentellen Manipulation verursachte Varianz in den manifesten Indikatoren nicht von der Varianz der Prozesse trennen, welche unabhängig von der experimentellen Manipulation sind.

Untersuchungen, die \glspl{flm} benützt haben, um die Verunreinigung von kognitiven Korrelaten psychometrischer Intelligenz auf statistischer Ebene rückgängig zu machen, gibt es einige \citep[z. B.][]{Ren2013, Schweizer2007, Stankov2007, Wang2015}. Die formulierten theoretischen Modelle beschrieben dabei die empirischen Daten jeweils gut. Diese Ergebnisse deuten darauf hin, dass \glspl{flm} bei der Bestimmung der kognitiven Grundlagen individueller Intelligenzunterschiede nicht nur aus theoretischer, sondern auch aus praktischer Sichtweise vorteilhaft sind. \todo[color=green!40, fancyline]{gut so?}

\textcolor{red}{
Wenn eine experimentell manipulierte Aufgabe mit Messwiederholung eingesetzt wird, um ein Konstrukt zu erfassen, bieten sich \glspl{flm} somit als eine elegante Modellierungstechnik an, um zur Erfassung kognitiver Konstrukte die Verunreinigung von Massen auf statistischer Ebene rückgängig zu machen.}



\section{Fragestellungen \label{sec:Fragestellungen}}

Der \gls{ssans} zur Erklärung individueller Intelligenzunterschiede ist neu und unterscheidet sich von der Art der Aufgabenstellung her deutlich von reaktionszeitbasierten \glspl{msm}n. Das übergeordnete Ziel dieser Arbeit besteht darin, zu überprüfen, ob sich die \gls{ssauf} als Prädiktor psychometrischer Intelligenz bewährt und inwiefern der \gls{ssans} zur Aufklärung individueller Intelligenzunterschiede neuartige Erklärungsmöglichkeiten liefert, welche nicht bereits der \gls{msa} bietet. Dieses Ziel soll durch die Erarbeitung von fünf Punkten erreicht werden:

\begin{enumerate}
	\item Die Arbeit von \citet{Melnick2013} berichtet bis heute als einzige über den Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz. Um die Aufgabe als Prädiktor für psychometrische Intelligenz zu festigen, bedarf es einer Bestätigung dieses Befunds. Dafür werden für die vorliegende Arbeit die experimentellen Bedingungen von \citeauthor{Melnick2013} bestmöglich übernommen und die Aufgabe wird einer grossen, betreffend der Intelligenzausprägung heterogenen Stichprobe vorgelegt. Die aus der Aufgabe abgeleitete abhängige Variable, der \gls{si}, wird entsprechend dem Vorgehen in der Originalarbeit gebildet. Der \gls{si} wurde in der Arbeit von \citeauthor{Melnick2013} mit IQ-Punkten in Zusammenhang gebracht. Der IQ wurde dabei für jede Person aus der Kurzform der Wechsler-Adult-Intelligence-Scale III \citep{Axelrod2002} und aus der Wechsler-Adult-In\-tell\-igence-Scale IV \citep{Wechsler2008} gebildet \citep[siehe Studie 1 und 2 bei][]{Melnick2013}. Wenn die Annahme gilt, dass der Zusammenhang zwischen dem \gls{si} und psychometrischer Intelligenz robust ist, sollte dieser auch unter Einsatz eines anderen Instruments zur Erfassung der psychometrischen Intelligenz auftreten. In der  vorliegenden Arbeit wird der Berliner Intelligenzstruktur-Test \citep{Jaeger1997} eingesetzt, welcher sich empirisch als Indikator für Intelligenz bewährt hat \citep{Beauducel2002, Valerius2014}. Die Verwendung von nicht exakt demselben Intelligenzmass erscheint hinsichtlich einer beabsichtigten Bestätigung des Befunds von \citeauthor{Melnick2013} als Schwachpunkt dieser Arbeit. Führt man sich aber vor Augen, dass die \gls{ssauf} beansprucht, einen grundlegenden Aspekt der menschlichen Informationsverarbeitung zu erfassen, erscheint die Verwendung eines Intelligenzmasses, welches noch nie mit der \gls{ssauf} in Zusammenhang gebracht wurde, weniger als Schwachpunkt, sondern vielmehr als eine Notwendigkeit.

	\item Der \gls{si} wurde bei \citet{Melnick2013} für jede Person als Differenz zwischen zwei Erkennungsschwellen gebildet. Differenzmasse leiden in empirischen Untersuchungen oft unter einer reduzierten Reliabilität \citep[][S. 145]{Murphy2005}. Es kann somit bei den Resultaten von \citeauthor{Melnick2013} nicht ausgeschlossen werden, dass die verminderte Reliabilität des \gls{si} die Ergebnisse verzerrt hat. Um diese Problematik anzugehen, wird in der vorliegenden Arbeit zusätzlich eine abhängige Variable eingesetzt, welche nicht auf einer Differenz zwischen zwei Erkennungsschwellen beruht. \citeauthor{Melnick2013} haben sich in ihrer Arbeit bereits bemüht, ein alternatives Mass herzuleiten. Sie haben die Erkennungsschwellen jeder Person mit einer exponentiellen Regression vorhergesagt, jedoch nicht beide daraus resultierenden Aufgabenparameter, die Asymptote und die Steigung, mit psychometrischer Intelligenz in Verbindung gesetzt. Um die \gls{ssauf} mit ihren Bestandteilen besser zu verstehen und die Problematik des Differenzmasses zu umgehen, werden deshalb in der vorliegenden Arbeit beide aus der exponentiellen Regression abgeleiteten Aufgabenparameter benutzt, um psychometrische Intelligenz vorherzusagen. 

	\item Eine weitere Möglichkeit zur Quantifizierung von \gls{ss} besteht darin, die Aufgabenbedingungen auf latenter Ebene zu analysieren -- das heisst, die Zusammenhänge der Aufgabenbedingungen mit einer klassischen Faktorenanalyse auf einen \textcolor{red}{unbeobachteten} Faktor zurückzuführen. Im Gegensatz zur manifesten Auswertung (vgl. Punkt 1 und 2) berücksichtigt die Analyse auf latenter Ebene die Tatsache, dass sich ein beobachteter Messwert immer aus einem wahren Anteil der Merkmalsausprägung und einem zufällig zustande gekommenen Fehleranteil, der unabhängig von der wahren Merkmalsausprägung ist, zusammensetzt \citep{Moosbrugger2007}. Ein latenter Faktor beinhaltet nur die wahren Merkmalsausprägungen von Personen, womit sich, verglichen mit einer Analyse auf manifester Ebene, Zusammenhänge mit anderen Variablen valider bestimmen lassen \citep[S. 9]{Kline2011}. Die Bedeutung der \gls{ssauf} als Prädiktor von \textit{g}, der latenten Operationalisierung psychometrischer Intelligenz, sollte demnach auf latenter Ebene deutlicher erkennbar sein als auf manifester Ebene.

	\item Um bei der Beschreibung der \gls{ssauf} auf latenter Ebene eine vergleichbare Trennung von Prozessen zu erhalten wie unter Punkt 2 auf manifester Ebene, wird versucht die Aufgabenbedingungen mit einem \gls{flm} (siehe \autoref{subsec:Loesungsansaetze}) zu beschreiben. 
	Dafür werden zwei latente Variablen angenommen: Die erste latente Variable bildet durch konstant gehaltene Faktorladungen aufgabenrelevante Prozesse ab, deren Einflüsse sich über die vier Bedingungen hinweg nicht ändern. \todo[color=green!40, fancyline]{worauf?}
	Die zweite latente Variable weist sich unterscheidende Faktorladungen auf, welche  bestimmten Annahmen folgend gewählt werden.
	Durch diese Faktorladungen werden in der zweiten latenten Variable aufgabenrelevante Prozesse gebunden, die durch die vier Bedingungen systematisch manipuliert wurden. Weil die Aufgabe noch nie mit einem \gls{flm} beschrieben wurde, werden unterschiedliche Ladungsverläufe getestet und das beste Modell wird für die weiteren Analysen ausgewählt.
	Diese Trennung von aufgabenrelevanten Prozessen auf latenter Ebene kann dann zum einen benutzt werden, um die \gls{ssauf} mit ihren Bestandteilen besser zu verstehen, und zum anderen lässt sich damit der Zusammenhang der Aufgabe mit dem \gls{gfaktor} differenzierter betrachten als mit einer klassischen Faktorenanalyse.

	\item Nach dieser ausführlichen, aber auch isolierten Aufarbeitung des Zusammenhangs zwischen der \gls{ssauf} und psychometrischer Intelligenz wird der Zusammenhang im Sinne eines nomologischen Netzwerks \citep{Cronbach1955} um \gls{ms} erweitert. Dafür wird die \gls{ha} als ein etabliertes \gls{msm} hinzugezogen. 
	Mit diesem Schritt wird auf manifester wie auch auf latenter Ebene geprüft, ob die \gls{ssauf} im Zusammenhang mit psychometrischer Intelligenz einen Aspekt der menschlichen Informationsverarbeitung abbildet, der neuartig ist und nicht bereits von einer bestehenden, etablierten Aufgabe erfasst beziehungsweise erklärt wird. Schlussendlich soll dadurch die Frage beantwortet werden, ob der \gls{ssans} zur Aufklärung individueller Intelligenzunterschiede neuartige Erklärungsmöglichkeiten bietet oder ob der \gls{msa} den Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz vollständig zu erklären vermag. \todo[color=green!40, fancyline]{ja?}

\end{enumerate}



% =================================================================
% M E T H O D
% =================================================================
\chapter{Methode \label{cha:Methode}}

\section{Stichprobe \label{sec:Stichprobe}}

An den Testungen haben $206$~\glspl{vp} teilgenommen, wovon $29$~\glspl{vp}~($14\,\%$) aufgrund von technischen Problemen, nicht auswertbarer Subtests oder im Vergleich zu den restlichen \glspl{vp} stark abweichenden Werten ausgeschlossen wurden (siehe \autoref{cha:Anhang_A} für eine genaue Erläuterung der Vorgehensweise).

Analysiert wurden die Daten von $177$ \glspl{vp}. Die $116$ Frauen und $61$ Männer waren zwischen $18$ und $30$ Jahre alt und wiesen ein mittleres Alter $\pm$ \gls{sd} von $21.14\,\pm\,2.71$ Jahren auf. 
Um eine bezüglich der Intelligenzausprägung heterogene Stichprobe zu erhalten, nahmen \glspl{vp} aus verschiedenen Bildungsgruppen an der Untersuchung teil:
Neun~\glspl{vp} haben als höchsten Bildungsabschluss die obligatorische Schulzeit genannt,
$55$~\glspl{vp} eine Berufslehre,
$31$~\glspl{vp} eine Berufsmatura,
$23$~\glspl{vp} eine gymnasiale Maturität,
$45$~\glspl{vp} ein Bachelor-Studium,
drei~\glspl{vp} ein Master-Studium und 
$11$~\glspl{vp} eine andere Ausbildung.
$160$ der $177$ \glspl{vp} waren deutscher Muttersprache. Die anderen $17$~\glspl{vp} sprachen akzentfrei deutsch. Alle \glspl{vp} berichteten über eine normale Sehschärfe, eine normale Hörfähigkeit, waren Nichtraucher, konsumierten keine Medikamente und waren nicht chronisch krank. Um Einflüsse von Koffein auf die Wahrnehmungsleistung \citep[][]{Stough1995} der \glspl{vp} zu minimieren, wurden die \glspl{vp} gebeten, bis zwei Stunden vor der Teilnahme keine koffeinhaltigen Getränke zu konsumieren. Die \glspl{vp} hatten keine Erfahrung mit den Testverfahren. 
Für die Teilname an der Untersuchung erhielten Berner Studierende des Fachs Psychologie vier~Ver\-suchs\-per\-sonen-Stun\-den, die sie an ihr Studium anrechnen lassen konnten. Alle anderen \glspl{vp} wurden für die Teilnahme mit CHF~$50.-$ entlöhnt.



\section{Die Spatial-Suppression-Aufgabe \label{sec:Die_Spatial-Suppression-Aufgabe}}

Als Grundlage für die Aufgabe diente der \href{http://www2.bcs.rochester.edu/sites/duje/SuppressionCode.zip}{Programmcode} von \citet{Melnick2013}.

\subsection{Apparatur und Material \label{sub:ssas}}
Präsentiert wurde die Aufgabe auf einem ASUS Vento A2 Computer, der mit einem 2.6 GHz Prozessor, 4 GB Arbeitsspeicher und 512 MB Videospeicher (Nvidia GeForce 9800 GT) ausgestattet war. Als Betriebssystem diente Windows 7. Der verwendete ASUS VG248QE Computermonitor wies bei einer Bildschirmbreite von $53.2$ cm und einer Bildschirmhöhe von $29.9$ cm eine Auflösung von $1920 \times 1080$ Pixel auf. Er wurde linearisiert und mit einer Bildwiederholungsrate von 144 Hz betrieben. Die Antworten der \glspl{vp} wurden mit einer PC-Tastatur erfasst. 

Die visuellen Reize wurden in MATLAB\textsuperscript{\textregistered} \citep{matlab} erzeugt. Die vertikal schwarz-grau gestreiften Muster (Ortsfrequenz von $1^{\circ}$ Sehwinkel pro Periode) wurden mit einem Kontrast von $99\,\%$ auf einem grauen Hintergrund präsentiert, welcher eine Leuchtdichte von $178\,\textnormal{cd}/ \textnormal{m}^2$ aufwies. Die Leuchtdichte des Raumes betrug in unmittelbarer Umgebung des Monitors $9\,\textnormal{cd}/ \textnormal{m}^2$. Die drei in \citet{Melnick2013} verwendeten Mustergrössen mit den Sehwinkeln  $1.8^{\circ}$, $3.6^{\circ}$ und $7.2^{\circ}$ wurden um die Mustergrösse von $5.4^{\circ}$ ergänzt, wodurch sich für diese Arbeit die Mustergrössen mit den Sehwinkeln $1.8^{\circ}$, $3.6^{\circ}$, $5.4^{\circ}$ und $7.2^{\circ}$ ergaben (siehe \autoref{fig:spatial_suppression_stimuli}). 
Die Sehwinkel der Muster wurden mit einer Kinnstütze, die $61$~cm vom Monitor entfernt war, sichergestellt. 
%Die räumliche Frequenz aller vertikal schwarz-grau gestreiften Mustergrössen betrug wie bei \citeauthor{Melnick2013} $1^{\circ}$ pro Periodenlänge.
Der verwendete Ton wies bei einer Frequenz von $2900$~Hz und einer Lautstärke von $70$~dB eine Länge von $50$~ms auf.

\begin{figure}[htb]
	\centering
	\subfloat[Sehwinkel $= 1.8^{\circ}$][Sehwinkel $= 1.8^{\circ}$]{\includegraphics[width=0.48\textwidth]{png/s1_a}}~~
	\subfloat[Sehwinkel $= 3.6^{\circ}$][Sehwinkel $= 3.6^{\circ}$]{\includegraphics[width=0.48\textwidth]{png/s2_a}}

	\subfloat[Sehwinkel $= 5.4^{\circ}$][Sehwinkel $= 5.4^{\circ}$]{\includegraphics[width=0.48\textwidth]{png/s3_a}}~~
	\subfloat[Sehwinkel $= 7.2^{\circ}$][Sehwinkel $= 7.2^{\circ}$]{\includegraphics[width=0.48\textwidth]{png/s4_a}}

	\caption[Die Spatial-Suppression-Bedingungen]{Die vier Mustergrössen $(a - d)$ der \gls{ssauf}.}
	\label{fig:spatial_suppression_stimuli}
\end{figure}

\subsection{Versuchsablauf \label{subsec:Spatial-Suppression_Versuchsablauf}}

Ein Durchgang sah folgendermassen aus: Nach einer Zeitspanne von $440$~ms erschien in der Mitte des Monitors für $560$~ms ein Kreis, der sich über die ersten $200$~ms von einer Grösse von $1.6^{\circ}$ auf eine Grösse von $0.26^{\circ}$ zusammenzog, für $360$~ms diese Grösse beibehielt und anschliessend ausgeblendet wurde. Dieses Vorgehen diente dazu, den Blick der \glspl{vp} in die Bildschirmmitte zu lenken. Nach einem  Intervall von $300$~ms erschien in der Mitte des Monitors ein sich nach links oder rechts bewegendes vertikal schwarz-grau gestreiftes Musters. Die Stelle, an welcher die \glspl{vp} das Muster auf dem Monitor sahen, war stationär. Hinter dieser stationären Stelle bewegte sich das Muster mit einer Geschwindigkeit von $4^\circ / \textnormal{s} $  nach links oder nach rechts. Nach der Darbietungszeit mussten die \glspl{vp} mit einem Tastendruck entscheiden, in welche Richtung sich das Muster bewegt hat. Die \glspl{vp} erhielten die Instruktion, bei einer wahrgenommenen Bewegung nach links mit ihrem linken Zeigefinger die linke Pfeiltaste  und bei einer wahrgenommen Bewegung nach Rechts mit ihrem rechten Zeigefinger die rechte Pfeiltaste zu drücken. 
Bei einer korrekten Antwort wurde ein Ton abgegeben und die Darbietungszeit des nächsten Musters verringert, bei einer falschen Antwort wurde kein Ton abgegeben und die Darbietungszeit des nächsten Musters erhöht. 
Die Darbietungszeit des Musters wurde entsprechend dem QUEST-Ver\-fah\-ren \citep{Watson1983} angepasst.
Das QUEST-Ver\-fah\-ren ist adaptiv und arbeitet mit logarithmierten Werten, das heisst alle Berechnungen des Verfahrens finden im logarithmierten Raum statt. Der Algorithmus schätzt dabei mit Hilfe von Grundprinzipien der Bayes-Statistik nach jeder Antwort eine $\log_{10}$-Erkennungsschwelle für einen im Voraus bestimmten Prozentsatz an korrekten Antworten (in der hier vorliegenden Aufgabe betrug der Prozentsatz $82\,\%$).
Die geschätzte $\log_{10}$-Erkennungsschwelle wird dann vom Algorithmus benutzt, um die Darbietungszeit des nächsten Stimulus zu bestimmen. 
Die \glspl{vp} wurden instruiert, sich bei der Antwortabgabe genügend Zeit zu lassen und möglichst fehlerfrei zu arbeiten. Nach Antwortabgabe startete der nächste Durchgang.

Als Erstes bearbeiteten die \glspl{vp} eine Übungsaufgabe. Dabei wurden die vier Mustergrössen allen \glspl{vp} je drei Mal in einer pseudorandomisierten Abfolge präsentiert. Die Darbietungszeit aller Mustergrössen betrug zu Beginn der Aufgabe $80$~ms und wurde adaptiv angepasst. Die Übungsaufgabe dauerte etwa eine Minute und wurde nicht ausgewertet. Die $12$~Durchgänge der Übungsaufgabe dienten dazu, dass sich die \glspl{vp} mit der Art der Stimuluspräsentation, der Antworteingabe und dem Ton vertraut machen konnten. 

Als Zweites folgte eine etwas längere Aufgabe. Die \glspl{vp} bearbeiteten drei Wiederholungen, die durch eine Pause von etwa $30$~Sekunden getrennt waren. Eine Wiederholung bestand aus zwei Schätzungen der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le pro Mustergrösse. Jede der vier Mustergrössen wurde innerhalb einer Schätzung sieben Mal präsentiert. Gesamthaft bearbeiteten die \glspl{vp} folglich $3 \times 2 \times 4 \times 7 = 168$ Durchgänge. Die Mustergrössen wurde allen \glspl{vp} in einer pseudorandomisierten Abfolge präsentiert. Die Darbietungszeit der Mustergrössen betrug zu Beginn der Aufgabe $30$~ms und wurde für jede Mustergrösse einzeln über den gesamten Verlauf der $42$~Durchgänge adaptiv angepasst. Die Aufgabe dauerte etwa $7$~Minuten und wurde nicht ausgewertet, weil sich bei einigen \glspl{vp} die Wahrnehmungsleistung während der ersten Durchgänge stark verbessern kann (D. Tadin, persönl. Mitteilung, 19.08.2014). Dieser Aufgabenblock diente dazu, diese Trainingseffekte zuzulassen und die Leistung der \glspl{vp} auf ihrem individuellem Niveau zu festigen. 

Als Drittes wurde den \glspl{vp} die eigentliche Aufgabe vorgelegt. Die \glspl{vp} bearbeiteten drei Wiederholungen, die durch eine Pause von etwa einer Minute getrennt waren. Eine Wiederholung bestand aus zwei Schätzungen der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le pro Mustergrösse. Jede der vier Mustergrössen wurde innerhalb einer Schätzung $22$~Mal präsentiert. Gesamthaft bearbeiteten die \glspl{vp} somit $3 \times 2 \times 4 \times 22 = 528$ Durchgänge. 
Daraus resultierten für jede \gls{vp} 24 Schätzungen der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le (sechs pro Mustergrösse).
Die Mustergrössen wurde allen \glspl{vp} in einer pseudorandomisierten Abfolge präsentiert. Die Darbietungszeit der Mustergrössen betrug bei Start der Aufgabe $30$~ms und wurde für jede Mustergrösse einzeln über den gesamten Verlauf der $132$~Durchgänge adaptiv angepasst. 
Die Aufgabe dauerte etwa $25$~Minuten. 

Für jede \gls{vp} wurden die sechs pro Mustergrösse erhaltenen $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-len in eine Rangreihenfolge gebracht, die tiefste und höchste Schätzung entfernt und die restlichen vier $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-len gemittelt. Damit resultierte für jede \gls{vp} pro Mustergrösse ($1.8^{\circ}$, $3.6^{\circ}$, $5.4^{\circ}$ und $7.2^{\circ}$) eine $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le für horizontale Bewegung. 
Alle Berechnungen wurden mit diesen $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-len getätigt. 
Ausnahme bildete die exponentielle Regression (siehe \autoref{sec:2Fragestellung}), bei welcher die vier $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-len auf Anraten von D. Tadin (persönl. Mitteilung, 11.02.2016) als Exponenten zur Basis 10 verrechnet und in dieser invertierten Form analysiert wurden.
Um die Interpretation der logarithmierten Werte zu erleichtern, wurden sie für die Ergebnisdarstellung (in Tabellen und Abbildungen) invertiert.
Der \gls{si} wurde gemäss der Vorgehensweise von \citet{Melnick2013} als Differenz zwischen der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le für die Mustergrösse $7.2^{\circ}$ und der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le für die Mustergrösse $1.8^{\circ}$ gebildet. 


\section{Die Hick-Aufgabe \label{sec:Hick}}

Angelehnt an die Versuchsanordnung von \citet{Rammsayer2007} wurde als Mass für \gls{ms} eine \gls{ha} eingesetzt.

\subsection{Apparatur und Material \label{sub:}}
Präsentiert wurde die Aufgabe auf dem in \autoref{sub:ssas} beschriebenen Computer, mit dem einzigen Unterschied, dass die Auflösung des Computermonitors für die \gls{ha} $1280 \times 1024$ Pixel betrug. Die Antworten der \glspl{vp} wurden mit einer Cedrus RB-830 Tastatur erfasst. 

Die Stimuli wurden mit E-Prime\textsuperscript{\textregistered} \citep{eprime} generiert. Die weissen Stimuli wurden auf einem schwarzen Hintergrund präsentiert, welcher eine Leuchtdichte von $2\,\textnormal{cd}/ \textnormal{m}^2$ aufwies. Der horizontale und vertikale Sehwinkel der verwendeten Rechtecke betrug $1.8^{\circ}$ respektive $1.5^{\circ}$. Die Rechtecke wurden auf dem Monitor zentriert dargeboten. Die Stimulianordnung der verwendeten Bedingungen sah folgendermassen aus (siehe \autoref{fig:hick_stimuli}):  In der $0$-Bit-Bedingung wurde ein Rechteck präsentiert. In der $1$-Bit-Bedingung wurden horizontal nebeneinander zwei Rechtecke präsentiert. Die beiden Rechtecke erschlossen zusammen einen horizontalen und vertikalen Sehwinkel von $4.5^{\circ}$ respektive $1.5^{\circ}$. In der $2$-Bit-Bedingung wurden in U-Form vier Rechtecke präsentiert. Die vier Rechtecke erschlossen gemeinsam einen horizontalen und vertikalen Sehwinkel von $7.5^{\circ}$ respektive $4.3^{\circ}$. In der $2.58$-Bit-Bedingung wurden zu den in U-Form angeordneten vier Rechtecken der $2$-Bit-Bedingung in der oberen Reihe je links und rechts ein Rechteck hinzugefügt. Die sechs Rechtecke erschlossen zusammen einen horizontalen und vertikalen Sehwinkel von $12.9^{\circ}$ respektive $4.3^{\circ}$. Der Sehwinkel des imperativen Reizes, einem \enquote{+}, betrug $0.5^{\circ}$ und wurde  immer in der Mitte eines Rechtecks präsentiert. Die Sehwinkel der Stimuli wurden mit einer Kinnstütze, die $61$ cm vom Monitor entfernt war, sichergestellt. Der verwendete Ton wies bei einer Frequenz von $1000$~Hz und einer Lautstärke von $70$~dB eine Länge von $200$~ms auf.

\begin{figure}[htbp]
	\centering
	\subfloat[0-Bit]		[0-Bit-Bedingung]	{
		\resizebox{.9\textwidth}{!}{
			\begin{tikzpicture}
			[scale=1, font=\sffamily, inner sep=0pt, baseline,
			manifest/.style		= {draw, rectangle, thick, white, inner sep=0pt, minimum width=19mm, minimum height=16mm},
			invisible/.style	= {draw opacity=0, rectangle, thick, black!80, inner sep=0pt, minimum width=19mm, minimum height=16mm},
			visual/.style 		= {draw, rectangle, thick, white, fill=white!100, minimum width= 10.65mm, minimum height=.5mm}]
			
			\node [invisible]	at (0,0)							(3)	{};
			\node [invisible]	[right = 11mm of 3]	  				(4)	{};
			\node [invisible]	[above left  = 15mm and -3mm of 3]	(2) {};
			\node [invisible]	[above right = 15mm and -3mm of 4]	(5) {};
			\node [invisible]	[left  = 11mm of 2]	  				(1)	{};
			\node [invisible]	[right = 11mm of 5]	  				(6)	{};
			
			\node [manifest] at (1.5,1.5)							(9)	{\Huge $+$};
			
			\node [visual]		at (-5,-1)	{}							;
			\node [white]		at (-5,-.6) {\Large$1^{\circ}$}		;
			
			\begin{scope}[on background layer]
				\node [fill=black!80, inner sep= 20pt, fit=(1) (2) (3) (4) (5) (6)] {};
			\end{scope}
			\end{tikzpicture}
}} \newline

\subfloat[1-Bit]		[1-Bit-Bedingung]	{
	\resizebox{.9\textwidth}{!}{
		\begin{tikzpicture}
		[scale=1, font=\sffamily, inner sep=0pt,
		manifest/.style		= {draw, rectangle, thick, white, inner sep=0pt, minimum width=19mm, minimum height=16mm},
		invisible/.style	= {draw opacity=0, rectangle, thick, black!80, inner sep=0pt, minimum width=19mm, minimum height=16mm},
		visual/.style 		= {draw, rectangle, thick, white, fill=white!100, minimum width= 10.65mm, minimum height=.5mm}]
		
		\node [invisible]	at (0,0)							(3)	{};
		\node [invisible]	[right = 11mm of 3]	  				(4)	{};
		\node [invisible]	[above left  = 15mm and -3mm of 3]	(2) {};
		\node [invisible]	[above right = 15mm and -3mm of 4]	(5) {};
		\node [invisible]	[left  = 11mm of 2]	  				(1)	{};
		\node [invisible]	[right = 11mm of 5]	  				(6)	{};
		
		\node [manifest] at (0,1.5)				(9)		{\Huge $+$}	;
		\node [manifest] [right = 11mm of 9] 	(10)	{}			;	
		
		\node [visual]		at (-5,-1)	{}							;
		\node [white]		at (-5,-.6) {\Large$1^{\circ}$}		;
		
		\begin{scope}[on background layer]
		\node [fill=black!80, inner sep= 20pt, fit=(1) (2) (3) (4) (5) (6)] {};
		\end{scope}
		\end{tikzpicture}
	}} \newline
	
	\subfloat[2-Bit]		[2-Bit-Bedingung]	{
		\resizebox{.9\textwidth}{!}{
			\begin{tikzpicture}
			[scale=1, font=\sffamily, inner sep=0pt,
			manifest/.style		= {draw, rectangle, thick, white, inner sep=0pt, minimum width=19mm, minimum height=16mm},
			invisible/.style	= {draw opacity=0, rectangle, thick, black!80, inner sep=0pt, minimum width=19mm, minimum height=16mm},
			visual/.style 		= {draw, rectangle, thick, white, fill=white!100, minimum width= 10.65mm, minimum height=.5mm}]
			
			\node [invisible]	at (0,0)							(3)	{};
			\node [invisible]	[right = 11mm of 3]	  				(4)	{};
			\node [invisible]	[above left  = 15mm and -3mm of 3]	(2) {};
			\node [invisible]	[above right = 15mm and -3mm of 4]	(5) {};
			\node [invisible]	[left  = 11mm of 2]	  				(1)	{};
			\node [invisible]	[right = 11mm of 5]	  				(6)	{};
			
			\node [manifest]	at (0,0)							(3)	{};
			\node [manifest]	[right = 11mm of 3]	  				(4)	{};
			\node [manifest]	[above left  = 15mm and -3mm of 3]	(2) {\Huge $+$};
			\node [manifest]	[above right = 15mm and -3mm of 4]	(5) {};	
			
			\node [visual]		at (-5,-1)	{}							;
			\node [white]		at (-5,-.6) {\Large$1^{\circ}$}		;
			
			\begin{scope}[on background layer]
			\node [fill=black!80, inner sep= 20pt, fit=(1) (2) (3) (4) (5) (6)] {};
			\end{scope}
			\end{tikzpicture}
		}} \newline
		
		\subfloat[$2.58$-Bit]		[$2.58$-Bit-Bedingung]	{
			\resizebox{.9\textwidth}{!}{
				\begin{tikzpicture}
				[scale=1, font=\sffamily, inner sep=0pt,
				manifest/.style		= {draw, rectangle, thick, white, inner sep=0pt, minimum width=19mm, minimum height=16mm},
				invisible/.style	= {draw opacity=0, rectangle, thick, black!80, inner sep=0pt, minimum width=19mm, minimum height=16mm},
				visual/.style 		= {draw, rectangle, thick, white, fill=white!100, minimum width= 10.65mm, minimum height=.5mm}]
				
				\node [invisible]	at (0,0)							(3)	{};
				\node [invisible]	[right = 11mm of 3]	  				(4)	{};
				\node [invisible]	[above left  = 15mm and -3mm of 3]	(2) {};
				\node [invisible]	[above right = 15mm and -3mm of 4]	(5) {};
				\node [invisible]	[left  = 11mm of 2]	  				(1)	{};
				\node [invisible]	[right = 11mm of 5]	  				(6)	{};
				
				\node [manifest]	at (0,0)							(3)	{};
				\node [manifest]	[right = 11mm of 3]	  				(4)	{};
				\node [manifest]	[above left  = 15mm and -3mm of 3]	(2) {};
				\node [manifest]	[above right = 15mm and -3mm of 4]	(5) {};
				\node [manifest]	[left  = 11mm of 2]	  				(1)	{};
				\node [manifest]	[right = 11mm of 5]	  				(6)	{\Huge $+$};
				
				\node [visual]		at (-5,-1)	{}							;
				\node [white]		at (-5,-.6) {\Large$1^{\circ}$}		;
				
				\begin{scope}[on background layer]
				\node [fill=black!80, inner sep= 20pt, fit=(1) (2) (3) (4) (5) (6)] {};
				\end{scope}
				\end{tikzpicture}
			}} \newline
			
			\caption[Die Hick-Bedingungen]{Die vier Bedingungen $(a - d)$ der \gls{ha}. }
			\label{fig:hick_stimuli}
\end{figure}




\subsection{Versuchsablauf \label{subsec:hick_Versuchsablauf}}

In der $0$-Bit-Bedingung bearbeiteten die \glspl{vp} $32$ Durchgänge. Jeder Durchgang startete nach $1100$ ms mit der Präsentation eines Rechtecks. Nach einer variablen Zeitdauer, \gls{soa} genannt, welche $1000$, $1333$, $1666$ oder $2000$ ms betrug, wurde der imperative Reiz, ein \enquote{+}, eingeblendet. Die \glspl{vp} wurden angewiesen, mit dem Zeigefinger ihrer dominanten Hand so rasch als möglich auf die vorgesehene Antworttaste zu drücken. Bei einer Antwortabgabe nach Einblenden des imperativen Reizes folgte ein Ton. Bei einer Antwortabgabe vor Einblenden des imperativen Reizes folgte kein Ton. In beiden Fällen führte eine Antwortabgabe zur Ausblendung der Stimuli und zum Start des nächsten Durchganges.

Die $1$-Bit-Bedingung unterschied sich von der $0$-Bit-Bedingung in der Anzahl dargebotener Rechtecke und der Tonabgabe. Der imperative Reiz trat im linken oder im rechten Rechteck auf. Die \glspl{vp} erhielten die Anweisung, beim Auftreten des imperativen Reizes im linken Rechteck mit ihrem linken Zeigefinger und beim Auftreten des imperativen Reizes im rechten Rechteck mit ihrem rechten Zeigefinger so rasch als möglich auf die dem jeweiligen Finger zugewiesene Antworttaste zu drücken. Bei einer korrekten Antwortabgabe nach Einblendung des imperativen Reizes folgte ein Ton. Bei einer Antwortabgabe vor Einblendung des imperativen Reizes oder bei einer falschen Antwortabgabe folgte kein Ton.

Die $2$-Bit-Bedingung unterschied sich von der $1$-Bit-Bedingung lediglich in der Anzahl präsentierter Rechtecke. Der imperative Reiz trat entweder im oberen linken, unteren linken, oberen rechten oder unteren rechten Rechteck auf. Die \glspl{vp} wurden angewiesen, beim Auftreten des imperativen Reizes im oberen linken Rechteck mit ihrem linken Mittelfinger, beim Auftreten des imperativen Reizes im unteren linken Rechteck mit ihrem linken Zeigefinger,  beim Auftreten des imperativen Reizes im oberen rechten Rechteck mit ihrem rechten Mittelfinger und beim Auftreten des imperativen Reizes im unteren rechten Rechteck mit ihrem rechten Zeigefinger so rasch als möglich auf die dem jeweiligen Finger zugewiesene Antworttaste zu drücken.

Die $2.58$-Bit-Bedingung unterschied sich von der $2$-Bit-Bedingung nur in der Anzahl präsentierter Rechtecke. Der imperative Reiz trat entweder im oberen äusseren linken, oberen inneren linken, unteren linken, oberen äusseren rechten, oberen inneren rechten oder unteren rechten Rechteck auf. Die \glspl{vp} wurden angewiesen, beim Auftreten des imperativen Reizes im oberen äusseren linken Rechteck mit ihrem linken Ringfinger, beim Auftreten des imperativen Reizes im oberen inneren linken Rechteck mit ihrem linken Mittelfinger, beim Auftreten des imperativen Reizes im unteren linken Rechteck mit ihrem linken Zeigefinger, beim Auftreten des imperativen Reizes im oberen äusseren Rechteck mit ihrem rechten Ringfinger, beim Auftreten des imperativen Reizes oberen inneren rechten Rechteck mit ihrem rechten Mittelfinger und beim Auftreten des imperativen Reizes im unteren rechten Rechteck mit ihrem rechten Zeigefinger so rasch als möglich auf die dem jeweiligen Finger zugewiesene Antworttaste zu drücken.

Die Bedingungen wurden von allen \glspl{vp} in aufsteigender Reihenfolge ($0$-, $1$-, $2$-, $2.58$-Bit-Bedingung) bearbeitet. Jeder Bedingung gingen acht  Übungsdurchgänge voraus, damit sich die \glspl{vp} mit der Art der Stimuluspräsentation, der Antworteingabe und dem Ton vertraut machen konnten. 
Der imperative Reiz trat in der $1$-, $2$- und $2.58$-Bit-Bedingung für alle \glspl{vp} in einer pseudorandomisierten Abfolge mit der identischen, ausbalancierten \gls{soa} am identischen, über die $32$~Durchgänge der Bedingungen ausbalancierten Ort auf. Insgesamt dauerte die Aufgabe etwa $15$~Minuten. 

Pro Bedingung wurde für jede \gls{vp} der Mittelwert und die Standardabweichung aller korrekten Antworten bestimmt, die zwischen $100$ und $2500$~ms lagen. Basierend auf diesen Berechnungen wurden für jede \gls{vp} in jeder Bedingung diejenigen Durchgänge entfernt, welche eine \gls{rz} $\geq$ \gls{m} $+\,3\,\times$ \gls{sd} aufwiesen. Nach dieser intraindividuellen Ausreisserkontrolle wurden die verbliebenen Durchgänge innerhalb einer Bedingung gemittelt und für jede \gls{vp} als Leistungsmass der Bedingung der \gls{ha} verwendet.


\section{Erfassung der psychometrischen Intelligenz \label{sec:Erfassung_der_psychometrischen_Intelligenz}}

\glsunset{bist} % see http://tex.stackexchange.com/questions/30167/suppress-the-glossary-expansion-at-first-occurance
\glsunset{bism}

Psychometrische Intelligenz wurde mit einer modifizierten Kurzversion des \acrlong{bist}s \citep[\gls{bist};][]{Jaeger1997} erfasst. Die fähigkeitstheoretische Grundlage des Tests ist das integrativ konzipierte bimodale und hierarchische \acrlong{bism} (\gls{bism}; siehe \autoref{fig:bis_model}) von \citet{Jaeger1984}.

\begin{figure}[b]
	\centering
	\begin{adjustbox}{width=.9\textwidth}
		\begin{tikzpicture}
		[scale=1, font=\sffamily, inner sep=0pt]
		
		\draw[dashed]	(0, 0) -- (4, 6) -- (7, 1.5) -- (3, -4.5) -- (0, 0);
		
		\draw[dashed]	(1, 1.5) -- (4, -3);
		\draw[dashed]	(2, 3) -- (5, -1.5);
		\draw[dashed]	(3, 4.5) -- (6, 0);
		
		\draw[dashed]	(1, -1.5) -- (5, 4.5);
		\draw[dashed]	(2, -3) -- (6, 3);
		
		\draw			(0, 6.6) -- (1, 7) -- (6, 7) -- (7, 6.6);
		
%		\draw[draw=none] (1, 7.1) -- (6, 7.1)
%		node[pos=0.5, rotate=0, above=1]{\LARGE AI - {\textrm{\textit{g}}}\textsubscript{\tiny BIS}};
		
		\draw[draw=none] (1, 7.1) -- (6, 7.1)
		node[pos=0.5, rotate=0, above=.2]{\Large Allgemeine Intelligenz (AI)};
		
		\draw[draw=none] (0, 0) -- (4, 6)
		node[pos=0.4, rotate=56, above=1]{\LARGE{OPERATIONEN}};
		
		\draw[draw=none] (4, 6) -- (7, 1.5)
		node[pos=0.63, rotate=-56, above=1]{\LARGE{INHALTE}};
		
		
		% F content ----------------------------------------------
		\draw[draw=none] (0, -1)
		node {\LARGE{F}};
		
		\draw[draw=none] (-1, -1)
		node[above=.05]{\scriptsize Figural-}
		node[below=.05]{\scriptsize bildhaft};
		
		% V content ----------------------------------------------
		\draw[draw=none] (1, -2.5)
		node{\LARGE{V}};
		
		\draw[draw=none] (0.1, -2.5)
		node{\scriptsize Verbal};
		
		% N content ----------------------------------------------
		\draw[draw=none] (2, -4)
		node{\LARGE{N}};
		
		\draw[draw=none] (.8, -4)
		node{\scriptsize Numerisch};
		
		% B operation --------------------------------------------
		\draw[draw=none] (7, 0.5)
		node {\LARGE{B}};
		
		\draw[draw=none] (8.5, 0.5)
		node[above=.05]{\scriptsize Bearbeitungs-\hphantom{iit}}
		node[below=.05]{\scriptsize geschwindigkeit};
		
		% M operation --------------------------------------------
		\draw[draw=none] (6, -1)
		node {\LARGE{M}};
		
		\draw[draw=none] (7.5, -1)
		node{\scriptsize Merkfähigkeit};
		
		% E operation --------------------------------------------
		\draw[draw=none] (5, -2.5)
		node {\LARGE{E}};
		
		\draw[draw=none] (6.5, -2.5)
		node{\scriptsize Einfallsreichtum};
		
		% K operation --------------------------------------------
		\draw[draw=none] (4, -4)
		node {\LARGE{K}};
		
		\draw[draw=none] (5.9, -4)
		node{\scriptsize Verarbeitungskapazität};
		\end{tikzpicture}
	\end{adjustbox}
	\vspace*{.5cm}
	\caption[Das Berliner Intelligenzstrukturmodell]{Das Berliner Intelligenzstrukturmodell von \citet{Jaeger1984}.}
	\label{fig:bis_model}
\end{figure}

Als integratives Modell ist das \gls{bism} zu bezeichnen, weil \citet{Jaeger1984} bei der Konstruktion des Modells versucht hat, die Vielfalt intellektueller Leistungsformen möglichst umfassend zu repräsentieren.
Bimodal ist das \gls{bism}, weil das Modell zwei Modalitäten aufweist, unter welchen Leistungen und Fähigkeiten klassifiziert werden können. 
Das \gls{bism} trennt dabei zwischen sogenannten Operationen und Inhalten. Innerhalb der Modalität Operationen werden die vier Fähigkeitsbündel Verarbeitungskapazität, Bearbeitungsgeschwindigkeit, Merkfähigkeit und Einfallsreichtum unterschieden. 
\gls{k} steht für die Fähigkeit, komplexe Informationen von Aufgaben zu verarbeiten, die nicht auf Anhieb zu lösen sind, sondern die erst durch vielfältiges Beziehungsstiften, formallogisch exaktes Denken und sachgerechtes Beurteilen von Informationen zu lösen sind. 
\gls{b} beschreibt das Arbeitstempo, die Auffassungsleichtigkeit und die Konzentrationskraft beim Lösen von einfach strukturierten Aufgaben mit geringem Schwierigkeitsgrad. 
\gls{M} spiegelt die Fähigkeit wider, sich etwas aktiv einzuprägen, etwas kurzfristig wieder zu erkennen oder zu reproduzieren. 
\gls{e} beschreibt die Fähigkeit, flexible Ideen zu produzieren und über vielfältige Vorstellungen von Problemen zu verfügen. 
Innerhalb der Modalität Inhalte lässt sich nach \citet{Jaeger1984} sprachgebundenes Denken von zahlengebundenem Denken und anschauungsgebundenem, figural-bildhaftem Denken unterscheiden.
\Gls{v} beschreibt den Grad der Aneignung und der Verfügbarkeit des Beziehungssystems Sprache.
\Gls{n} steht für das Ausmass der Aneignung und der Verfügbarkeit des Beziehungssystems Zahlen.
\Gls{f} spiegelt die Fähigkeit wider, Aufgabenmaterial zu verarbeiten, welches bildhaftes beziehungsweise räumliches Vorstellen erfordert.

Auf höchster Hierarchiestufe des \gls{bism} steht als Integral aller sieben Fähigkeiten (\gls{k}, \gls{b}, \gls{M}, \gls{e}, \gls{v}, \gls{n} und \gls{f}) die \gls{ai}. Die \gls{ai} und die Fähigkeiten unterscheiden sich aber lediglich im Differenzierungsgrad. \gls{ai} bildet Intelligenzleistungen gemäss \citet{Jaeger1984} aus grosser Distanz ab, während die sieben Fähigkeiten auf der Ebene darunter Intelligenzleistungen aus geringerer Distanz mit feinerem Auflösungsgrad abbilden. Untersuchungen zum \gls{bism} konnten die postulierte Struktur des \gls{bist}s replizieren  und Zusammenhänge mit anderen Intelligenzmodellen wie denjenigen von \citet{Cattell1971}  oder von \citet{Carroll1993} herstellen \citep{Bucik1996, Beauducel2002, Suess2002}.

Die von \citet{Jaeger1997} vorgeschlagene Kurzversion des \gls{bist}s enthält $15$ Subtests. Die Operationen \gls{b}, \gls{M} und \gls{e} werden darin mit je einem Subtest pro Inhalt erfasst, wobei \gls{k} mit zwei Subtests pro Inhalt erfasst wird. Bei der Modellierung der Daten mittels Strukturgleichungsmodellen hätte dies bei der vorliegenden Arbeit zu einer Überrepräsentation von \gls{k} im \gls{gfaktor} geführt. Um dies zu vermeiden, wurden die Operationen \gls{b} und \gls{M} um je einen Subtest pro Inhalt angereichert. Grundlage für die Auswahl der Subtests bildeten die Erkenntnisse von \citet{Wicki2014}, wobei bei der Entscheidung über die Aufnahme der Subtests ökonomische (Bearbeitungszeit der Subtests) und teststatistische (Trennschärfe und Reliabilität der Subtests)  Gesichtspunkte berücksichtigt wurden. Die Kurzversion von \citet{Jaeger1997} wurde mit folgenden Subtests ergänzt: Klassifizieren von Wörtern, Old English, Rechen-Zeichen, Wege-Erinnern, Worte Merken und Zweistellige Zahlen. 
\citet{Wicki2014} berichtet für diese modifizierte Kurzversion für die Operationen \gls{k}, \gls{b} und \gls{M} interne Konsistenzen von Cronbachs $\alpha=.61-.73$ und Konstruktreliabilitäten, gemessen mit \citeauthor{McDonald1999}\textcolor{blue}{s} \citeyearpar{McDonald1999} Omegakoeffizienten, von $\Omega = .58-.64$.
Auf Subtests der Operation \gls{e} wurde gänzlich verzichtet, weil zum einen unklar ist, wie Einfallsreichtum und Intelligenz zusammenhängen \citep{Kim2005} und zum anderen weil \citet{Jaeger1997} unbefriedigende Objektivitätswerte berichten. 
Alle eingesetzten Subtests, deren Beschreibung sowie Zuordnung zu den jeweiligen Operationen und Inhalte sind \autoref{tab:bis_subtest_description} zu entnehmen.




\begin{sidewaystable}
	\captionsetup{labelsep = none}
	\caption[Die verwendeten Subtests des \gls{bist}s]{\newline  \textit{Beschreibung und Reihenfolge der eingesetzten Subtests des \gls{bist}s} \vspace{.2cm}}
	\label{tab:bis_subtest_description}
	\begin{adjustbox}{width=\textwidth,totalheight=.9\textheight,keepaspectratio}
		\begin{threeparttable}
			\begin{tabular}{l l c c c c p{.0001cm} c c c p{20cm}}
				\hline
					&		&		& \multicolumn{3}{c}{Operation}	&	&	\multicolumn{3}{c}{Inhalt}	&		\\
				\cline{4-6}
				\cline{8-10}
				\multicolumn{1}{c}{Nr.}	&	\multicolumn{1}{c}{Name}	&	\multicolumn{1}{c}{Abkürzung}	&		K	&	B	&	M		&	&		V	&	N	&	F		&	\multicolumn{1}{c}{Beschreibung}	\\
				
				\hline
				1				&	Unvollständige Wörter*	&	UW			&&	\checkmark	&&&\checkmark&&& In vorgegebenen Wörtern fehlen einige Buchstaben, welche zu ergänzen sind (z. B. F\_scher)	\\
				2				&	Orientierungs-Gedächtnis	&	OG		&&&	\checkmark	&&&&\checkmark& Auf einem Stadtplanausschnitt markierte Gebäude müssen eingeprägt und unmittelbar danach wiedergegeben werden\\
				3				&	Zahlenreihen			&	ZN			&	\checkmark	&&&&&\checkmark&& Nach bestimmten Regeln aufgebaute Zahlenreihen sind um ein weiteres Glied zu ergänzen (z. B. 2 5 8 11 14 17 ?)\\
				4				&	Analogien				&	AN			&	\checkmark	&&&&&&\checkmark& Analogien mit Form $A:B=C:\,?$ müssen ergänzt werden, wobei die Analogien aus geometrischen Formen bestehen\\
				5				&	X-Grösser				&	XG			&&	\checkmark	&&&&\checkmark&& Zahlen, die um $3$ grösser sind als die unmittelbar vorangegangene Zahl müssen so schnell wie möglich durchgestrichen werden (z. B. 18 20 24 \cancel{27} 13 18 \cancel{21} \ldots)\\
				6				&	Wortanalogien			&	WA			&	\checkmark	&&&&\checkmark&&& Wortanalogien der Form \enquote{Huhn zu Küken} wie \enquote{Kuh zu ?} müssen vervollständigt werden\\
				7				&	Zahlenpaare				&	ZP			&&&	\checkmark	&&&\checkmark&& Zahlenpaare der Form 71 -- 918 sind einzuprägen. Das jeweils zweite Glied ist anschliessend unter vier Distraktoren zu identifizieren\\
				8				&	Tatsache-Meinung		&	TM			&	\checkmark	&&&&\checkmark&&& Sätze müssen daraufhin geprüft werden, ob sie eher eine Tatsache oder eher eine Meinung wiedergeben\\
				9				&	Buchstaben-Durchstreichen&	BD			&&	\checkmark	&&&&&\checkmark& Alle \enquote{x} müssen in Zeilen von Buchstaben durchgestrichen werden (z. B. sys\cancel{x}kdihj\cancel{x}\ldots)\\
				10				&	Schätzen				&	SC			&	\checkmark	&&&&&\checkmark&& Rechenaufgaben der Form $118492-3684-2106-4768=\,?$ müssen durch einfache rechnerische Überlegungen geschätzt bzw. gelöst werden\\
				11				&	Sinnvoller Text			&	ST			&&&	\checkmark	&&\checkmark&&& Verbale Detailangaben in einem Text sind einzuprägen und unmittelbar danach zu reproduzieren\\
				12				&	Charkow					&	CH			&	\checkmark	&&&&&&\checkmark& Eine Folge von Strichzeichnungen, die nach einer bestimmten Regel aufgebaut ist, ist um die beiden folgenden Glieder zu ergänzen\\
				13				&	Teil-Ganzes				&	TG			&&	\checkmark	&&&\checkmark&&& In Wortlisten sind zwei aufeinander folgende Wörter, die in der Beziehung Ganzes/zugehöriger Teil zueinander stehen zu markieren (z. B. Baum, \cancel{Blatt}, Stein, Haus, \cancel{Dach}, \ldots)\\
				14				&	Rechen--Zeichen			&	RZ			&&	\checkmark	&&&&\checkmark&& In  einfachen vorgegebenen Gleichungen stehen anstelle von Plus- oder Minuszeichen leere Kästchen. Die richtigen Rechenzeichen sind einzutragen\\
				15				&	Worte merken			&	WM			&&&	\checkmark	&&\checkmark&&& Eine Liste von Wörtern ist einzuprägen und unmittelbar danach in beliebiger Reihenfolge zu reproduzieren\\ 
				16				&	Klassifizieren von Wörtern&	KW			&&	\checkmark	&&&\checkmark&&& In Spalten von Wörtern sind alle Worte, die Pflanzen bezeichnen, durchzustreichen\\
				17				&	Zweistellige Zahlen		&	ZZ			&&&	\checkmark	&&&\checkmark&& Eine Reihe zweistelliger Zahlen ist einzuprägen und unmittelbar danach in beliebiger Reihenfolge zu reproduzieren\\
				18				&	Old English				&	OE			&&	\checkmark	&&&&&\checkmark& In Buchstabenreihen sind alle in einem vorgegebenen Schrifttyp gedruckten Buchstaben durchzustreichen\\
				19				&	Wege--Erinnern			&	WE			&&&	\checkmark	&&&&\checkmark& Ein in einem Stadtplanausschnitt eingezeichneter Weg ist einzuprägen und unmittelbar danach zu reproduzieren\\
				
				\hline
			\end{tabular}
			
			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkungen.} K~=~Verarbeitungskapazität; B~=~Bearbeitungsgeschwindigkeit; M~=~Merkfähigkeit; V~=~verbal; N~=~numerisch; F~=~figural-bildhaft.\\
				{$^*$}Der Subtest UW wurde als Aufwärmaufgabe verwendet und floss nicht in die Auswertung mit ein.
			\end{tablenotes}
		\end{threeparttable}
	\end{adjustbox}
\end{sidewaystable}

Die $19$ Subtests wurden den \glspl{vp} nach der in \autoref{tab:bis_subtest_description} aufgeführten Reihenfolge vorgelegt und gemäss dem Manual des \gls{bist}s instruiert. 
Die Bearbeitung der Subtests dauerte insgesamt $50$ Minuten.
Die Aufwärmaufgabe \gls{uw} wurde nicht ausgewertet. Die Rohwerte der restlichen $18$~Subtests wurden \textit{z}-standardisiert. 
Für die Beantwortung der Fragestellungen 1 und 2 wurden alle $18$~\textit{z}-stand\-ard\-isier\-ten Subtests gemittelt. Dadurch resultierte für jede \glspl{vp} ein \textit{z}-standardisiertes Mittel ihrer Leistung. 
Um für die Beantwortung der Fragestellungen 3, 4 und 5 einen \gls{gfaktor} zu bilden, wurden die $18$~\textit{z}-standardisierten Subtests innerhalb ihrer zugehörigen Operation gemittelt. Damit flossen in jede Operation (\gls{k}, \gls{b} und \gls{M}) zwei Subtests aus dem Bereich \gls{v}, zwei Subtests aus dem Bereich \gls{n} und zwei Subtests aus dem Bereich \gls{f} (insgesamt sechs Subtests) ein. Der \gls{gfaktor} wurde anschliessend aus den drei gemittelten \textit{z}-Werten der Operationen \gls{k}, \gls{b} und \gls{M} abgeleitet.


\section{Weitere Instrumente}

Im Rahmen der Untersuchung wurden den \glspl{vp} Fragebögen und weitere Com\-put\-er-Auf\-gaben zur Bearbeitung vorgelegt. Sie sind für die Fragestellungen dieser Arbeit nicht relevant und werden deshalb im folgenden Abschnitt nur kurz beschrieben.


\subsection{Fragebögen}

\subsubsection*{Persönliche Angaben}
Die Erfassung persönlicher Angaben fand in zwei Teilen statt. In einem ersten Teil machten die \glspl{vp} schriftlich Angaben zu ihrer Muttersprache, Seh- und Hörfähigkeit, ihren chronischen Krankheiten und ihrem Medikamenten- sowie Nikotinkonsum. In einem zweiten Teil machten sie computergestützt Angaben zu ihrem Alter, Geschlecht, Bildungsniveau, Koffeinkonsum,  Videospielhäufigkeit, Musikinstrumenterfahrung und Vertrautheit mit dem Zehnfingersystem beim Computerschreiben.


\subsubsection*{Kurzform der deutschen Übersetzung des revidierten \gls{epq-rk}}
Die \glspl{vp} haben  computergestützt die Kurzform der deutschen Übersetzung des \gls{epq-rk} von \citet{Ruch1999} bearbeitet. Der Fragebogen enthält insgesamt $50$~Fragen, darunter $14$~Items zur Erfassung von Psychotizismus, $12$~Items zur Erfassung von Extraversion, $12$~Items zur Erfassung von Neurotizismus und $12$~Items zur Erfassung der individuellen Neigung, sozial erwünschte Antworten abzugben.

\subsubsection*{Deutsche Übersetzung des \gls{dii}}
Die deutsche Übersetzung des \gls{dii} stammt von \citet{Kuhmann1996} und beinhaltet insgesamt $23$~Items, darunter $11$~Items zur Erfassung der funktionalen Impulsivität und  $12$~Items zur Erfassung der dysfunktionalen Impulsivität. Der Fragebogen wurde von den \glspl{vp} computergestützt bearbeitet.

\subsection{Zeitverarbeitungsaufgaben}


\subsubsection*{Zeitdauerdiskrimination im Millisekundenbereich mit gefüllten und leeren Intervallen}

Angelehnt an die Versuchsanordnung von \citet{Stauffer2011} bekamen die \glspl{vp} über Lautsprecher hintereinander eine Standardtondauer und eine variable Vergleichstondauer dargeboten. Danach mussten die \glspl{vp} jeweils mit einem Tastendruck entscheiden, ob die erste oder die zweite Tondauer länger war. Bei einer korrekten Antwort verringerte sich die Differenz zwischen der Standard- und der Vergleichstondauer und bei einer falschen Antwort erhöhte sich diese Differenz. Die Aufgabe wurde einmal mit gefüllten Zeitintervallen (das heisst mit jeweils zwei kontinuierlichen Tönen) und einmal mit leeren Zeitintervallen (das heisst die Töne waren durch einen Klick am Anfang und einen Klick am Schluss des Intervalls gekennzeichnet) durchgeführt. Diese Aufgaben dauerte insgesamt etwa $15$ Minuten.


\subsubsection*{Zeitgeneralisation im Millisekundenbereich}

Die Aufgabe der \glspl{vp} war es, in einer Lernphase die über Lautsprecher fünf Mal präsentierte Standardtonlänge einzuprägen. Danach folgte die eigentliche Aufgabe: Es wurden in zufälliger Reihenfolge die Standardtonlänge und sechs Vergleichstonlängen präsentiert. Die \glspl{vp} mussten nach jeder Tonlänge mit einem Tastendruck entscheiden, ob die präsentierte Tonlänge von gleicher Länge war wie die Standardtonlänge oder nicht. Diese Aufgabe dauerte insgesamt etwa $5$ Minuten \citep[in Anlehnung an][]{Stauffer2011}.

\subsubsection*{Rhythmuswahrnehmung}

Die \glspl{vp} hatten die Aufgabe, sechs über Lautsprecher in unregelmässigen Abständen präsentierte Töne von jeweils $3$~ms Dauer auf rhythmische Darbietung hin zu beurteilen. 
Gaben die \glspl{vp} an, den Rhythmus als regelmässig wahrgenommen zu haben, wurde die Abweichung des Interstimulusintervalls beim nächsten Durchgang erhöht. Gaben die \glspl{vp} an, den Rhythmus als unregelmässig wahrgenommen zu haben, wurde die Abweichung des Interstimulusintervalls beim nächsten Durchgang verringert.
Die Aufgabe dauerte insgesamt etwa $5$ Minuten \citep[siehe][]{Stauffer2011}.

\subsection{Inspection-Time-Aufgabe}

Die auf einem Computermonitor präsentierten Stimuli der \gls{ita} \citep{Vickers1972} bestanden aus zwei ungleich langen vertikalen Linien, die an ihren oberen Enden mit einer horizontalen Linie verbunden waren. Bei jedem Durchgang wurde die kürzere vertikale Linie zufällig links oder rechts präsentiert und nach der Darbietungszeit mit einer Pi-förmigen Abbildung, die gleich lange vertikale Linien aufwies, maskiert. Die Aufgabe der \glspl{vp} bestand darin anzugeben, ob die linke oder die rechte vertikale Linie länger war. Eine korrekte Antwort verringerte und eine falsche Antwort erhöhte die Darbietungszeit des nächsten Stimulus. Die Aufgabe dauerte insgesamt etwa $5$ Minuten.


\section{Untersuchungsablauf \label{sec:Versuchsablauf}}

Die Untersuchung wurde vor Datenerhebungsbeginn von der Ethikkomission der philosophisch-humanwissenschaftlichen Fakultät der Universität Bern gutgeheissen. Die \glspl{vp} nahmen an zwei Sitzungen teil, welche $2$ bis $14$~Tage voneinander getrennt waren. Zwei \glspl{vp} hatten krankheitsbedingt ein längeres Intervall zwischen den beiden Sitzungen ($18$ und $30$ Tage).

\subsection{Sitzung 1}

Die \glspl{vp} wurden in Gruppen von zwei bis sechs Personen in einem $18\,\textnormal{m}^2$ grossen Raum an Einzeltische gesetzt. Die Tische waren so weit voneinander entfernt, dass die \glspl{vp} nicht durch den Nachbarn gestört werden oder abschreiben konnten. 
Ohne die Fragestellungen der Arbeit zu offenbaren, klärte der Versuchsleiter\footnote{In dieser Arbeit wird der Einfachheit halber nur die männliche Form verwendet. Die weibliche Form ist selbstverständlich immer mit eingeschlossen.} die \glspl{vp} über den Zweck der Untersuchung auf, informierte sie über den Ablauf der bevorstehenden Sitzung und nahm die Einverständniserklärungen der \glspl{vp} entgegen. Danach wurden der Reihenfolge nach folgende Daten erhoben und Instrumente eingesetzt:

\begin{enumerate}
	\item Persönliche Angaben Teil 1
	\item \acrlong{bist} (\gls{bist})
	\item Persönliche Angaben Teil 2
	\item \acrlong{epq-rk} (\gls{epq-rk})
	\item \acrlong{dii} (\gls{dii})
\end{enumerate}

\noindent Diese erste Sitzung dauerte insgesamt etwa 90 Minuten.

\subsection{Sitzung 2}
Die zweite Sitzung fand als Einzeltestung in einer $5\,\textnormal{m}^2$ grossen, schallgedämpften Kabine statt. 
Der Versuchsleiter informierte die \glspl{vp} über den Ablauf der bevorstehenden Sitzung und legte ihnen am Computer der Reihenfolge nach folgende Aufgaben vor:

\begin{enumerate}
	\item	\gls{ssauf}
	\item	Die fünf Aufgaben
			\begin{dinglist}{43}
				\item \gls{ha}
				\item Zeitdauerdiskrimination im Millisekundenbereich mit gefüllten Intervallen
				\item Zeitdauerdiskrimination im Millisekundenbereich mit leeren Intervallen
				\item Zeitgeneralisation im Millisekundenbereich
				\item Rhythmuswahrnehmung
			\end{dinglist}
			wurden über alle \glspl{vp} hinweg vollständig permutiert, was in $5\,! = 120$ unterschiedlichen Reihenfolgen resultierte. Nach $120$~\glspl{vp} wurden die Reihenfolgen wiederholt, das heisst  \gls{vp} $121$ bearbeitete die Aufgaben in der gleichen Reihenfolge wie \gls{vp} 1, \gls{vp} $122$ bearbeitete die Aufgaben in der gleichen Reihenfolge wie \gls{vp} 2 und so weiter.
	\item	\gls{ita}
\end{enumerate}

Nach der letzten Aufgabe wurden die \glspl{vp} vollständig über das Ziel der Untersuchung aufgeklärt und entlöhnt. Diese zweite Sitzung dauerte inklusive einer fünfminütigen Pause nach 50 Minuten insgesamt etwa 120 Minuten.



%\clearpage
\section{Statistische Analyse \label{sec:StatistischeAnalyse}}

Alle Berechnungen wurden in R \citep{R} durchgeführt, dessen Basisfunktionen mit folgenden Paketen ergänzt wurde:
{coin} \citep{coin},
%colorspace \citep{colorspace},
dplyr \citep{dplyr},
effsize \citep{effsize},
ez \citep{ez},
ggplot2 \citep{ggplot2},
lavaan \citep{lavaan},
lm.beta \citep{lm.beta},
lmSupport \citep{lmSupport},
MASS \citep{MASS},
Metrics \citep{Metrics},		% für RMSE. Muss aufgeführt werden.
multcomp \citep{multcomp},
nlme \citep{nlme},
nlstools \citep{nlstools},
%nortest \citep{nortest},		% wird nicht mehr benötigt, weil parametrisch gerechnet wird. Shapiro-Wilk-Test in Tabelle sollte genügen.
pacman \citep{pacman},
pbapply \citep{pbapply},
plotrix \citep{plotrix},
ppcor \citep{ppcor},
psych \citep{psych},
readxl \citep{readxl},
reshape2 \citep{reshape2},
rprime \citep{rprime},
R.matlab \citep{R.matlab} und
semPlot \citep{semPlot}.
Als Editor diente RStudio \citep{RStudio}.

Die Fragestellungen 3, 4 und 5 wurden mittels konfirmatorischer Faktorenanalysen beantwortet. Die Güte einer konfirmatorischen Faktorenanalyse kann anhand einer Vielzahl von unterschiedlichen Kennwerten beurteilt werden, weshalb hier die für diese Arbeit wichtigen Kennwerte kurz vorgestellt werden.




\subsubsection*{\gls{cst}}

Der \gls{cst} ist ein Modelltest, der angibt, wie stark sich die theoretische, vom Modell implizierte Var\-ianz-Ko\-var\-ianz\-ma\-trix von der empirischen Var\-ianz-Ko\-var\-ianz\-ma\-trix unterscheidet \citep{Kline2011}. Die dafür berechnete Teststatistik folgt in grossen Stichproben und unter der Voraussetzung der multivariaten Normalverteilung einer zentralen Chi-Quad\-rat-Ver\-teil\-ung und wird deshalb auch als $\upchi^2_{m}$ bezeichnet. Die Freiheitsgrade für den $\upchi^2$-Test ergeben sich aus den Freiheitsgraden des zu testenden Modells ($df_{m}$). Wenn $\upchi^2_{m}=0$ ist, stimmt die empirische Var\-ianz-Ko\-var\-ianz\-ma\-trix mit der vom Modell implizierten Varianz-Kovarianzmatrix ohne Abweichung überein und das theoretische Modell passt perfekt zu den empirischen Daten. Bildet das Modell die Daten nicht gut ab, wird $\upchi^2_{m}>0$. Liegt $\upchi^2_{m}$ über dem kritischen $\upchi^2_{df}$, sind die Abweichungen zwischen der empirischen und der theoretischen Varianz-Kovarianzmatrix grösser als durch den Stichprobenfehler erwartet, und die Nullhypothese wird verworfen. Wenn ein korrekt spezifiziertes Modell mit mehreren Zufallsstichproben geprüft wird, liegt der Erwartungswert von $\upchi^2_{m}$ bei $df_{m}$ und $\upchi^2_{m}$ würde bei einem $\upalpha$-Fehler von $5\,\%$ bei 19 von 20 Stichproben im nicht-signifikanten Bereich liegen.

Bei der Bewertung der berichteten konfirmatorischen Faktorenanalysen wird das Ergebnis des Modelltests (im Vergleich zu den weiter unten beschriebenen Kennwerten) am stärksten gewichtet. Diese Art der Modellbeurteilung entspricht der Vorstellung von Karl Jöreskog \citep[][S. 10]{Soerbom2001}, der sich dafür aussprach alle andere Kennwerte weniger zu gewichten \citep[siehe auch][]{Hayduk2007}.

\subsubsection*{\gls{cfi}}
Der \gls{cfi} lässt sich der Klasse der inkrementellen Fit Indizes zuordnen und wurde von \citet{Bentler1990} entworfen. Die Formel lautet

$$ \textnormal{CFI} = 1 - \frac{\upchi^2_{m}-df_{m}}{\upchi^2_{b}-df_{b}} $$

\noindent Im Zähler wird $df_{m}$ von $\upchi^2_{m}$ subtrahiert. Im Nenner des Bruchs wird die gleiche Differenz mit den Werten des Baseline Modells ($df_{b}$ und $\upchi^2_{b}$) gebildet.
Das Baseline-Modell nimmt keinerlei Zusammenhänge zwischen den manifesten Variablen an und wird deshalb auch als \enquote{independence model} bezeichnet. Zieht man den beschriebenen Quotienten von Eins ab, ergibt sich ein Mass für die relative Verbesserung des angenommenen Modells gegenüber dem Baseline-Modell. Aus der Formel folgt, dass \gls{cfi} $= 1$ ergibt, wenn $\upchi^2_{m} \leq df_{m}$ ist. Das bedeutet aber auch, dass ein \gls{cfi} von $1$ nicht mit einem perfekten Fit ($\upchi^2_{m} = 0$) gleichzusetzen ist. Ein \gls{cfi} von $.95$ ist laut \citet{Hu1999} als guter Fit zu bezeichnen.

\subsubsection*{\gls{rmsea}}
Die Anzahl Freiheitsgrade eines Modells geben an, auf wie vielen Dimensionen die empirischen Daten vom Modell abweichen können. Der RMSEA \citep{Steiger1990} ist ein Fit Index, der die durchschnittliche Abweichung des Modells pro mögliche Dimension der Abweichung angibt. Die Formel lautet

$$ \textnormal{RMSEA} = \sqrt{ \frac{\upchi^2_{m}-df_{m}}{df_{m}(N-1)} } $$

\noindent Wie beim \gls{cfi} ergibt sich der beste Wert, wenn $\upchi^2_{m} \leq df_{m}$ ist (dann ist \gls{rmsea} $= 0$). Das bedeutet jedoch wie beim \gls{cfi} auch, dass ein \gls{rmsea} von Null keinen perfekten Modell-Fit ($\upchi^2_{m} = 0$) ergibt. Im Nenner wird $df_{m}$ mit der Stichprobengrösse minus Eins multipliziert. Dies führt dazu, dass der \gls{rmsea} bei Modellen mit vielen Freiheitsgraden und grossen Stichproben kleiner wird. Ein \gls{rmsea} $\leq.08$ deutet laut \citet{Browne1993} auf einen guten Modell-Fit hin.

\subsubsection*{\gls{srmr}}
Das \gls{srmr} ist ein Mass dafür, wie hoch die durchschnittlichen Korrelationsresiduen der manifesten Variablen sind \citep{Kline2011}. Anders formuliert gibt das \gls{srmr} den durchschnittlichen Zusammenhang der manifesten Variablen wieder, welcher nicht durch das Modell erklärt werden kann. Das \gls{srmr} sollte möglichst nahe bei Null zu liegen kommen, was bedeutet, dass das theoretische Modell die empirische Var\-ianz-Ko\-var\-ianz\-ma\-trix angemessen abbildet. Gemäss \citet{Hu1999} kann ein \gls{srmr} $\leq.08$ als guter Modell-Fit interpretiert werden.











% =================================================================
% R E S U L T S
% =================================================================
\chapter{Resultate \label{cha:Resultate}}

\section{Deskriptiv- und Inferenzstatistik \label{sec:Deskriptive_Statistik}}

\subsection{Spatial-Suppression-Aufgabe \label{subsec:SSres}}

Die Mittelwerte, Verteilungsangaben und Reliabilitäten der Bedingungen sind in \autoref{tab:spatial_suppression_descriptives} abgetragen. 
Die Splithalf-Reliabilitäten der vier Bedingungen fielen mit $r_{tt}=.96$ ähnlich hoch aus wie bei \citeauthor{Melnick2013} (\citeyear{Melnick2013}; $r_{tt}=.99$).
Die Streudiagramme der $82\,\%$-Er\-ken\-nungs\-schwel\-len sind in \autoref{fig:spatial_suppression_scatterplot} zu sehen.

\begin{table}[b]
	\centering
%	\captionsetup{font = small}
	\caption[Deskriptive Angaben zu den $82\,\%$-Erkennungsschwellen in der \gls{ssauf}]{\newline \textit{Deskriptive Angaben zu den $82\,\%$-Erkennungsschwellen der \gls{ssauf} in Millisekunden (Mittelwert, Standardabweichung, Minimum, Maximum) sowie Kennwerte zur Verteilungsform und der Reliabilität der Daten} \vspace{.2cm}}
	\label{tab:spatial_suppression_descriptives}
	\begin{adjustbox}{width=1\textwidth}
		\begin{threeparttable}
			\begin{tabular}{
					l
					S[table-format = 3.0]
					S[table-format = 2.0]
					S[table-format = 2.0]
					S[table-format = 3.0]
					S[table-format = 1.2]
					S[table-format = 1.2]
					S[table-format = <0.3, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
				}
				\hline
				\multicolumn{1}{c}{Bedingung} 		&	{\textit{M}}	&	\textit{SD}	&	{Min}	&	Max 	&	\textnormal{Schiefe}	&	\textnormal{Kurtosis}  &{S-W \textit{p}-Wert}& {$r_{tt}$}\\
				\hline
				$1.8^{\circ}$	&	82			&	28			&	31		&	216		&	-0.25	&	0.19	& 		.39		&	.96	\\
				$3.6^{\circ}$	&	89			&	31			&	37		&	282		&	0.02	&	0.80	& 		.03		&	.96	\\
				$5.4^{\circ}$	&	109			&	40			&	45		&	422		&	0.73	&	1.78	& 		<.001	&	.96	\\
				$7.2^{\circ}$	&	136			&	60			&	61		&	705		&	1.14	&	1.86	& 		<.001	&	.96	\\
				\hline
			\end{tabular}%
			%}
			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkungen.} Min~=~Minimum; Max~=~Maximum; S-W~=~Shapiro-Wilk-Test; $r_{tt}$~=~nach der Odd-Even-Methode berechnete, mit der Spearman-Brown-Formel \citep[][]{Brown1910, Spearman1910} korrigierte Splithalf-Reliabilität.
			\end{tablenotes}
		\end{threeparttable}
	\end{adjustbox}
\end{table}


\begin{figure}[p]
	\centering
	\begin{adjustbox}{width=1\textwidth} 
		\input{tikzDevice/spatial_suppression_scatterplot.tex}
	\end{adjustbox}
	\caption[Streudiagramme der $82\,\%$-Erkennungsschwellen in der \gls{ssauf}]{Streudiagramme der $82\,\%$-Erkennungsschwellen für horizontale Bewegung in der \gls{ssauf}. Die horizontale Linie kennzeichnet jeweils den Mittelwert innerhalb einer Bedingung (vgl. \autoref{tab:spatial_suppression_descriptives}). Siehe \autoref{cha:Anhang_A} für eine Beschreibung der Ausreisserkontrolle. Vp = Versuchsperson.}
	\label{fig:spatial_suppression_scatterplot}
\end{figure}

Als Erstes wurde geprüft, ob die experimentelle Manipulation (die Mustergrösse) einen Einfluss auf die abhängige Variable (die $82\,\%$-Er\-ken\-nungs\-schwel\-le) ausübte. Dafür wurde eine einfaktorielle Varianzanalyse mit Messwiederholung\footnote{Die Abweichung der Daten von der Normalverteilung (siehe Kennwerte zur Verteilung in \autoref{tab:spatial_suppression_descriptives}) erforderten eigentlich verteilungsfreie Analyseverfahren. Da die Ergebnisse dieser nonparametrischen Analyseverfahren aber nicht bedeutend von den mit parametrischen Verfahren ermittelten Ergebnissen abwichen, werden im Folgenden die Ergebnisse der traditionellen (parametrischen) Verfahren berichtet. Siehe \autoref{cha:Anhang_B} für die Analyse der Aufgaben mittels nonparametrischer Verfahren.}
gerechnet. Weil Sphärizität gemäss einem Mauchly-Test nicht gegeben war, $\upchi^2(5)=202.12$, $p<.001$, wurden die Freiheitsgrade des \textit{F}-Tests mit der Greenhouse-Geisser-Methode korrigiert ($\hat{\varepsilon}=.55$).
Der \textit{F}-Test hat ergeben, dass die Unterschiede zwischen den Bedingungsmittelwerten signifikant von 0 abwichen, $F(1.65,\,290.40)=275.26$, $p<.001$, $\eta_{G}^2=.27$. Der Effekt der Mustergrösse auf die $82\,\%$-Erkennungsschwelle konnte dabei gemäss generalisiertem $\eta_{G}^2$ \citep{Olejnik2003} als gross bezeichnet werden \citep[S. 383]{Bakeman2005}.
Um zu erfahren, ob sich alle oder nur bestimmte Mittelwertpaare signifikant voneinander unterschieden, wurden post hoc alle Mittelwerte miteinander verglichen.
Tukey-Tests haben gezeigt, dass sich alle Mittelwertpaare signifikant voneinander unterschieden (alle \textit{p}s $<.001$).
Die $82\,\%$-Er\-ken\-nungs\-schwel\-len der \glspl{vp} erhöhten sich folglich mit zunehmender Mustergrösse signifikant.
Die Effektstärken für die Mittelwertsunterschiede wurden mit Cohens \textit{d} für abhängige Stichproben \citep{Gibbons1993} bestimmt. 
Dabei hat sich gezeigt, dass die Effektstärken im mittleren und hohen Bereich \citep[][S. 40]{Cohen1988} lagen (siehe \autoref{tab:spatial_suppression_effect_sizes}). 

\begin{table}[htbp]
	\centering
	\setlength{\tabcolsep}{10pt}
	\captionsetup{labelsep = none}
	\caption[Effektstärken für die Mittelwertsunterschiede in der \gls{ssauf}]{\newline \textit{Effektstärken (Cohens \textit{d} für abhängige Stichproben) der Mittelwertsunterschiede in der \gls{ssauf}} \vspace{.2cm}}
	\label{tab:spatial_suppression_effect_sizes}
	\sisetup{table-number-alignment = center}
	\begin{threeparttable}
		\begin{tabular}{
				l
				S[table-format = 1.2]
				S[table-format = 1.2]
				S[table-format = 1.2]
				>{\centering\arraybackslash}p{1.2cm}
			}
			\hline
			
			\multicolumn{1}{c}{Bedingung}		&	\(1.8^{\circ}\)		&	\(3.6^{\circ}\)		&	\(5.4^{\circ}\)		\\
			\hline
			$1.8^{\circ}$	&						&						&						\\
			$3.6^{\circ}$	&	0.51				&						&						\\
			$5.4^{\circ}$	&	1.12				&	1.07				&						\\
			$7.2^{\circ}$	&	1.39				&	1.42				&	1.08					\\

			\hline
			
		\end{tabular}%
		%}
		\begin{tablenotes}[flushleft]
			\footnotesize				% font size
			\setlength\labelsep{0pt}	% no indent on second line
			\item \textit{Anmerkung}. Alle Mittelwertsunterschiede waren statistisch signifikant ($p<.001$).
		\end{tablenotes}
		
	\end{threeparttable}
\end{table}

\clearpage
Produkt-Moment-Korrelationen zwischen den vier Bedingungen der \gls{ssauf} sind in \autoref{tab:product_moment_correlations_manifest} abgetragen. Sie deuteten ausnahmslos auf stark positive Zusammenhänge zwischen den Bedingungen hin.

Der \gls{si} wies einen Mittelwert $\pm$ Standardabweichung von $0.222\,\pm\,0.160$ auf (Minimum $= -0.185$, Maximum $= 0.886$). 
Die Verteilung des \gls{si} (siehe \autoref{fig:suppression_index_density}) hatte eine Schiefe von $0.91$ und sowie Kurtosis von $1.80$ und wich damit gemäss einem Shapiro-Wilk-Test signifikant von der Normalverteilung ab ($p<.001$).

\begin{figure}[htbp]
	\centering
%	\captionsetup{font = small}
	\begin{adjustbox}{width=1\textwidth}
		\input{tikzDevice/suppression_index_density.tex}
	\end{adjustbox}
	\caption[Dichtefunktion des \gls{si}]{Dichtefunktion des \gls{si}. Der \gls{si} wurde als Differenz zwischen der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le für die Mustergrösse $7.2^{\circ}$ und der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le für die Mustergrösse $1.8^{\circ}$ gebildet. Alle Datenpunkte sind auf der x-Achse mit vertikalen Strichen markiert.}
	\label{fig:suppression_index_density}
\end{figure}

\subsection{Hick-Aufgabe}

In \autoref{fig:hick_scatterplot} sind die mittleren Reaktionszeiten aller \glspl{vp} als Streudiagramme abgebildet.
%Die mittleren Reaktionszeiten aller \glspl{vp} sind als Streudiagramme in  \autoref{fig:hick_scatterplot} zu finden.
Die Mittelwerte, Verteilungsangaben und Reliabilitäten der Bedingungen finden sich in \autoref{tab:hick_descriptives}. 

\begin{figure}[p]
	\centering
	\begin{adjustbox}{width=1\textwidth}
		\input{tikzDevice/hick_scatterplot.tex}
	\end{adjustbox}
	\caption[Streudiagramme der Reaktionszeiten in der \gls{ha}]{Streudiagramme der mittleren Reaktionszeiten in der \gls{ha}. Die horizontale Linie kennzeichnet jeweils den Mittelwert innerhalb einer Bedingung (vgl. \autoref{tab:hick_descriptives}). Siehe \autoref{subsec:hick_Versuchsablauf} für eine Beschreibung der Datenaufbereitung. Vp = Versuchsperson.}
	\label{fig:hick_scatterplot}
\end{figure}

\begin{table}[htb]
	\centering
	\captionsetup{labelsep = none}
	\caption[Deskriptive Angaben zu den Reaktionszeiten in der \gls{ha}]{\newline \textit{Deskriptive Angaben zu den mittleren Reaktionszeiten der \gls{ha} in Millisekunden (Mittelwert, Standardabweichung, Minimum, Maximum) sowie Kennwerte zur Verteilungsform und der Reliabilität der Daten} \vspace{.2cm}}
	\label{tab:hick_descriptives}
	\begin{adjustbox}{width=1\textwidth}
	\begin{threeparttable}
		
		\begin{tabular}{
				l
				S[table-format = 3.0, add-integer-zero=false]
				S[table-format = 2.0, add-integer-zero=false]
				S[table-format = 3.0, add-integer-zero=false]
				S[table-format = 3.0, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 1.2, add-integer-zero=false]
				S[table-format = <0.3, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
			}
			\hline
			\multicolumn{1}{c}{Bedingung}	& 	{\textit{M}}&{\textit{SD}}	&	{Min}	&	{Max} 	&	{\textnormal{Schiefe}}	&	{\textnormal{Kurtosis}} &	{S-W \textit{p}-Wert} & $r_{tt}$\\
			\hline
			0-bit		&	240			&	29		&	188		&	394		&	1.58	&	4.99	& 	<.001	&	.90	\\
			1-bit		&	296			&	32		&	234		&	416		&	0.94	&	1.33	& 	<.001	&	.93	\\
			2-bit		&	377			&	54		&	280		&	590		&	0.88	&	1.01	& 	<.001	&	.94	\\
			2.58-bit	&	438			&	67		&	315		&	650		&	0.82	&	0.41	& 	<.001	&	.93	\\
			\hline
		\end{tabular}%
		%}
		\begin{tablenotes}[flushleft]
			\footnotesize				% font size
			\setlength\labelsep{0pt}	% no indent on second line
			\item \textit{Anmerkungen.}  Min~=~Minimum; Max~=~Maximum; S-W~=~Shapiro-Wilk-Test; $r_{tt}$~=~nach der Odd-Even-Methode berechnete, mit der Spearman-Brown-Formel \citep[][]{Brown1910, Spearman1910} korrigierte Splithalf-Reliabilität.
		\end{tablenotes}%
	\end{threeparttable}%
	\end{adjustbox}
\end{table}

Wie bei der \gls{ssauf} wurde bei der \gls{ha} als Erstes geprüft, ob die experimentelle Manipulation (die Anzahl der Antwortalternativen) einen Einfluss auf die abhängige Variable (die Reaktionszeit) ausübte. Dafür wurde 
eine einfaktorielle Varianzanalyse mit Messwiederholung gerechnet.
Weil Sphärizität gemäss einem Mauchly-Test nicht gegeben war, $\upchi^2(5)=219.06$, $p<.001$, wurden die Freiheitsgrade des \textit{F}-Tests mit der Greenhouse-Geisser-Methode korrigiert ($\hat{\varepsilon}=.57$). Der \textit{F}-Test hat ergeben, dass die Unterschiede zwischen den Bedingungsmittelwerten signifikant von 0 abwichen, $F(1.71,\,300.96)=1434.32$, $p<.001$, $\eta_{G}^2=.71$. Der Effekt der Anzahl Antwortalternativen auf die Reaktionszeit konnte dabei gemäss generalisiertem $\eta_{G}^2$ \citep{Olejnik2003} als gross bezeichnet werden \citep[S. 383]{Bakeman2005}.
Um zu erfahren, ob sich alle oder nur bestimmte Mittelwertpaare signifikant voneinander unterschieden, wurden post hoc alle Mittelwerte miteinander verglichen.
Tukey-Tests haben gezeigt, dass sich alle Mittelwertpaare signifikant voneinander unterschieden (alle \textit{p}s $<.001$).
Die Reaktionszeiten der \glspl{vp} erhöhten sich folglich mit zunehmender Anzahl Antwortalternativen signifikant.
Die Effektstärken für die Mittelwertsunterschiede wurden mit Cohens \textit{d} für abhängige Stichproben \citep{Gibbons1993} bestimmt und lagen alle im hohen Bereich \citep[][S. 40; siehe \autoref{tab:hick_effect_sizes}]{Cohen1988}.

\begin{table}[htbp]
	\centering
	\setlength{\tabcolsep}{10pt}
	\captionsetup{labelsep = none}
	\caption[Effektstärken für die Mittelwertsunterschiede in der \gls{ha}]{\newline \textit{Effektstärken (Cohens \textit{d} für abhängige Stichproben) der Mittelwertsunterschiede in der \gls{ha}} \vspace{.2cm}}
	\label{tab:hick_effect_sizes}
	\sisetup{table-number-alignment = center}
	\begin{threeparttable}
		\begin{tabular}{
				l
				S[table-format = 1.2]
				S[table-format = 1.2]
				S[table-format = 1.2]
				>{\centering\arraybackslash}p{1.2cm}
			}
			\hline
			
			\multicolumn{1}{c}{Bedingung}	&	{0-bit}		&	{1-bit}		&	{2-bit}		\\
			\hline
			0-bit		&				&				&				\\
			1-bit		&	2.67		&				&				\\
			2-bit		&	3.13		&	2.13		&				\\
			2.58-bit	&	3.43		&	2.71		&	1.62		\\
			
			\hline
			
		\end{tabular}

		\begin{tablenotes}[flushleft]
			\footnotesize				% font size
			\setlength\labelsep{0pt}	% no indent on second line
			\item \textit{Anmerkung}. Alle Mittelwertsunterschiede waren statistisch signifikant ($p<.001$).
		\end{tablenotes}
	\end{threeparttable}
\end{table}

Produkt-Moment-Korrelationen zwischen den vier Bedingungen der \gls{ha} sind in \autoref{tab:product_moment_correlations_manifest} abgetragen. Sie deuteten auf stark positive Zusam\-men\-hänge zwischen den Bedingungen hin. 
%Die Zusammenhänge zwischen der 0-bit-, der 1-bit- und der 2-bit Bedingung waren dabei etwa gleich stark wie bei \citet{Schweizer2006a}.

\FloatBarrier
\subsection{BIS-Test \label{subsec:BIS-Test}}

Deskriptive Angaben zu den Subtests des \gls{bist}s sind in \autoref{tab:bis_descriptives} zu finden.
Wie aufgrund der Modellannahmen des \gls{bist}s zu erwarten war, liessen sich zwischen der Mehrheit der Subtests signifikante positive Zusammenhänge beobachten (siehe \autoref{tab:bis_product_correlations}). Dieser positive manifold bildete die Voraussetzung für die Beantwortung der dritten, vierten und fünften Fragestellung, bei welchen aus den Aufgaben des \gls{bist}s mit Hilfe von Faktorenanalysen ein \gls{gfaktor} extrahiert wurde.

Der \gls{zwert} des \gls{bist}s, gebildet als Mittelwert aller $18$ \textit{z}-stand\-ard\-isier\-ter Subtests, wies einen Mittelwert $\pm$ Standardabweichung von $0.02\,\pm\,0.53$ auf (Minimum $= -1.60$, Maximum $= 1.40$). Die Verteilung des \gls{zwert}s (siehe \autoref{fig:bis_zscore_density}) hatte eine negative Schiefe ($-0.02$) und eine positive Kurtosis ($0.16$), wich damit aber gemäss einem Shapiro-Wilk-Test  nicht signifikant von der Normalverteilung ab ($p=.82$).

\begin{table}[!t]
	%\flushleft
	\centering
	\captionsetup{labelsep = none}
	\caption[Deskriptive Angaben zur Anzahl richtig gelöster Items der Subtests im \gls{bist}]{\newline  \textit{Deskriptive Angaben zur Anzahl richtig gelöster Items der Subtests im \gls{bist} (Mittelwert, Standardabweichung, Minimum, Maximum) und Kennwerte zur Verteilungsform der Daten} \vspace{.2cm}}
	\label{tab:bis_descriptives}
	\begin{adjustbox}{width=.82\textwidth,keepaspectratio} %totalheight=1\textheight,
	\begin{threeparttable}
		\begin{tabular}{
				l
				S[table-format = 2.2]
				S[table-format = 2.2]
				S[table-format = 1.0]
				S[table-format = 2.0]
				S[table-format = 1.2]
				S[table-format = 1.2]
				S[table-format = < 0.3, add-integer-zero=false]
				}
			\hline

			\multicolumn{1}{c}{Subtest} &  {\textit{M}}	& {\textit{SD}}	&	{Min}	&	{Max} 	& {\textnormal{Schiefe}}	& {\textnormal{Kurtosis}} & {S-W  \textit{p}-Wert}\\
			\hline
			OG		&	15.31		&	4.82		&	3		&	27		&	-0.35				&	-0.05					& 		.03			\\
			ZN		&	3.86		&	2.44		&	0		&	9		&	0.50				&	-0.83					& 		<.001			\\
			AN		&	3.23		&	1.62		&	0		&	7		&	0.08				&	-0.41					& 		<.001			\\
			XG		&	19.45		&	6.52		&	1		&	36		&	0.14				&	0.08					& 		.05			\\
			WA		&	3.23		&	1.87		&	0		&	7		&	0.10				&	-0.71					& 		<.001			\\
			ZP		&	5.95		&	2.28		&	1		&	12		&	0.27				&	-0.12					& 		.003			\\
			TM		&	9.25		&	3.62		&	1		&	16		&	-0.03				&	-0.83					& 		.002			\\
			BD		&	51.01		&	10.76		&	2		&	78		&	-1.46				&	5.86					& 		<.001			\\
			SC		&	3.16		&	1.97		&	0		&	7		&	0.06				&	-1.01					& 		<.001			\\
			ST		&	8.59		&	3.68		&	0		&	18		&	-0.04				&	-0.34					& 		.12			\\
			CH		&	2.76		&	1.66		&	0		&	6		&	-0.01				&	-0.81					& 		<.001			\\
			TG		&	11.72		&	3.20		&	1		&	20		&	-0.66				&	1.01					& 		<.001			\\
			RZ		&	10.80		&	4.02		&	1		&	20		&	-0.19				&	-0.49					& 		.06			\\
			WM		&	7.15		&	2.89		&	2		&	17		&	0.77				&	0.83					& 		<.001			\\
			KW		&	23.31		&	6.46		&	2		&	37		&	-0.24				&	0.13					& 		.04			\\
			ZZ		&	6.41		&	2.94		&	1		&	14		&	0.32				&	-0.33					& 		.002			\\
			OE		&	34.33		&	5.93		&	9		&	47		&	-0.46				&	1.08					& 		.007			\\
			WE		&	18.25		&	6.07		&	1		&	31		&	-0.25				&	-0.33					& 		.14			\\
			
			\hline
		\end{tabular}

		\begin{tablenotes}[flushleft]
			\footnotesize				% font size
			\setlength\labelsep{0pt}	% no indent on second line
			\item \textit{Anmerkungen.} Siehe \autoref{tab:bis_subtest_description} für eine Beschreibung der Subtests.
			Min~=~Minimum; Max~=~Maximum; S-W~=~Shapiro-Wilk-Test.
		\end{tablenotes}
	\end{threeparttable}
	\end{adjustbox}
\end{table}

\begin{figure}[!b]
	\centering
	%	\captionsetup{font = small}
	\begin{adjustbox}{width=1\textwidth}
		\input{tikzDevice/bis_density.tex}
	\end{adjustbox}
	\caption[Dichtefunktion des \gls{zwert}s des \gls{bist}s]{Dichtefunktion des \gls{zwert}s des \gls{bist}s. Der \gls{zwert} wurde als Mittelwert aller 18 \textit{z}-standardisierter Subtests gebildet. Alle Datenpunkte sind auf der x-Achse mit vertikalen Strichen markiert.}
	\label{fig:bis_zscore_density}
\end{figure}

\begin{sidewaystable}
	\captionsetup{labelsep = none}
	\caption[Produkt-Moment-Korrelationen zwischen den Subtests des \gls{bist}s]{\newline  \textit{Produkt-Moment-Korrelationen zwischen den Subtests des \gls{bist}s} \vspace{.2cm}}
	\label{tab:bis_product_correlations}
	\sisetup{table-space-text-post = $^{*ab}$}
	\begin{adjustbox}{width=1\textwidth,totalheight=1\textheight,keepaspectratio}
		\begin{threeparttable}
			\begin{tabular}{
				l
				l
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				>{\centering\arraybackslash}p{1.2cm}
			}
			\hline
			&	\multicolumn{1}{c}{Subtest}	&	{1}	&	{2}	&	{3}	&	{4}	&	{5}	&	{6}	&	{7}	&	{8}	&	{9}	&	{10}&	{11}&	{12}&	{13}&	{14}&	{15}&	{16}&	{17}	\\
			\hline
			
1	&	OG	&	&	&	&	&	&	&	&	&	&	&	&	&	&	&	&	&	\\
2	&	ZN	&	.27{$^{***}$}	&	&	&	&	&	&	&	&	&	&	&	&	&	&	&	&	\\
3	&	AN	&	.31{$^{***}$}	&	.42{$^{***}$}	&	&	&	&	&	&	&	&	&	&	&	&	&	&	&	\\
4	&	XG	&	.21{$^{**}$}	&	.56{$^{***}$}	&	.32{$^{***}$}	&	&	&	&	&	&	&	&	&	&	&	&	&	&	\\
5	&	WA	&	.34{$^{***}$}	&	.41{$^{***}$}	&	.49{$^{***}$}	&	.34{$^{***}$}	&	&	&	&	&	&	&	&	&	&	&	&	&	\\
6	&	ZP	&	.22{$^{**}$}	&	.17{$^{*}$}		&	.13				&	.31{$^{***}$}	&	.17{$^{*}$}		&	&	&	&	&	&	&	&	&	&	&	&	\\
7	&	TM	&	.30{$^{***}$}	&	.26{$^{***}$}	&	.44{$^{***}$}	&	.33{$^{***}$}	&	.51{$^{***}$}	&	.22{$^{**}$}	&	&	&	&	&	&	&	&	&	&	&	\\
8	&	BD	&	.07				&	.08				&	.05				&	.11				&	-.01			&	.04				&	.03	&	&	&	&	&	&	&	&	&	&	\\
9	&	SC	&	.14				&	.52{$^{***}$}	&	.35{$^{***}$}	&	.47{$^{***}$}	&	.23{$^{**}$}	&	.17{$^{*}$}		&	.32{$^{***}$}	&	.20{$^{**}$}	&	&	&&&	&&	&&\\
10	&	ST	&	.38{$^{***}$}	&	.19	{$^{*}$}	&	.24{$^{**}$}	&	.31{$^{***}$}	&	.32{$^{***}$}	&	.24{$^{**}$}	&	.39{$^{***}$}	&	-.01			&	.22{$^{**}$}	&		&&&&&&\\
11	&	CH	&	.36{$^{***}$}	&	.51{$^{***}$}	&	.52{$^{***}$}	&	.31{$^{***}$}	&	.52{$^{***}$}	&	.13				&	.33{$^{***}$}	&	.07				&	.31{$^{***}$}&	.17{$^{*}$}	&	&&&	&&&	\\
12	&	TG	&	.32{$^{***}$}	&	.33{$^{***}$}	&	.27{$^{***}$}	&	.43{$^{***}$}	&	.43{$^{***}$}	&	.16{$^{*}$}		&	.43{$^{***}$}	&	.11				&	.28{$^{***}$}&	.38{$^{***}$}	&	.22{$^{**}$}	&&	&	&&&	\\
13	&	RZ	&	.30{$^{***}$}	&	.53{$^{***}$}	&	.41{$^{***}$}	&	.55{$^{***}$}	&	.43{$^{***}$}	&	.27{$^{***}$}	&	.42{$^{***}$}	&	.08				&	.44{$^{***}$}&	.34{$^{***}$}	&	.38{$^{***}$}&	.33{$^{***}$}&&&&&	\\
14	&	WM	&	.40{$^{***}$}	&	.12				&	.29{$^{***}$}	&	.17{$^{*}$}		&	.26{$^{**}$}	&	.27{$^{***}$}	&	.39{$^{***}$}	&	.08				&	.10			&	.40{$^{***}$}	&	.18{$^{*}$}	&	.18{$^{*}$}		&	.13				&&&&	\\
15	&	KW	&	.26{$^{***}$}	&	.23{$^{**}$}	&	.28{$^{***}$}	&	.35{$^{***}$}	&	.40{$^{***}$}	&	.23{$^{**}$}	&	.56{$^{***}$}	&	.14				&	.29{$^{***}$}&	.52{$^{***}$}	&	.21{$^{**}$}&	.54{$^{***}$}	&	.36{$^{***}$}	&	.32{$^{***}$}	&&&	\\
16	&	ZZ	&	.29{$^{***}$}	&	.05				&	.04				&	.21{$^{**}$}	&	.01				&	.37{$^{***}$}	&	.10				&	.09				&	.05			&	.30{$^{***}$}&	.07				&	.08				&	.09				&	.39{$^{***}$}	&	.13				&					&	\\
17	&	OE	&	.09				&	.04				&	.03				&	.08				&	.01				&	.03				&	.13				&	.34{$^{***}$}	&	.16{$^{*}$}&	.03			&	-.06			&	.15{$^{*}$}		&	.15{$^{*}$}		&	.02				&	.16{$^{*}$}		& -.03				&	\\
18	&	WE	&	.39{$^{***}$}	&	.31{$^{***}$}	&	.27{$^{***}$}	&	.22{$^{**}$}		&	.28{$^{***}$}	&	.28{$^{***}$}	&	.09			&	-.02			&	.16{$^{*}$}	&	.23{$^{**}$}&	.27{$^{***}$}	&	.20{$^{**}$}	&	.34{$^{***}$}	&	.16{$^{*}$}		&	.22{$^{**}$}	&.19{$^{*}$}		&	-.10\\
			\hline			
			\end{tabular}
		
			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkung.} Siehe \autoref{tab:bis_subtest_description} für eine Beschreibung der Subtests.
				\item {$^{*}$}$p<.05$. {$^{**}$}$p<.01$. {$^{***}$}$p<.001$ (zweiseitig).
			\end{tablenotes}
		\end{threeparttable}
	\end{adjustbox}
\end{sidewaystable}

\clearpage
\subsection{Zusammenhänge zwischen den Aufgaben \label{subsec:Zusammenhänge}}

Bevor ausgewählte Zusammenhänge zwischen den Aufgaben in den folgenden Abschnitten anhand der Fragestellungen abgearbeitet werden, ist der Vollständigkeit halber in \autoref{tab:product_moment_correlations_manifest} eine Korrelationsmatrix abgebildet. 

Abgesehen von den bereits erwähnten Zusammenhängen zwischen den Bedingungen der \gls{ssauf}, der \gls{ha} respektive den Subtests des \gls{bist}s ist an dieser Stelle zusätzlich auf Folgendes hinzuweisen:
Der \gls{si} wies eine negative Korrelation mit der $1.8^{\circ}$-Be\-ding\-ung auf ($r=-.28$, $p<.001$) und korrelierte positiv mit der $7.2^{\circ}$-Bedingung ($r=.66$, $p<.001$). 
Diese Zusammenhänge können als Hinweis dafür gesehen werden, dass der \gls{si} als Differenz zwischen der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le für die Mustergrösse $7.2^{\circ}$ und der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le für die Mustergrösse $1.8^{\circ}$ korrekt gebildet wurde.

Weiter korrelierte einzig die 0-bit-Bedingung der \gls{ha} signifikant mit der $1.8^{\circ}$-, der $3.6^{\circ}$- und der $5.4^{\circ}$-Bedingung der \gls{ssauf}. Alle anderen Zusammenhänge zwischen den Bedingungen der beiden Aufgaben fielen so gering aus, dass sie bei der gewählten Irrtumswahrscheinlichkeit von weniger als $5\,\%$ nicht von 0 unterschieden werden konnten.

Die Bedingungen der \gls{ha} korrelierten erwartungsgemäss signifikant negativ mit psychometrischer Intelligenz \citep[$r=-.19$ bis $-.28$, alle $p\textnormal{s}<.05$; vgl.][]{Sheppard2008}.

Die Bedingungen der \gls{ssauf} korrelierten mit Ausnahme des Zusammenhangs zwischen der $7.2^{\circ}$-Bedingung und dem \gls{zwert} des \gls{bist}s ($r=-.12$, $p=.10$) alle signifikant negativ mit psychometrischer Intelligenz ($r=-.16$ bis $-.19$, alle $p\textnormal{s}<.05$).

\begin{sidewaystable}
	\centering
	\captionsetup{labelsep = none}
	\caption[Produkt-Moment-Korrelationen zwischen der \gls{ssauf}, dem \gls{si}, der \gls{ha}, dem \textit{z}-Wert und dem \gls{gfaktor} des \gls{bist}s]{\newline  \textit{Produkt-Moment-Korrelationen zwischen den Bedingungen der \gls{ssauf}, dem \gls{si}, den Bedingungen der \gls{ha}, dem \textit{z}-Wert und dem \gls{gfaktor} des \gls{bist}s} \vspace{.2cm}}
	\label{tab:product_moment_correlations_manifest}
	\sisetup{table-space-text-post = $^{***}$}
%	\begin{adjustbox}{width=.90\textwidth, keepaspectratio}
	\begin{threeparttable}
		\begin{tabular}{
				l
				l
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				p{.001cm}
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				p{.001cm}
				S[table-format = 0.2, add-integer-zero=false]
				c
				>{\centering\arraybackslash}p{1.2cm}
			}
			\hline
			
			
			&	& 	\multicolumn{5}{c}{\gls{ssauf}}	&	&	\multicolumn{4}{c}{\gls{ha}}	&	&	\multicolumn{2}{c}{\gls{bist}}	\\
			
			\cline{3-7}
			\cline{9-12}
			\cline{14-15}
			
	&	\multicolumn{1}{c}{Mass}			&	{1}				&	{2}				&	{3}				&	{4}			&	{5}			&	& {6}	& {7}	& {8}	&{9}&&{10}&{11} \\
\hline
1	&	$1.8^{\circ}$	&					&					&					&					&				&	& & & & &\\
2	&	$3.6^{\circ}$	&	.85{$^{***}$}	&					&					&					&				&	& & & & &\\
3	&	$5.4^{\circ}$	&	.73{$^{***}$}	&	.87{$^{***}$}	&					&					&				&	& & & & &\\
4	&	$7.2^{\circ}$	&	.54{$^{***}$}	&	.72{$^{***}$}	&	.87{$^{***}$}	&					&				&	& & & & &\\
5	&	SI 				&	-.28{$^{***}$}	&	.05				&	.34{$^{***}$}	&	.66{$^{***}$}	&				&	& & & & &\\
\rule{0pt}{4ex}%  EXTRA vertical height
6	&	0-bit			&	.17{$^{*}$}		&	.24{$^{**}$}	&	.25{$^{***}$}	&	.14				&	.01			&	& & & & &\\
7	&	1-bit			&	.09				&	.11				&	.13				&	.07				&	.00			&	&.76{$^{***}$}	&	&	&	&	&		\\
8	&	2-bit			&	.12				&	.08				&	.08				&	.04				&	-.06		&	&.58{$^{***}$}	&	.72{$^{***}$}	&	&	&	&		\\
9	&	2.58-bit		&	.14				&	.09				&	.12				&	.07				&	-.04		&	&.52{$^{***}$}	&	.66{$^{***}$}	&	.83{$^{***}$}	&	&	&		\\
\rule{0pt}{4ex}%  EXTRA vertical height
10	&	\textit{z}-Wert	&	-.16{$^{*}$}	&	-.17{$^{*}$}	&	-.16{$^{*}$}	&	-.12			&	.00			&	&-.19{$^{*}$}	&	-.27{$^{***}$}	&	-.28{$^{***}$}	&	-.28{$^{***}$}	&				&		\\
11	&	\gls{gfaktor}	&	-.18{$^{*}$}	&	-.19{$^{*}$}	&	-.19{$^{*}$}	&	-.16{$^{*}$}	&	-.01		&	&-.20{$^{**}$}	&	-.28{$^{***}$}	&	-.28{$^{***}$}	&	-.27{$^{***}$}	&				&	.98{$^{***}$}	& \hphantom{.10000}			\\	
			
			\hline
			
		\end{tabular}%
		%}
		\begin{tablenotes}[flushleft]
			\footnotesize				% font size
			\setlength\labelsep{0pt}	% no indent on second line
			\item \textit{Anmerkungen}. SI = \gls{si}; \gls{zwert} = Mittelwert aller 18 \textit{z}-standardisierten Subtests.
			\item {$^{*}$}$p<.05$. {$^{**}$}$p<.01$. {$^{***}$}$p<.001$ (zweiseitig).
		\end{tablenotes}
	\end{threeparttable}
	%\end{adjustbox}
\end{sidewaystable}



\clearpage
\section{1. Fragestellung}

Mit der ersten Fragestellung sollte geprüft werden, ob die von \citet{Melnick2013} berichteten Zusammenhänge zwischen der \gls{ssauf} und psychometrischer Intelligenz bestätigt werden können. 

Der von \citet{Melnick2013} berichtete Zusammenhang zwischen dem \gls{si} und IQ-Punkten (Studie 1 [$N=12$]: $r~=~.64$, $p~=~.02$ und Studie 2 [$N=53$]: $r~=~.71$, $p~<~.001$) konnte in der vorliegenden Arbeit nicht bestätigt werden: Der Zusammenhang zwischen dem \gls{si} und dem \gls{zwert} aus dem \gls{bist} betrug $r~=~.00$ ($p~=~.98$; siehe \autoref{fig:suppression_index_zscore_scatterplot}). 
Um zu prüfen, ob diese Korrelation signifikant tiefer ausfiel als bei \citeauthor{Melnick2013}, wurden die Korrelationskoeffizienten in Fisher-\textit{Z}-Werte umgerechnet und  auf Unterschiedlichkeit geprüft \citep[][S. 54]{Cohen1983}. 
Dabei hat sich ergeben, dass sich der in der vorliegenden Arbeit ermittelte Korrelationskoeffizient $r~=~.00$ signifikant von den von \citet{Melnick2013} berichteten $r~=~.64$ und $r~=~.71$ unterschied ($z=2.22$, $p=.03$ respektive $z=5.53$, $p<.001$).

\begin{figure}[t]
	\centering
	\begin{adjustbox}{width=1\textwidth}
		\input{tikzDevice/si_intelligence_scatterplot.tex}
	\end{adjustbox}
	\caption[Zusammenhang zwischen dem \gls{si} und \gls{zwert} des \gls{bist}s]{Streudiagramm des Zusammenhangs zwischen dem \gls{si} und dem \gls{zwert} aus dem \gls{bist} ($r=.00$, $p=.98$).}
	\label{fig:suppression_index_zscore_scatterplot}
\end{figure}

Auch der von \citet{Melnick2013} in Studie 2 berichtete Zusammenhang zwischen der kleinsten Mustergrösse ($1.8^{\circ}$-Bedingung) und IQ-Punkten ($r=-.46$, $p<.001$) konnte nicht bestätigt werden: Die Korrelation zwischen der $1.8^{\circ}$-Bedingung und dem \gls{zwert} aus dem \gls{bist} betrug in der vorliegenden Arbeit $r=-.16$ ($p=.03$) und fiel damit signifikant tiefer aus als bei \citeauthor{Melnick2013} ($z=2.09$, $p=.04$).

Gleichermassen nicht bestätigt werden konnten die von \citet{Melnick2013} berichteten Semipartialkorrelationen zwischen der kleinsten Mustergrösse ($1.8^{\circ}$-Bedingung), der grössten Mustergrösse ($7.2^{\circ}$-Bedingung) und psychometrischer Intelligenz: In Studie 2 von \citeauthor{Melnick2013} betrug die Semipartialkorrelation zwischen der kleinsten Mustergrösse und IQ-Punkten bei Kontrolle für die grösste Mustergrösse $r=-.71$ ($p<.001$) und zwischen der grössten Mustergrösse und IQ-Punkten bei Kontrolle für die kleinste Mustergrösse $r=.55$ ($p<.001$). Hoher IQ war bei \citeauthor{Melnick2013} im Vergleich zu tiefem IQ somit mit tieferen $82\,\%$-Erkennungsschwellen bei kleiner Mustergrösse und mit höheren $82\,\%$-Erkennungsschwellen bei grosser Mustergrösse verbunden. 
In der vorliegenden Arbeit betrugen die Semipartialkorrelationskoeffizienten bei Kontrolle für die grösste Mustergrösse ($z$) zwischen der kleinsten Mustergrösse ($x$) und dem \gls{zwert} ($y$) aus dem \gls{bist} $r_{y(x.z)}= -.11$ ($p = .15$) und bei einer Kontrolle für die kleinste Mustergrösse ($z$) zwischen der grössten Mustergrösse ($x$) und dem \gls{zwert} ($y$) aus dem \gls{bist} $r_{y(x.z)}=-.04$ ($p = .57$). 
Ein Vergleich dieser unabhängigen Semipartialkorrelationskoeffizienten hat ergeben, dass die in der vorliegenden Arbeit erhaltenen Zusammenhänge signifikant schwächer ausfielen als bei \citeauthor{Melnick2013} ($z=4.84$, $p<.001$ respektive $z=4.10$, $p<.001$).

Abschliessend zur Beantwortung der ersten Fragestellung kann festgehalten werden, dass sowohl die von \citet{Melnick2013} berichteten Zusammenhänge zwischen dem \gls{si} und psychometrischer Intelligenz als auch die Zusammenhänge der einzelnen Bedingungen der \gls{ssauf} mit psychometrischer Intelligenz nicht bestätigt werden konnten.













\section{2. Fragestellung \label{sec:2Fragestellung}}

Mit der zweiten Fragestellung sollte geprüft werden, ob die aus der \gls{ssauf} mit einer exponentiellen Regression abgeleiteten Aufgabenparameter benutzt werden können, um psychometrische Intelligenz vorherzusagen.

Für jede \gls{vp} wurden die vier $82\,\%$-Erkennungsschwellen mit einer exponentiellen Regression der von \citet{Melnick2013} vorgeschlagenen Form $y=a \times e^{bx}$ vorhergesagt (siehe \autoref{fig:spatial_suppression_exponential_model}).
\begin{table}[b]
	%\flushleft
	\centering
	\captionsetup{labelsep = none}
	\caption[Deskriptive Angaben zur exponentiellen Regression für die Vorhersage der $82\,\%$-Er\-ken\-nungs\-schwel\-len durch die Mustergrössen der \gls{ssauf}]{\newline  \textit{Deskriptive Angaben zur exponentiellen Regression ($y=a \times e^{bx}$) für die Vorhersage der $82\,\%$-Er\-ken\-nungs\-schwel\-len durch die Mustergrössen der \gls{ssauf} und Kennwerte zur Verteilungsform der Daten} \vspace{.2cm}}
	\label{tab:spatial_suppression_exponential_model}
	\begin{adjustbox}{width=1\textwidth}
		\begin{threeparttable}
			\begin{tabular}{
					l
					S[table-format = 2.3]
					S[table-format = 2.3]
					S[table-format = 2.3]
					S[table-format = 3.3]
					S[table-format = 1.2]
					S[table-format = 2.2]
					S[table-format = <0.3, add-integer-zero=false]
				}
				\hline
				\multicolumn{1}{c}{Parameter}	& 	{\textit{M}}	&{\textit{SD}}	&	{Min}	&	{Max} 	&	{\textnormal{Schiefe}}	&	{\textnormal{Kurtosis}} & {S-W \textit{p}-Wert}\\
				\hline
				$a$			&		70			&	28			&	5		&	195		&	0.97					&	1.87					& 		<.001			\\
				$b$			&		.103		&	.081		&	-.079	&	.650	&	2.17					&	10.80					& 		<.001			\\
				\hline
			\end{tabular}

			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkungen.} \textit{a}~=~Asymptote (in ms); \textit{b}~=~Steigung; Min~=~Minimum; Max~=~Maximum; S-W~=~Shapiro-Wilk-Test.
			\end{tablenotes}
		\end{threeparttable}
	\end{adjustbox}
\end{table}
\begin{figure}[t]
	\centering
	\begin{adjustbox}{width=1\textwidth}
		\input{tikzDevice/spatial_suppression_exponential_model.tex}
	\end{adjustbox}
	\caption[Exponentielles Modell zur Vorhersage der $82\,\%$-Er\-ken\-nungs\-schwel\-le durch die Mustergrösse der \gls{ssauf}]{Exponentieller Einfluss der Mustergrösse auf die $82\,\%$-Er\-ken\-nungs\-schwel\-le für horizontale Bewegung in der \gls{ssauf}. Eingezeichnet sind die Mittelwerte $\pm$ Standardfehler der Mittelwerte. Die x- und die y-Achse sind beide logarithmiert. $y=70 \times e^{0.103x}$.}
	\label{fig:spatial_suppression_exponential_model}
\end{figure}
Deskriptive Angaben zu den daraus resultierenden Parametern, der Asymptote $a$ und der Steigung $b$, sind in \autoref{tab:spatial_suppression_exponential_model} zu finden.
Weil der Determinationskoeffizient $R^2$ bei nicht-linearen Modellen kein adäquates Mass für die Anpassungsgüte des Modells an die Daten darstellt \citep{Spiess2010}, wurde für jede Person der \gls{rmse} berechnet. Der \gls{rmse} ist die Quadratwurzel aus dem Mittelwert der quadrierten Fehler und damit ein Mass für die durchschnittliche Abweichung der vorhergesagten Werte von den empirischen Werten. 
Obwohl der \gls{rmse} für einige \glspl{vp} sehr gross ausfiel, eignete sich ein exponentielles Modell zur Beschreibung der Daten für einen grossen Teil der \glspl{vp} sehr gut (siehe \autoref{fig:spatial_suppression_rmse_density}). Der Median betrug $6$ ms und das dritte Quartil lag bei $9$ ms (Minimum~$=0.47$~ms, Maximum~$=65.47$~ms).

\begin{figure}[t]
	\centering
	%	\captionsetup{font = small}
	\begin{adjustbox}{width=1\textwidth}
		\input{tikzDevice/spatial_suppression_rmse_density.tex}
	\end{adjustbox}
	\caption[Dichtefunktion des aus der \gls{ssauf} mit einer exponentiellen Regression abgeleiteten \gls{rmse}]{Dichtefunktion des \acrlong{rmse} (\gls{rmse}; in Millisekunden), der sich aus dem exponentiellen Modell zur Beschreibung der Erkennungsschwellen der \gls{ssauf} ergeben hat. Alle Datenpunkte sind auf der x-Achse mit vertikalen Strichen markiert.}
	\label{fig:spatial_suppression_rmse_density}
\end{figure}

Um erkennen zu können, ob der Zusammenhang zwischen den beiden Aufgabenparametern (Asymptote und Steigung), der Zusammenhang zwischen der Steigung und dem \gls{si} oder der Zusammenhang zwischen der Asymptote respektive der Steigung mit dem \gls{zwert} des \gls{bist}s durch diejenigen \glspl{vp} verzerrt wurde, bei welchen eine Beschreibung der Daten mit einem exponentiellen Modell nicht angebracht war, wurden diese Zusammenhänge in Abhängigkeit des \gls{rmse} bestimmt. 
Dafür wurde für jeden \gls{rmse} \todo[color=green!40, fancyline]{Caption der Abbildung inhaltlich korrekt?} zwischen $1$ und $70$~ms eine Teilstichprobe mit \glspl{vp} gebildet, welche den gewählten \gls{rmse} (\gls{rmse}-Grenzwert) nicht überschritten haben. Die erste Teilstichprobe ($n=4$) bestand folglich aus \glspl{vp}, welche einen \gls{rmse} von nicht grösser als $1$~ms aufwiesen. Die zweite Teilstichprobe ($n=11$) setzte sich aus \glspl{vp} zusammen, welche einen \gls{rmse} von nicht grösser als $2$~ms aufwiesen. Die dritte Teilstichprobe ($n=32$) beinhaltete \glspl{vp}, welche einen \gls{rmse} von nicht grösser als $3$~ms aufwiesen (usw.). Dieses Vorgehen wurde solange weitergeführt, bis die Teilstichprobe bei einem \gls{rmse}-Grenzwert von $65.47$~ms alle \glspl{vp} ($N=177$) beinhaltete. 
Damit liessen sich die Zusammenhänge über den ganzen \gls{rmse}-Grenz\-wert\-be\-reich bestimmen. Eine Teilstichprobe bei einem tiefen \gls{rmse}-Grenz\-wert umfasste somit \glspl{vp}, welche Modell-konforme Daten aufwiesen, während eine Teilstichprobe bei einem hohen \gls{rmse}-Grenzwert auch \glspl{vp} beinhaltete, deren Werte stärker vom exponentiellen Modell abwichen.

Die Analyse hat ergeben, dass die Asymptote und die Steigung ab einem \gls{rmse}-Grenzwert von $1.4$ ms stark negativ miteinander zusammenhingen ($r=-.57$ bis $-.98$, alle $p\textnormal{s}<.05$). Eine visuelle Inspektion des Verlaufs deutete darauf hin, dass der \gls{rmse}-Grenzwert einen negativen Einfluss auf die Höhe des Zusammenhangs ausübte (siehe \autoref{fig:spatial_suppression_rmse_cutoff_asymtote_slope_suppressionindex}a).

\begin{figure}[htbp]
	\centering
	%	\captionsetup{font = small}
	\begin{adjustbox}{width=1\textwidth}
		\subfloat[Test][Zusammenhang ($r$) zwischen der Asymptote und der Steigung.]{\input{tikzDevice/spatial_suppression_rmse_cutoff_asymptote_slope.tex}}
	\end{adjustbox}
	\newline
	\begin{adjustbox}{width=1\textwidth}
		\subfloat[Test][Zusammenhang ($r$) zwischen der Steigung und dem \gls{si}.]{\input{tikzDevice/spatial_suppression_rmse_cutoff_slope_suppressionindex.tex}}
	\end{adjustbox}
	\caption[Einfluss des \gls{rmse}-Grenzwerts der \gls{ssauf} auf den Zusammenhang zwischen der Asymptote, der Steigung und dem \gls{si}]{Einfluss des \gls{rmse}-Grenzwerts auf ($a$) den Zusammenhang zwischen den aus der \gls{ssauf} mit einer exponentiellen Regression abgeleiteten Aufgabenparametern Asymptote und Steigung respektive auf ($b$) den Zusammenhang zwischen der Steigung und dem \gls{si}. Die durchgezogene Linie kennzeichnet den Verlauf des Zusammenhangs. Der graue Bereich beschreibt das $95\,\%$-Konfidenzintervall.}
	\label{fig:spatial_suppression_rmse_cutoff_asymtote_slope_suppressionindex}
\end{figure}

Die Steigung korrelierte über den ganzen \gls{rmse}-Grenzwertbereich stark positiv mit dem \gls{si} ($r=.96$ bis $.99$, alle $p\textnormal{s}<.001$; siehe \autoref{fig:spatial_suppression_rmse_cutoff_asymtote_slope_suppressionindex}b). Die tiefste Schätzung ($r=.96$, $p<.001$) unterschied sich dabei signifikant ($z=7.85$, $p<.001$) von dem von \citet{Melnick2013} berichteten Zusammenhang ($r>.996$).

Der Zusammenhang zwischen der Asymptote und dem \gls{zwert} des \gls{bist}s fiel in Abhängigkeit des \gls{rmse}-Grenzwerts weniger eindeutig aus (siehe \autoref{fig:spatial_suppression_asymtote_slope_zscore}a).
Während der Zusammenhang über einen grossen Teil des tieferen \gls{rmse}-Grenzwertbereichs nicht signifikant war, unterschritt die Korrelation zwischen $8.6$ und $9.5$ ms ($r = -.17$, $p = .049$), zwischen $26.1$ und $35.7$ ms ($r = -.15$ bis $ -.16$, alle $p\textnormal{s} < .048$) und ab $36.5$ ms ($r = -.16$ bis $-.18$, alle $p\textnormal{s} < .03$) die Signifikanzgrenze. In den erwähnten Bereichen war eine tiefe Asymptote somit tendenziell mit einem hohen \gls{zwert} verbunden. Eine visuelle Inspektion des Verlaufs liess keine Aussage darüber zu, ob der  \gls{rmse}-Grenzwert einen positiven oder negativen Einfluss auf die Höhe des Zusammenhangs ausübte.

Die Steigung und der \gls{zwert} des \gls{bist}s korrelierten unabhängig vom \gls{rmse}-Grenzwert nicht signifikant miteinander ($r=-.16$ bis $.62$, alle $p\textnormal{s}>.08$; siehe \autoref{fig:spatial_suppression_asymtote_slope_zscore}b). 
Um für den Vergleich zwischen dem von \citet{Melnick2013} berichteten Zusammenhang zwischen ihrer Steigung (Studie 1: $b=0.116$ und Studie 2: $b=0.139$) und IQ-Punkten und dem in der vorliegenden Arbeit ermittelten Zusammenhang zwischen der Steigung ($b=0.103$) und dem \gls{zwert} die bestmögliche Teststärke zu erhalten, wurde die Gesamtstichprobe (\gls{rmse}-Grenzwert = $65.47$ ms) verwendet. Die Analyse hat ergeben, dass sich der in der vorliegenden Arbeit ermittelte Zusammenhang ($r=.00$, $p=.97$) signifikant von dem von \citeauthor{Melnick2013} berichteten Zusammenhang ($r=.68$) unterschied ($z=5.61$, $p<.001$).

Betrachtet man die mit der Gesamtstichprobe erhaltenen Ergebnisse, kann abschliessend zur Beantwortung der zweiten Fragestellung Folgendes festgehalten werden:  
Die Asymptote, der erste aus der \gls{ssauf} abgeleitete Aufgabenparameter, korrelierte in der vorliegenden Arbeit schwach negativ mit dem \gls{zwert} des \gls{bist}s ($r=-.16$, $p=.03$). Die Steigung, der zweite abgeleitete Aufgabenparameter, hing nicht signifikant mit dem \gls{zwert} zusammen ($r=.00$, $p=.97$) und bestätigte damit den von \citet{Melnick2013} berichteten Zusammenhang nicht. 

\begin{figure}[htbp]
	\centering
	%	\captionsetup{font = small}
	\begin{adjustbox}{width=1\textwidth}
		\subfloat[Test][Zusammenhang ($r$) zwischen der Asymptote und dem \gls{zwert} des \gls{bist}s.]{\input{tikzDevice/spatial_suppression_rmse_cutoff_asymptote_zscore.tex}}
	\end{adjustbox}
	\newline
	\begin{adjustbox}{width=1\textwidth}
		\subfloat[Test][Zusammenhang ($r$) zwischen der Steigung und dem \gls{zwert} des \gls{bist}s.]{\input{tikzDevice/spatial_suppression_rmse_cutoff_slope_zscore.tex}}
	\end{adjustbox}
	
	\caption[Einfluss des \gls{rmse}-Grenzwerts der \gls{ssauf} auf den Zusammenhang zwischen der Asymptote, der Steigung und dem \gls{zwert} des \gls{bist}s]{Einfluss des \gls{rmse}-Grenzwerts auf die Zusammenhänge der aus der \gls{ssauf} mit einer exponentiellen Regression abgeleiteten Aufgabenparameter ($a$) Asymptote  und ($b$)Steigung  mit dem \gls{zwert} des \gls{bist}s. Die durchgezogene Linie kennzeichnet den Verlauf des Zusammenhangs. Der graue Bereich beschreibt das $95\,\%$-Konfidenzintervall.}
	\label{fig:spatial_suppression_asymtote_slope_zscore}
\end{figure}











%Abschliessend zur zweiten Fragestellung kann festgehalten werden, dass die Quantifizierung der Wahrnehmungsleistungsverschlechterung durch den \gls{si} (als Differenzmass) nicht mit Nachteilen verbunden ist. Die Steigung der exponentiellen Regression liefert in Bezug auf die Vorhersage von psychometrischer Intelligenz gewissermassen dieselbe Information wie der \gls{si}. Weiter konnte die Asymptote der exponentiellen Regression psychometrische Intelligenz nicht vorhersagen. Die Analyse  der \gls{ssauf} auf manifester Ebene hat ergeben, dass weder der \gls{si} noch die aus der exponentiellen Regression abgeleiteten Aufgabenparameter mit psychometrischer Intelligenz zusammenhängen.
















\clearpage
\section{3. Fragestellung \label{sec:3Fragestellung}}

Mit der dritten Fragestellung sollte der Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz auf latenter Ebene untersucht werden. 
%Mit der dritten Fragestellung sollte der prädiktive Wert der \gls{ssauf} in Bezug auf \textit{g}, der latenten Operationalisierung psychometrischer Intelligenz, untersucht werden.
Alle konfirmatorischen Faktorenanalysen wurden mit der Satorra-Bentler Maximum-Likelihood Schätzmethode \citep{Satorra1994} berechnet, weil diese bei nicht-normal\-ver\-teilten, intervallskalierten Daten empfohlen wird \citep[z. B.][]{Curran1996, Finney2006}.
Um die aus den Aufgaben extrahierten Faktoren auf latenter Ebene miteinander in Verbindung zu bringen, wurde als Erstes für jede Aufgabe ein kongenerisches Messmodell \citep{Joereskog1971} gerechnet. Diese dem Strukturgleichungsmodell vorausgehende Prüfung der Modellannahmen erlaubte es, allfällige Fehlspezifikationen bereits auf Aufgabenebene zu erkennen.

Das kongenerische Messmodell der \gls{ssauf} (Modell 1; siehe \autoref{fig:spatial_suppression_congeneric_model}) bildete die empirischen Varianzen und Kovarianzen unzureichend ab.  Der \gls{cst} zeigte eine überzufällig hohe Abweichung zwischen der theoretischen und der empirischen Var\-ianz-Ko\-var\-ianz\-ma\-trix an und der \gls{cfi} und der \gls{rmsea} lagen weit ausserhalb des akzeptablen Bereichs, $\upchi^2(2)=103.13$, $p<.001$, $\textnormal{CFI}=.78$, $\textnormal{RMSEA}=.53$, $\textnormal{SRMR}=.06$.

Um den \gls{gfaktor} aus dem \gls{bist} zu bilden, wurden die gemittelten \textit{z}-Werte der Operationen \gls{k}, \gls{b} und \gls{M} als Indikatoren verwendet \citep[für ein gleiches Vorgehen siehe][]{Pahud2017, Stauffer2014}. Weil dieses kongenerische Messmodell mit drei Indikatoren genau identifiziert war, konnte es nicht getestet werden \citep[][S. 125]{Kline2011}.

\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}
	[font=\sffamily, scale=2, inner sep=0pt,
	latent/.style	= {circle, draw, inner sep=0pt, minimum size=12mm},
	manifest/.style	= {rectangle, draw, inner sep=0pt, minimum width=12mm, minimum height=12mm},
	paths/.style	= {->, >=stealth, shorten >= 1pt},
	error/.style	= {circle, draw=none, fill=white, minimum size=5mm},
	covar/.style	= {<->, >=stealth, shorten >= 1pt, shorten <= 1pt}]
	
	\node at (0, 1.7)		[latent]	(sup)	{S};
	
	\node at (-1.5, 2.9)	[manifest]	(s1)	{1.8$^{\circ}$};
	\node at (-1.5, 2.1)	[manifest]	(s2)	{3.6$^{\circ}$};
	\node at (-1.5, 1.3)	[manifest]	(s3)	{5.4$^{\circ}$};
	\node at (-1.5, 0.5)	[manifest]	(s4)	{7.2$^{\circ}$};
	
	\node at (-2.3, 2.9)	[error]		(e1)	{\footnotesize .45};
	\node at (-2.3, 2.1)	[error]		(e2)	{\footnotesize .23};
	\node at (-2.3, 1.3)	[error]		(e3)	{\footnotesize .02};
	\node at (-2.3, 0.5)	[error]		(e4)	{\footnotesize .24};
	
	\draw [paths] (sup.west) -- (s1.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .75{$^{1}$}\hphantom{$^**$}};	
	\draw [paths] (sup.west) -- (s2.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .88{$^{***}$}};	
	\draw [paths] (sup.west) -- (s3.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .99{$^{***}$}};	
	\draw [paths] (sup.west) -- (s4.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .87{$^{***}$}};
	
	\draw [paths] (e1) -- (s1.west) {};
	\draw [paths] (e2) -- (s2.west) {};
	\draw [paths] (e3) -- (s3.west) {};
	\draw [paths] (e4) -- (s4.west) {};
	\end{tikzpicture}
	
	\vspace{.2cm}
	\caption[Modell 1: Kongenerisches Messmodell der \gls{ssauf}]{Modell 1: Kongenerisches Messmodell der \gls{ssauf} (\textsf{S}). Eingezeichnet sind die standardisierten Koeffizienten.\\
	$^1$Um die Identifizierung der Varianz der latenten Variable zu ermöglichen, wurde diese unstandardisierte Faktorladung auf $1$ fixiert.\\
	$^{***}p~<~.001$.}
	\label{fig:spatial_suppression_congeneric_model}
\end{figure}



\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}
	[font=\sffamily, scale=2, inner sep=0pt,
	latent/.style	= {circle,draw,inner sep=0pt,minimum size=12mm},
	manifest/.style	= {rectangle,draw,inner sep=0pt,minimum width=12mm,minimum height=12mm},
	paths/.style	= {->, >=stealth, shorten >= 1pt},
	error/.style	= {circle, draw=none, fill=white, minimum size=5mm},
	covar/.style	= {<->, >=stealth, shorten >= 1pt, shorten <= 1pt}]
	
	\node at (0, 0)			[latent]	(sup)	{S};
	\node at (1.5, 0)		[latent]	(g)		{\textrm{\textit{g}}};
	
	\node at (-1.5, 1.2)	[manifest]	(s1)	{1.8$^{\circ}$};
	\node at (-1.5, 0.4)	[manifest]	(s2)	{3.6$^{\circ}$};
	\node at (-1.5, -.4)	[manifest]	(s3)	{5.4$^{\circ}$};
	\node at (-1.5, -1.2)	[manifest]	(s4)	{7.2$^{\circ}$};
	
	\node at (3, .8)		[manifest]	(k)		{Kap};
	\node at (3, 0)			[manifest]	(b)		{Bea};
	\node at (3, -.8)		[manifest]	(m)		{Mer};
	
	\node at (-2.3, 1.2)	[error]		(e1)	{\footnotesize .44};
	\node at (-2.3, 0.4)	[error]		(e2)	{\footnotesize .23};
	\node at (-2.3, -.4)	[error]		(e3)	{\footnotesize .02};
	\node at (-2.3, -1.2)	[error]		(e4)	{\footnotesize .24};
	
	\node at (3.8, .8)		[error]		(e9)	{\footnotesize .32};
	\node at (3.8, 0)		[error]		(e10)	{\footnotesize .46};
	\node at (3.8, -.8)		[error]		(e11)	{\footnotesize .71};
	
	\node at (1.5, 0.8)		[error]		(e12)	{\footnotesize .95};
	
	\draw [paths] (sup.west) -- (s1.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .75{$^{1}$}\hphantom{$^**$}};
	\draw [paths] (sup.west) -- (s2.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .88{$^{***}$}};
	\draw [paths] (sup.west) -- (s3.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .99{$^{***}$}};
	\draw [paths] (sup.west) -- (s4.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .87{$^{***}$}};
	
	\draw [paths] (g.east) -- (k.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .83{$^{1}$}\hphantom{$^**$}};
	\draw [paths] (g.east) -- (b.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .74{$^{***}$}};
	\draw [paths] (g.east) -- (m.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .54{$^{***}$}};
	
	\draw [paths] (e1) -- (s1.west);
	\draw [paths] (e2) -- (s2.west);
	\draw [paths] (e3) -- (s3.west);
	\draw [paths] (e4) -- (s4.west);
	
	\draw [paths] (e9)  -- (k.east);
	\draw [paths] (e10) -- (b.east);
	\draw [paths] (e11) -- (m.east);
	
	\draw [paths] (e12) -- (g);
	
	\draw [paths] (sup)  -- (g.west) node[minimum size = 4mm, draw=none,fill=white,midway] {\footnotesize \hspace{.5em}--.23{$^{**}$}};
	\end{tikzpicture}
	
	\vspace{.2cm}
	\caption[Modell 2: Strukturgleichungsmodell zur Vorhersage des \gls{gfaktor}s durch die \gls{ssauf}]{Modell 2: Latenter Zusammenhang zwischen der \gls{ssauf} (\textsf{S}) und dem \gls{gfaktor} des \gls{bist}s. Eingezeichnet sind die standardisierten Koeffizienten. \textsf{Kap} = Kapazität; \textsf{Bea} = Bearbeitungsgeschwindigkeit; \textsf{Mer} = Merkfähigkeit.\\
	$^1$Um die Identifizierung der Varianz der latenten Variable zu ermöglichen, wurde diese unstandardisierte Faktorladung auf $1$ fixiert.\\
	$^{**}p~<~.01$. $^{***}p~<~.001$.}
	\label{fig:spatial_suppression_g_model}
\end{figure} 

Trotz des schlechten kongenerischen Modell-Fits der \gls{ssauf} wurden die beiden Messmodelle in einem Strukturgleichungsmodell miteinander in Verbindung gebracht. Das theoretische Modell (Modell 2; siehe \autoref{fig:spatial_suppression_g_model}) bildete die empirischen Daten erneut schlecht ab.  Der \gls{cst} zeigte eine überzufällig hohe Abweichung zwischen der theoretischen und der empirischen Var\-ianz-Ko\-var\-ianz\-ma\-trix an und der \gls{cfi} und der \gls{rmsea} lagen nicht im akzeptablen Bereich, $\upchi^2(13)=123.88$, $p<.001$, $\textnormal{CFI}=.85$, $\textnormal{RMSEA}=.22$, $\textnormal{SRMR}=.06$. 
Der standardisierte Regressionskoeffizient zwischen der aus den vier Bedingungen der \gls{ssauf} extrahierten latenten Variable und dem \gls{gfaktor} aus dem \gls{bist} betrug $\upbeta~=~-.23$ ($p~=~.01$).
Die aus der \gls{ssauf} extrahierte latente Variable erklärte damit $5\,\%$ der Varianz im \gls{gfaktor}.

Abschliessend zur dritten Fragestellung kann festgehalten werden, dass sich zwischen der \gls{ssauf} und psychometrischer Intelligenz auf latenter Ebene ein schwacher bis mittlerer negativer Zusammenhang zeigte.
Tiefe Faktorwerte auf der aus den vier Bedingungen der \gls{ssauf} extrahierten latenten Variable waren somit tendenziell mit hohen Faktorwerten im \gls{gfaktor} verbunden. Dieser Zusammenhang muss jedoch aufgrund des schlechten theoretischen Modells  mit Vorsicht interpretiert werden.


















\section{4. Fragestellung \label{sec:4Fragestellung}}

Mit der vierten Fragestellung sollte versucht werden, die \gls{ssauf} mit einem \gls{flm} zu beschreiben und die zwei aus der Aufgabe abgeleiteten latenten Variablen mit dem \gls{gfaktor} des \gls{bist}s in Verbindung zu bringen.


\subsection{Fixed-Links-Messmodell \label{subsec:spatial_suppression_fixed_links_messmodell}}

Weil die \gls{ssauf} noch nie mit einem \gls{flm} beschrieben wurde, sind unterschiedliche Modelle getestet und miteinander verglichen worden. Bei allen berechneten Modellen wurden zwei voneinander unabhängige latente Variablen angenommen: 

Die erste latente Variable beinhaltete aufgabenrelevante Prozesse, deren Einflüsse sich über die vier Bedingungen hinweg nicht verändert haben. In den Messmodellen wurde dieser gleichbleibende Einfluss hergestellt, indem die unstandardisierten Faktorladungen der manifesten Indikatoren auf diese erste latente Variable auf den Wert 1 gesetzt wurden. Diese latente Variable wird im Folgenden \textit{konstante} latente Variable genannt. 

Die zweite latente Variable beinhaltete aufgabenrelevante Prozesse, die durch die vier Bedingungen systematisch manipuliert wurden. Der unterschiedlich starke Einfluss der in der latenten Variable abgebildeten Prozesse auf die $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-len der \gls{ssauf} wurde hergestellt, indem sich die unstandardisierten Faktorladungen der manifesten Indikatoren auf diese zweite latente Variable unterschieden.
Diese latente Variable wird im Folgenden \textit{dynamische} latente Variable genannt.

Die konstante latente Variable wurde in allen Messmodellen unabhängig von der dynamischen latenten Variable gehalten. Diese Unabhängigkeit der beiden extrahierten Variablen ist im Rahmen der Anwendung von \glspl{flm}n üblich \citep[z. B.][]{Ren2013, Schweizer2007, Schweizer2009a, Stankov2007, Wang2015}, weil sich dadurch die Interpretation der latenten Variablen vereinfacht.
Alle Modell-Fits der in den folgenden Paragraphen berichteten \glspl{flm} sind in \autoref{tab:spatial_suppression_fixedlinks_measurement_models} aufgeführt.

Das erste berechnete \gls{flm} (Modell 3) berücksichtigte das Ergebnis der exponentiellen Regression (siehe \autoref{sec:2Fragestellung}), welches auf manifester Ebene eine Steigung von $e^{0.103x}$ ergeben hat. Die unstandardisierten Faktorladungen der dynamischen latenten Variable wurden deshalb mit diesem Parameter ($y=e^{0.103x},\,x\in\{1, 2, 3, 4\}$) gebildet. Modell 3 bildete die empirischen Varianzen und Kovarianzen der \gls{ssauf} nicht gut ab. Der \gls{cst} war hochsignifikant und der \gls{cfi}, der \gls{rmsea} und das \gls{srmr} lagen nicht im akzeptablen Bereich.

Modell 4 beachtete die Tatsache, dass die den \glspl{vp} vorgelegten Mustergrössen ($1.8^{\circ}$, $3.6^{\circ}$, $5.4^{\circ}$, $7.2^{\circ}$) ein Vielfaches von $1.8$ waren.
Die unstandardisierten Faktorladungen der dynamischen latenten Variable in Modell 4 wurden deshalb linear ansteigend ($y=x,\,x\in\{1, 2, 3, 4\}$) fixiert. Modell 4 bildete die empirischen Varianzen und Kovarianzen der \gls{ssauf} ebenfalls nicht gut ab. Der $\upchi^2$-Wert reduzierte sich im Vergleich zu Modell 3 zwar beträchtlich, war aber immer noch hochsignifikant. Die schlechte Passung des Modells wurde weiter durch einen hohen \gls{rmsea} und ein hohes \gls{srmr} angezeigt.


\begin{table}[ht]
	%\flushleft
	\centering
	\captionsetup{labelsep = none}
	\caption[Modell-Fits der Fixed-Links-Messmodelle der \gls{ssauf}]{\newline  \textit{Modell-Fits der berichteten \glspl{flm} der \gls{ssauf}} \vspace{.2cm}}
	\label{tab:spatial_suppression_fixedlinks_measurement_models}
	\begin{adjustbox}{width=1\textwidth}
		\begin{threeparttable}
	%		\sisetup{table-space-text-post = $^{*}$} % not needed
	%		\sisetup{table-text-alignment=center}
			\begin{tabular}{
					l
%					S[table-format = 1.0]
					l
					S[table-format = 2.2]
					S[table-format = 1.0]
					S[table-format = <0.3, add-integer-zero=false]
					S[table-format = 0.3, add-integer-zero=false]
					S[table-format = 0.3, add-integer-zero=false]
					S[table-format = 0.3, add-integer-zero=false]
				}
				\hline
				\multicolumn{1}{c}{Modell}	& Ladungsverlauf	& 	{$\upchi^2$}	& \textit{df}	& {\textit{p}}	&	{CFI} 	&	{RMSEA}	&	{SRMR}	\\
				\hline
				3			&	$y=e^{0.103x}$	&	68.43			&	4			&	<.001		&	.861	&	.302	&	.084	\\
				4			&	$y=x$			&	22.67			&	4			&	<.001		&	.960	&	.162	&	.317	\\
				5{$^*$}		&	$y=2^x$			&	16.70			&	4			&	.001		&	.973	&	.134	&	.182	\\
				6			&	$y=\log_e x$	&	14.13			&	4			&	.007		&	.978	&	.120	&	.215	\\
				7			&	$y=x^2$			&	9.20			&	4			&	.056		&	.989	&	.086	&	.127	\\
				8			&	$y=x$			&	6.09			&	4			&	.193		&	.995	&	.054	&	.123	\\
				\hline
			\end{tabular}
	
			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkungen.} Der Ladungsverlauf bezieht sich auf die unstandardisierten Faktorladungen der dynamischen latenten Variable. Die unstandardisierten Faktorladungen der konstanten latenten Variable betrugen immer 1. Es gilt für alle Funktionen $x\in\{1,2,3,4\}$ (ausgenommen Modell 8, in welchem $x\in\{0,1,2,3\}$). $\upchi^2 =$ Satorra-Bentler \citeyearpar{Satorra1994} korrigierter $\upchi^2$-Wert; \textit{df} = Freiheitsgrade; \gls{cfi} = \acrlong{cfi}; \gls{rmsea} = \acrlong{rmsea}; \gls{srmr} = \acrlong{srmr}.
				\item {$^*$}Das Modell konnte nicht interpretiert werden, weil die Fehlervarianz der $7.2^{\circ}$-Bedingung negativ geschätzt wurde.
			\end{tablenotes}
		\end{threeparttable}
	\end{adjustbox}
\end{table}

Nach diesen zwei Modellen, welche klare Annahmen über den Verlauf der Faktorladungen der dynamischen latenten Variable beinhalteten, wurden Verläufe von Faktorladungen gesucht, welche die empirischen Daten bestmöglich beschreiben.
Die unstandardisierten Faktorladungen der dynamischen latenten Variable von Modell 5 wurden mit einer exponentiellen Funktion ($y=2^x,\,x\in\{1, 2, 3, 4\}$) bestimmt. Dieses Modell konnte nicht interpretiert werden, weil die Fehlervarianz der $7.2^{\circ}$-Bedingung negativ geschätzt wurde. 

In Modell 6 wiesen die unstandardisierten Faktorladungen der dynamischen latenten Variable einen logarithmischen Verlauf ($y=\log_{e}x,\,x\in\{1, 2, 3, 4\}$) auf. Das Modell bildete die empirischen Varianzen und Kovarianzen der \gls{ssauf} nicht adäquat ab. Zwar reduzierte sich der $\upchi^2$-Wert im Vergleich zu Modell 4 erneut, der \gls{cst} war aber immer noch signifikant. Weiter deuteten der \gls{rmsea} und das \gls{srmr} mit Werten ausserhalb des akzeptablen Bereichs auf eine schlechte Modellpassung hin.

Die unstandardisierten Faktorladungen der dynamischen latenten Variable von Modell 7 wurden mit einer quadratischen Funktion ($y=x^2,\,x\in\{1, 2, 3, 4\}$) bestimmt. Der \gls{cst} erkannte keine signifikante Abweichung zwischen der von Modell 7 implizierten und der empirischen Var\-ianz-Ko\-var\-ianz\-ma\-trix. Obwohl der \gls{cfi} im akzeptablen Bereich lag, deuteten der \gls{rmsea} und das \gls{srmr} auf eine schlechte Passung des Modells hin.

In Modell 8 (siehe \autoref{fig:spatial_suppression_fixedlinks_measurement_model}) wurden die unstandardisierten Faktorladungen der dynamischen latenten Variable erneut linear ansteigend fixiert.
Im Gegensatz zu Modell 4 wurde die Faktorladung der ersten Bedingung aber auf 0 gesetzt ($y=x,\,x\in\{0, 1, 2, 3\}$).
Verglichen mit den Modellen 3 bis 7 wich die von Modell 8 implizierte Var\-ianz-Ko\-var\-ianz\-ma\-trix am wenigsten von der empirische Var\-ianz-Ko\-var\-ianz\-ma\-trix ab. Der \gls{cst} war nicht signifikant und der \gls{cfi} und \gls{rmsea} deuteten auf eine gute Modellpassung hin. 
Das \gls{srmr}  lag nicht unter dem von \citet{Hu1999} vorgegebenen Wert von $\leq.08$, fiel aber deshalb  nicht tiefer aus, weil die beiden latenten Variablen unabhängig voneinander gehalten wurden\footnote{Diese Erklärung wurde durch die Tatsache gestützt, dass das \gls{srmr} deutlich tiefer ausfiel, wenn die Unabhängigkeit zwischen der konstanten latenten Variable und der dynamischen latenten Variable aufgehoben wurde, $\upchi^2(3)=1.98$, $p=.58$, $\textnormal{CFI}>.999$, $\textnormal{RMSEA}~=~.036$, $\textnormal{SRMR}~=~.023$. Die beiden latenten Variablen korrelierten in diesem Fall mit $r=-.22$ ($p=.02$). Das \gls{srmr} wurde bei der Beurteilung der folgenden Modelle deshalb nicht mehr berücksichtigt.}. 
Die Varianz der konstanten latenten Variable betrug $0.018$ ($z~=~8.45$, $p~<.001$) und die Varianz der dynamischen latenten Variable betrug $0.002$ ($z~=~5.53$, $p~<~.001$). 
Der relative Anteil dieser beiden Varianzen an der in den manifesten Variablen erklärten Varianz liess sich aufgrund der in konfirmatorischen Faktorenanalysen gegebenen multiplikativen Verknüpfung von Faktorladungen und Varianzen nicht direkt ermitteln. Um die Varianzen miteinander vergleichen zu können, wurde der Einfluss der Faktorladungen auf die Varianzen deshalb mit der Methode von  \citet{Schweizer2011a} kontrolliert. Die Skalierung der Varianzen hat ergeben, dass die konstante latente Variable 72\,\% und die dynamische latente Variable 28\,\% der in den manifesten Variablen gemeinsamen Varianz band.

\begin{figure}[htbp]
	\centering
	
	\begin{tikzpicture}
	[font=\sffamily, scale=2, inner sep=0pt,
	latent/.style	= {circle,draw,inner sep=0pt,minimum size=12mm},
	manifest/.style	= {rectangle,draw,inner sep=0pt,minimum width=12mm,minimum height=12mm},
	paths/.style	= {->, >=stealth, shorten >= 1pt},
	error/.style	= {circle, draw=none, fill=white, minimum size=5mm},
	covar/.style	= {<->, >=stealth, shorten >= 1pt, shorten <= 1pt}]
	
	\node at (1, 2.4)		[latent]	(sk)	{S\textsubscript{kon}};
	\node at (1, 1)			[latent]	(sd)	{S\textsubscript{dyn}};
	
	\node at (-1.5, 2.9)	[manifest]	(s1)	{1.8$^{\circ}$};
	\node at (-1.5, 2.1)	[manifest]	(s2)	{3.6$^{\circ}$};
	\node at (-1.5, 1.3)	[manifest]	(s3)	{5.4$^{\circ}$};
	\node at (-1.5, 0.5)	[manifest]	(s4)	{7.2$^{\circ}$};
	
	
	\node at (-2.3, 2.9)	[error]		(e1)	{\footnotesize .10};
	\node at (-2.3, 2.1)	[error]		(e2)	{\footnotesize .10};
	\node at (-2.3, 1.3)	[error]		(e3)	{\footnotesize .05};
	\node at (-2.3, .5)		[error]		(e4)	{\footnotesize .12};
	
	\draw [paths] (sk.west) -- (s1.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .95{$^{1}$}};
	\draw [paths] (sk.west) -- (s2.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .90{$^{1}$}};
	\draw [paths] (sk.west) -- (s3.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .81{$^{1}$}};
	\draw [paths] (sk.west) -- (s4.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .66{$^{1}$}};
	
	\draw [paths] (sd.west) -- (s1.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .00{$^{0}$}};
	\draw [paths] (sd.west) -- (s2.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .30{$^{1}$}};
	\draw [paths] (sd.west) -- (s3.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .54{$^{2}$}};
	\draw [paths] (sd.west) -- (s4.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .67{$^{3}$}};
	
	\draw [paths] (e1) -- (s1.west);
	\draw [paths] (e2) -- (s2.west);
	\draw [paths] (e3) -- (s3.west);
	\draw [paths] (e4) -- (s4.west);
	
	\end{tikzpicture}
	
	\vspace{.2cm}
	\caption[Modell 8: Fixed-Links-Messmodell der \gls{ssauf}]{Modell 8: Fixed-Links-Messmodell der \gls{ssauf} (\textsf{S}). Eingezeichnet sind die standardisierten Koeffizienten. Hochgestellt sind die fixierten unstandardisierten Faktorladungen. \textsf{\textsubscript{kon}} = konstante latente Variable; \textsf{\textsubscript{dyn}} = dynamische latente Variable.}
	\label{fig:spatial_suppression_fixedlinks_measurement_model}
\end{figure} 

Im Vergleich zum kongenerischen Messmodell (Modell 1) vermochte das Fixed-Links-Messmodell (Modell 8) die empirischen Daten deutlich besser abzubilden. Die bessere Passung von Modell 8 äusserte sich im Vergleich zu Modell 1 in einem nicht-signifikanten $\upchi^2$-Wert, im akzeptablen \gls{cfi} und \gls{rmsea} sowie in zwei zusätzlichen Freiheitsgraden. Modell 8 war Modell 1 somit aufgrund adäquaterer Abbildung der empirischen Daten und höherer Sparsamkeit vorzuziehen.



\subsection{Fixed-Links-Struk\-tur\-glei\-chungs\-mo\-dell}

Als Nächstes wurde Modell 8 mit dem \gls{gfaktor} aus dem \gls{bist} in Verbindung gebracht (Modell 9; siehe \autoref{fig:spatial_suppression_fixedlinks_sem}).
Das Modell bildete die empirischen Varianzen und Kovarianzen gut ab. Der \gls{cst} war nicht signifikant und der \gls{cfi} und \gls{rmsea} lagen im akzeptablen Bereich, $\upchi^2(14)=19.06$, $p=.16$, $\textnormal{CFI}=.99$, $\textnormal{RMSEA}~=~.05$, $\textnormal{SRMR}~=~.09$. 
Der standardisierte Regressionskoeffizient zwischen der konstanten latenten Variable und dem \gls{gfaktor} betrug $\upbeta~=~-.25$ ($p~=~.02$). Der standardisierte Regressionskoeffizient zwischen der dynamischen latenten Variable und dem \gls{gfaktor} betrug $\upbeta~=~-.08$ ($p~=~.43$).
Gemeinsam erklärten die konstante und die dynamische latente Variable der \gls{ssauf} $7\,\%$ der Varianz im \gls{gfaktor}.

\begin{figure}[htbp]
	\centering
	\begin{adjustbox}{width=1\textwidth}
		\begin{tikzpicture}
		[font=\sffamily, scale=2, inner sep=0pt,
		latent/.style	= {circle,draw,inner sep=0pt,minimum size=12mm},
		manifest/.style	= {rectangle,draw,inner sep=0pt,minimum width=12mm,minimum height=12mm},
		paths/.style	= {->, >=stealth, shorten >= 1pt},
		error/.style	= {circle, draw=none, fill=white, minimum size=5mm},
		covar/.style	= {<->, >=stealth, shorten >= 1pt, shorten <= 1pt}]
		
		\node at (1, .7)		[latent]	(sk)	{S\textsubscript{kon}};
		\node at (1, -.7)		[latent]	(sd)	{S\textsubscript{dyn}};
		\node at (2.5, 0)		[latent]	(g)		{\textrm{\textit{g}}};
		
		\node at (-1.5, 1.2)	[manifest]	(s1)	{1.8$^{\circ}$};
		\node at (-1.5, 0.4)	[manifest]	(s2)	{3.6$^{\circ}$};
		\node at (-1.5, -.4)	[manifest]	(s3)	{5.4$^{\circ}$};
		\node at (-1.5, -1.2)	[manifest]	(s4)	{7.2$^{\circ}$};
		
		
		\node at (4, .8)		[manifest]	(k)		{Kap};
		\node at (4, 0)			[manifest]	(b)		{Bea};
		\node at (4, -.8)		[manifest]	(m)		{Mer};
		
		\node at (-2.3, 1.2)	[error]		(e1)	{\footnotesize .10};
		\node at (-2.3, 0.4)	[error]		(e2)	{\footnotesize .10};
		\node at (-2.3, -.4)	[error]		(e3)	{\footnotesize .05};
		\node at (-2.3, -1.2)	[error]		(e4)	{\footnotesize .12};
		
		
		
		\node at (4.8, .8)		[error]		(e9)	{\footnotesize .29};
		\node at (4.8, 0)		[error]		(e10)	{\footnotesize .47};
		\node at (4.8, -.8)		[error]		(e11)	{\footnotesize .71};
		
		\node at (2.5, 0.8)		[error]		(e12)	{\footnotesize .93};
		
		\draw [paths] (sk.west) -- (s1.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .95{$^{1}$}};
		\draw [paths] (sk.west) -- (s2.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .90{$^{1}$}};
		\draw [paths] (sk.west) -- (s3.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .81{$^{1}$}};
		\draw [paths] (sk.west) -- (s4.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .66{$^{1}$}};
		
		\draw [paths] (sd.west) -- (s1.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .00{$^{0}$}};
		\draw [paths] (sd.west) -- (s2.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .30{$^{1}$}};
		\draw [paths] (sd.west) -- (s3.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .54{$^{2}$}};
		\draw [paths] (sd.west) -- (s4.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .67{$^{3}$}};
		
		
		\draw [paths] (g.east) -- (k.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .84{$^{1}$}\hphantom{$^**$}};	
		\draw [paths] (g.east) -- (b.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .73{$^{***}$}};	
		\draw [paths] (g.east) -- (m.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .54{$^{***}$}};	
		
		\draw [paths] (e1) -- (s1.west);
		\draw [paths] (e2) -- (s2.west);
		\draw [paths] (e3) -- (s3.west);
		\draw [paths] (e4) -- (s4.west);
		
		
		\draw [paths] (e9) -- (k.east);
		\draw [paths] (e10) -- (b.east);
		\draw [paths] (e11) -- (m.east);
		
		\draw [paths] (e12) -- (g.north);
		
		
		\draw [paths] (sk)  -- (g.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize --.25{$^{*}$}};
		\draw [paths] (sd)  -- (g.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize --.08\hphantom{$^{*}$}};
		
		\end{tikzpicture}
	\end{adjustbox}
	
	\vspace{.2cm}
	\caption[Modell 9: Fixed-Links-Strukturgleichungsmodell zur Vorhersage des \gls{gfaktor}s durch die \gls{ssauf}]{Modell 9: Latenter Zusammenhang zwischen dem Fixed-Links-Messmodell (Modell 8) der \gls{ssauf} (\textsf{S}) und dem \gls{gfaktor} aus dem \gls{bist}. Eingezeichnet sind die standardisierten Koeffizienten. Hochgestellt sind die fixierten unstandardisierten Faktorladungen. \textsf{\textsubscript{kon}} = konstante latente Variable; \textsf{\textsubscript{dyn}} = dynamische latente Variable; \textsf{Kap} = Kapazität; \textsf{Bea} = Bearbeitungsgeschwindigkeit; \textsf{Mer} = Merkfähigkeit.\\
	$^{*}p~<~.05$. $^{***}p~<~.001$.
	}
	\label{fig:spatial_suppression_fixedlinks_sem}
\end{figure} 

Im Vergleich zum klassischen Strukturgleichungsmodell (Modell 2) bildete das Fixed-Links-Struk\-tur\-glei\-chungs\-mo\-dell (Modell 9) die empirischen Daten deutlich besser ab. Die bessere Passung von Modell 9 äusserte sich im Vergleich zu Modell 2 in einem nicht-signifikanten $\upchi^2$-Wert, im akzeptablen \gls{cfi} und \gls{rmsea} sowie in einem zusätzlichen Freiheitsgrad. Bezüglich der Varianzaufklärung im \gls{gfaktor} waren sich Modell 2 ($5\,\%$) und Modell 9 ($7\,\%$)  vergleichsweise ähnlich. Modell 9 war Modell 2 folglich aufgrund adäquaterer Abbildung der empirischen Daten und höherer Sparsamkeit vorzuziehen. 

Abschliessend zur vierten Fragestellung kann Folgendes festgehalten werden: Auf Messmodellebene vermochte das \gls{flm} (Modell 8) die empirischen Daten der \gls{ssauf} besser zu beschreiben als das kongenerische Messmodell (Modell 1). Auch im Zusammenhang mit dem \gls{gfaktor} war die Beschreibung der empirischen Daten mittels Fixed-Links-Struk\-tur\-glei\-chungs\-mo\-dell (Modell 9) dem klassischen Strukturgleichungsmodell (Modell 2) deutlich überlegen. 
In Modell 9 zeigte sich zwischen der konstanten latenten Variable der \gls{ssauf} und dem \gls{gfaktor} ein schwacher bis mittlerer negativer Zusammenhang. Tiefe Faktorwerte auf der konstanten latenten Variable waren demnach tendenziell mit hohen Faktorwerten im \gls{gfaktor} verbunden.
Zwischen der dynamischen latenten Variable der \gls{ssauf} und dem \gls{gfaktor} bestand ein so schwacher Zusammenhang, dass er bei der gewählten Irrtumswahrscheinlichkeit von $5\,\%$ nicht von 0 unterschieden werden konnte. 














\section{5. Fragestellung}

Mit der fünften Fragestellung sollte die Frage geklärt werden, ob die \gls{ssauf} zur Aufklärung individueller Intelligenzunterschiede neuartige Erklärungsmöglichkeiten bietet oder ob die \gls{ha} den Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz vollständig zu erklären vermag. Geprüft wurde diese Frage auf manifester und latenter Ebene.

\subsection{Analyse auf manifester Ebene}

\subsubsection*{Die Vorhersage psychometrischer Intelligenz durch die Aufgabenbedingungen der Hick- und \gls{ssauf}}

Die korrelative Analyse der Aufgaben in \autoref{subsec:Zusammenhänge}  hat gezeigt, dass alle vier Bedingungen der \gls{ha} und drei von vier Bedingungen der \gls{ssauf} mit dem \gls{zwert} des \gls{bist}s zusammenhingen. Auch zwischen den Bedingungen der beiden Aufgaben bestanden signifikante Zusammenhänge. 
Um diese Abhängigkeiten bei der Vorhersage des \gls{zwert}s zu berücksichtigen, wurden die Bedingungen in Gruppen zusammengefasst und nacheinander blockweise in eine multiple Regressionsanalyse aufgenommen.

Ausgangslage für die Beantwortung der Fragestellung bildete Modell 10, in welchem der \gls{zwert} des \gls{bist}s mit den vier Bedingungen der \gls{ha} vorhergesagt wurde (siehe \autoref{tab:multiple_regression_all_conditions}). Die Regressionsanalyse hat ergeben, dass die Prädiktoren gemeinsam mit $9\,\%$ einen signifikanten Varianzanteil im \gls{zwert} erklärten, $F(4,\,172)=4.40$, $p=.002$, $R^2=.09$. Bei einer Kontrolle für die Zusammenhänge zwischen den Bedingungen sagte jedoch keiner der Prädiktoren den \gls{zwert} signifikant vorher (alle $p\textnormal{s}>.22$). Der Umstand, dass die einzelnen Prädiktoren nicht signifikante Regressionskoeffizienten aufwiesen, das gesamte Regressionsmodell hingegen einen signifikanten Varianzanteil im \gls{zwert} erklärte, konnte durch die starken Abhängigkeiten zwischen den Prädiktoren (Multikollinearität) erklärt werden \citep[S. 686]{Eid2013}. Während Multikollinearität die Interpretation der einzelnen Regressionskoeffizienten erschwert, ist sie bei einer reinen Prädiktion eines Kriteriums, wie sie hier vorlag, unproblematisch.

\begin{table}[tb]
	\centering
	\captionsetup{labelsep = none}
	\caption[Multiple Regression zur Vorhersage des \gls{zwert}s des \gls{bist}s durch die Bedingungen der Spa\-ti\-al-Sup\-pres\-sion- und der \gls{ha}]{\newline  \textit{Multiple Regression zur Vorhersage des \gls{zwert}s des \gls{bist}s durch die Bedingungen der \gls{ha} (Modell 10) respektive durch die Bedingungen der Hick- und der \gls{ssauf} (Modell 11)} \vspace{.2cm}}
	\label{tab:multiple_regression_all_conditions}
	\newcommand{\rowgroup}[1]{\hspace{-1em}#1}
	\newcommand\Tstrut{\rule{0pt}{2.1ex}}       % top strut http://tex.stackexchange.com/questions/65919/space-between-rows-in-a-table - not implemented!
	\begin{threeparttable}
		\begin{tabular}{
				>{\quad}
				l
				S[table-format = 1.4, add-integer-zero=false]
				S[table-format = 1.4, add-integer-zero=false]
				S[table-format = 1.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				p{.001cm}
				S[table-format = 1.2, add-integer-zero=false,table-space-text-post = $^{**}$]
				S[table-format = 0.2, add-integer-zero=false]
				S[table-format = 1.2, add-integer-zero=false]
				S[table-format = 0.2, add-integer-zero=false]
				>{\centering\arraybackslash}p{1.2cm}
			}
			\hline
			
			{Prädiktor}	&	{\textit{B}}	&	{\textit{SE}(\textit{B})}	&	{$\upbeta$}	&	{$p$}	& &	{$F$}	&	{$R^2$}	& {$\Delta F$} & {$\Delta R^2$}	\\
			
			\hline
			
			\rowgroup{Modell 10}	&		&			&			&			&	&	4.40{$^{**}$}	&	.09		&					\\
			0-bit				&	0.0008	&	0.0020	&	.04		&	.70		&	&					&			&					\\
			1-bit				&	-0.0027	&	0.0022	&	-.16	&	.22		&	&					&			&					\\
			2-bit				&	-0.0008	&	0.0014	&	-.08	&	.56		&	&					&			&					\\
			2.58-bit			&	-0.0010	&	0.0010	&	-.12	&	.36		&	&					&			&					\\
			
			\rule{0pt}{4ex}			%  EXTRA vertical height
			
			\rowgroup{Modell 11}	&		&			&			&			&	&	2.71{$^{**}$}	&	.11		& 1.02	&	.02		\\
			0-bit				&	0.0018	&	0.0021	&	.10		&	.40		&	&					&			&					\\
			1-bit				&	-0.0031	&	0.0022	&	-.19	&	.16		&	&					&			&					\\
			2-bit				&	-0.0009	&	0.0014	&	-.09	&	.51		&	&					&			&					\\
			2.58-bit			&	-0.0008	&	0.0010	&	-.11	&	.41		&	&					&			&					\\
			$1.8^{\circ}$		&	-0.0536	&	0.5444	&	-.01	&	.92		&	&					&			&					\\
			$3.6^{\circ}$		&	-0.4192	&	0.7062	&	-.11	&	.55		&	&					&			&					\\
			$5.4^{\circ}$		&	-0.1077	&	0.7183	&	-.03	&	.88		&	&					&			&					\\
			$7.2^{\circ}$		&	0.0157	&	0.4532	&	.01		&	.97		&	&					&			&					\\
			\hline
		\end{tabular}
		
		\begin{tablenotes}[flushleft]
			\footnotesize				% font size
			\setlength\labelsep{0pt}	% no indent on second line
			\item \textit{Anmerkungen}. $B$ = unstandardisiertes Regressionsgewicht; $\upbeta$ = standardisiertes Regressionsgewicht; $F$ = $F$-Wert des Regressionsmodells; $R^2$ = erklärte Varianz; $\Delta F$ = $F$-Wert der Veränderung der erklärten Varianz; $\Delta R^2$ = zusätzlich erklärte Varianz.
			\item {$^{**}$}$p<.01$ (zweiseitig).
		\end{tablenotes}
	\end{threeparttable}
\end{table}

Modell 11 beinhaltete als Prädiktoren sowohl die Bedingungen der Hick- als auch die der \gls{ssauf} (siehe \autoref{tab:multiple_regression_all_conditions}). Zusammen sagten die Prädiktoren den \gls{zwert} signifikant vorher und erklärten $11\,\%$ der Varianz im \gls{zwert}, $F(8,\,168)=2.71$, $p=.008$, $R^2=.11$. 
Keiner der Prädiktoren sagte den \gls{zwert} hingegen alleine signifikant vorher (alle $p\textnormal{s}>.16$). 

Um zu prüfen, ob die Bedingungen der \gls{ssauf} gegenüber der \gls{ha} einen inkrementellen Beitrag zur Varianzaufklärung im \gls{zwert} des \gls{bist}s leisteten, wurde der Zuwachs an erklärter Varianz im \gls{zwert} zwischen Modell 10 und Modell 11 auf Signifikanz getestet. 
Dabei hat sich ergeben, dass $\Delta R^2=.02$ kein signifikanter Zuwachs an erklärter Varianz darstellte, $F(4,\,168)=1.02$, $p=.40$.
Die Bedingungen der \gls{ssauf} haben somit auf Ebene der Aufgabenbedingungen keinen inkrementellen Beitrag zur Aufklärung individueller Intelligenzunterschiede geleistet.


%Auf eine schrittweise Aufnahme in die Regressionsanalyse wurde bewusst verzichtet, weil sie zu Verzerrungen führt \citep[S. 68]{Harrell2015}.
% Multikollinearität \citep[S. 686]{Eid2013}









\subsubsection*{Die Vorhersage psychometrischer Intelligenz durch die Aufgabenparameter der Hick- und \gls{ssauf} \label{subsec:Aufgabenparameter_Hick}}

Um den \gls{zwert} des \gls{bist}s mit den abgeleiteten Aufgabenparametern beider Aufgaben vorherzusagen, mussten die Aufgabenparameter der \gls{ha} noch bestimmt werden (für die Bestimmung der Aufgabenparameter der \gls{ssauf} siehe \autoref{sec:2Fragestellung}). 
%\textcolor{red}{
%Die Reaktionszeit (RZ) in einer Auswahlaufgabe (wie sie die \gls{ha} darstellt) kann gemäss \citet[S. 105]{Jensen1987a} mit der linearen Funktion $RZ=a+b\log_{2}n$ beschrieben werden, wobei $a$ durch den y-Ach\-sen\-ab\-schnitt, $b$ durch die Steigung der Regressionsgeraden und $\log_{2}\,n$ durch den Logarithmus zur Basis 2 der Anzahl Antwortalternativen ($n$) bestimmt ist.
%Das Produkt $\log_{2}\,n$ wurde von \citet{Hick1952} als \textit{Bit} bezeichnet und entspricht derjenigen Menge an Information, welche die Entscheidung zwischen zwei gleich wahrscheinlichen Antwortalternativen ermöglicht\footnote{Entsprechend dieser Definition gab das \textit{Bit} den Bedingungen der \gls{ha} ihre Namen: In der 0-bit-Bedingung steht eine Antwortalternative zur Verfügung ($\log_{2}\,1=0$), in der 1-bit-Bedingung zwei Antwortalternativen ($\log_{2}\,2=1$), in der 2-bit-Bedingung vier Antwortalternativen ($\log_{2}\,4=2$) und in der 2.58-bit-Bedingung stehen sechs Antwortalternativen zur Verfügung ($\log_{2}\,6=2.58$).} \citep[siehe auch][S. 27]{Jensen2006}.
%}

Dafür wurden die Reaktionszeiten der \gls{ha} für jede Person mit einer linearen Regression der Form $y=a+b\log_{2}n$ \citep[S. 105]{Jensen1987a} vorhergesagt (siehe \autoref{fig:hick_linear_model}). Deskriptive Angaben zu den daraus resultierenden Parametern, dem y-Ach\-sen\-ab\-schnitt $a$ und der Steigung $b$, sind in \autoref{tab:hick_linear_model} zu finden.
\begin{table}[b]
	\centering
	\captionsetup{labelsep = none}
	\caption[Deskriptive Angaben zur linearen Regression für die Vorhersage der Reaktionszeiten durch die Bits der \gls{ha}]{\newline  \textit{Deskriptive Angaben zur linearen Regression ($y=a + b\log_{2}\,n$) für die Vorhersage der Reaktionszeiten durch die Anzahl Antwortalternativen n der \gls{ha} und Kennwerte zur Verteilungsform der Daten} \vspace{.2cm}}
	\label{tab:hick_linear_model}
	\begin{threeparttable}
		\begin{tabular}{
				l
				S[table-format = 3.0]
				S[table-format = 2.0]
				S[table-format = 3.0]
				S[table-format = 3.0]
				S[table-format = 1.2]
				S[table-format = 1.2]
				S[table-format = <0.3, add-integer-zero=false]
			}
			\hline
			\multicolumn{1}{c}{Parameter}	& 	\textit{M}	& \textit{SD}	&	{Min}	&	{Max} 	&	{Schiefe}	&	{Kurtosis} & {S-W \textit{p}-Wert}	\\
			\hline
			$a$			&	232			&	28			&	168		&	347		&	1.18		&	2.95		& 		<.001			\\
			$b$			&	76			&	22			&	33		&	142		&	0.53		&	-0.12		& 		.003			\\
			\hline
		\end{tabular}
		
		\begin{tablenotes}[flushleft]
			\footnotesize				% font size
			\setlength\labelsep{0pt}	% no indent on second line
			\item \textit{Anmerkungen.} \textit{a}~=~y-Ach\-sen\-ab\-schnitt (in ms); \textit{b}~=~Steigung; Min~=~Minimum; Max~=~Maximum; S-W~=~Shapiro-Wilk-Test.
		\end{tablenotes}
	\end{threeparttable}
\end{table}
Als Mass für die Anpassungsgüte des Modells an die Daten wurde analog zum Vorgehen bei der \gls{ssauf} für jede Person der \gls{rmse} berechnet. Dabei hat sich gezeigt, dass sich ein lineares Modell zur Beschreibung der Daten für einen grossen Teil der \glspl{vp} gut eignete (siehe \autoref{fig:hick_rmse_density}). Der Median betrug $12$~ms und das dritte Quartil lag bei $19$~ms (Minimum~$=0.96$~ms, Maximum~$=54.23$~ms).


\begin{figure}[t]
	\centering
	\begin{adjustbox}{width=1\textwidth}
		\input{tikzDevice/hick_linear_model.tex}
	\end{adjustbox}
	\caption[Lineares Modell zur Vorhersage der Reaktionszeit durch das Bit der \gls{ha}]{Linearer Einfluss des Bits auf die Reaktionszeit in der \gls{ha}. Eingezeichnet sind die Mittelwerte $\pm$ Standardfehler der Mittelwerte. n = Anzahl Antwortalternativen. $y = 232 + 76\log_{2}\,n$.}
	\label{fig:hick_linear_model}
\end{figure}



%Über alle \glspl{vp} gemittelt betrug $R^2=.96$, wobei im Gegensatz zur regressionsanalytischen Analyse der \gls{ssauf} (siehe \autoref{sec:2Fragestellung}) geringere individuelle Variabilität (\gls{sd} $=.04$, Min = .732, Max = .999) bestand.

\begin{figure}[t]
	\centering
	%	\captionsetup{font = small}
	\begin{adjustbox}{width=1\textwidth}
		\input{tikzDevice/hick_rmse_density.tex}
	\end{adjustbox}
	\caption[Dichtefunktion des aus der \gls{ha} mit einer linearen Regression abgeleiteten \gls{rmse}]{Dichtefunktion des \acrlong{rmse} (\gls{rmse}; in Millisekunden), der sich aus dem linearen Modell zur Beschreibung der Reaktionszeiten der \gls{ha} ergeben hat. Alle Datenpunkte sind auf der x-Achse mit vertikalen Strichen markiert.}
	\label{fig:hick_rmse_density}
\end{figure}

%\todo[color=green!40, fancyline]{Caption inhaltlich korrekt?}

Wie bei der \gls{ssauf} (siehe \autoref{sec:2Fragestellung}) wurde der Zusammenhang zwischen den Aufgabenparametern (y-Ach\-sen\-ab\-schnitt und Steigung) und dem \gls{zwert} des \gls{bist}s in Abhängigkeit des \gls{rmse} betrachtet. Die Analysen haben ergeben, dass der y-Ach\-sen\-ab\-schnitt und der \gls{zwert} bei \gls{rmse}-Grenzwerten zwischen $9.6$ und $10.4$~ms ($r = -.28$ bis $ -.29$, alle $p\textnormal{s} < .03$), zwischen $11$ und $15.7$~ms ($r = -.24$ bis $ -.31$, alle $p\textnormal{s} < .04$), zwischen $17.2$ und $22.2$~ms ($r = -.17$ bis $ -.20$, alle $p\textnormal{s} < .04$) sowie ab $23.3$~ms ($r = -.15$ bis $ -.17$, alle $p\textnormal{s} < .049$) signifikant negativ miteinander \todo[color=green!40, fancyline]{Caption der Abbildung inhaltlich korrekt?} korrelierten (siehe \autoref{fig:hick_rmse_cutoff}a). In den erwähnten Bereichen war ein tiefer y-Ach\-sen\-ab\-schnitt folglich tendenziell mit einem hohen \gls{zwert} verbunden. Eine visuelle Inspektion des Verlaufs liess keine Aussage darüber zu, ob der \gls{rmse}-Grenzwert einen positiven oder negativen Einfluss auf die Höhe des Zusammenhangs ausübte.


\begin{figure}[htbp]
	\centering
	%	\captionsetup{font = small}
	\begin{adjustbox}{width=1\textwidth}
		\subfloat[Test][Zusammenhang ($r$) zwischen dem y-Ach\-sen\-ab\-schnitt und dem \gls{zwert} des \gls{bist}s.]{\input{tikzDevice/hick_rmse_cutoff_intercept_zscore.tex}}
	\end{adjustbox}
	\newline
	\begin{adjustbox}{width=1\textwidth}
		\subfloat[Test][Zusammenhang ($r$) zwischen der Steigung und dem \gls{zwert} des \gls{bist}s.]{\input{tikzDevice/hick_rmse_cutoff_slope_zscore.tex}}
	\end{adjustbox}
	
	\caption[Einfluss des \gls{rmse}-Grenzwerts der \gls{ha} auf den Zusammenhang zwischen dem y-Ach\-sen\-ab\-schnitt, der Steigung und dem \gls{zwert} des \gls{bist}s]{Einfluss des \gls{rmse}-Grenzwerts auf die Zusammenhänge der aus der \gls{ha} mit einer linearen Regression abgeleiteten Aufgabenparameter ($a$) y-Ach\-sen\-ab\-schnitt und ($b$) Steigung mit dem \gls{zwert} des \gls{bist}s. Die durchgezogene Linie kennzeichnet den Verlauf des Zusammenhangs. Der graue Bereich beschreibt das $95\,\%$-Konfidenzintervall.}
	\label{fig:hick_rmse_cutoff}
\end{figure}

Die Steigung und der \gls{zwert} des \gls{bist}s korrelierten bei \gls{rmse}-Grenzwerten zwischen $8.9$ und $10.7$~ms ($r = -.24$ bis $ -.37$, alle $p\textnormal{s} < .048$) und ab $15.7$~ms ($r = -.19$ bis $ -.28$, alle $p\textnormal{s} < .046$) signifikant negativ miteinander (siehe \autoref{fig:hick_rmse_cutoff}b). In diesen Bereichen waren geringe Steigungen folglich tendenziell mit hohen \gls{zwert}en verbunden. Wie beim Zusammenhang zwischen dem y-Ach\-sen\-ab\-schnitt und dem \gls{zwert} konnte eine visuelle Inspektion des Verlaufs keine klaren Hinweise dafür liefern, ob der \gls{rmse}-Grenzwert einen positiven oder negativen Einfluss auf die Höhe des Zusammenhangs zwischen der Steigung und dem \gls{zwert} ausübte.
Betrachtet man die mit der Gesamtstichprobe ermittelten Ergebnisse, kann festgehalten werden, dass sowohl der y-Ach\-sen\-ab\-schnitt ($r=-.17$, $p=.02$) als auch die Steigung ($r=-.23$, $p=.002$) der \gls{ha} schwach negativ mit dem \gls{zwert} des \gls{bist}s korrelierten. %Die Zusammenhänge der Aufgabenparameter der Hick- und der \gls{ssauf} mit dem \gls{zwert} des \gls{bist}s sind in  zu finden.
%Diese Zusammenhänge waren vergleichbar mit den von \citet{Jensen1987a} berichteten Ergebnissen.

Nachdem die Aufgabenparameter der \gls{ha} bestimmt waren, konnte der \gls{zwert} des \gls{bist}s mit den Aufgabenparameter der Hick- und der \gls{ssauf} vorhergesagt werden. Für diese multiple Regressionsanalyse wurde die Gesamtstichprobe verwendet, weil die Analysen zum Einfluss des \gls{rmse}-Grenzwerts auf die Zusammenhänge der Aufgabenparameter mit dem \gls{zwert} kein eindeutiges Ergebnis lieferten (siehe \autoref{fig:spatial_suppression_asymtote_slope_zscore} und \autoref{fig:hick_rmse_cutoff}). Um die Abhängigkeiten der Aufgabenparameter innerhalb und zwischen den beiden Aufgaben (siehe \autoref{tab:suppression_hick_regression_correlations}) bei der Vorhersage des \gls{zwert}s zu berücksichtigen, wurden die Aufgabenparameter in Gruppen zusammengefasst und nacheinander blockweise in die multiple Regressionsanalyse aufgenommen. 

\begin{table}[b] % see http://tex.stackexchange.com/questions/247921/different-column-widths-under-a-multicolumn-prevent-appropriate-centering
	\centering
	\captionsetup{labelsep = none}
	\caption[Produkt-Moment-Korrelationen zwischen dem \gls{zwert} des \gls{bist}s und den Aufgabenparameter der Spa\-ti\-al-Sup\-pres\-sion- und der \gls{ha}]{\newline  \textit{Produkt-Moment-Korrelationen zwischen den aus der Spatial-Suppression- und der \gls{ha} regressionsanalytisch abgeleiteten Aufgabenparametern und dem \textit{z}-Wert des \gls{bist}s} \vspace{.2cm}}
	\label{tab:suppression_hick_regression_correlations}
	\begin{adjustbox}{width=1\textwidth}
		\begin{threeparttable}
			\newlength{\tempdima}
			\settowidth{\tempdima}{\gls{ha}}% compute width needed
			\addtolength{\tempdima}{-2\tabcolsep}% minus default column sep
			\newlength{\tempdimb}
			\settowidth{\tempdimb}{\gls{ssauf}}% compute width needed
			\addtolength{\tempdimb}{-2\tabcolsep}% minus default column sep
			\begin{tabular}{
%				p{.1cm}
				l
				l
				S[table-format = 1.2, add-integer-zero=false, table-space-text-post = $^{*}$]
				S[table-format = 1.2, add-integer-zero=false, table-space-text-post = $^{**}$]
				p{.001cm}
				S[table-format = 1.2, add-integer-zero=false,table-space-text-post = $^{***}$]
				S[table-format = 0.2, add-integer-zero=false]
				p{.001cm}
				S[table-format = 0.0, add-integer-zero=false]
				>{\centering\arraybackslash}p{1.2cm}
				}
			\hline
				&		& 	\multicolumn{2}{c}{\gls{ha}}	&	&	\multicolumn{2}{c}{\gls{ssauf}}	&	&	\multicolumn{1}{c}{\gls{bist}}	\\
			\cline{3-4}
			\cline{6-7}
			\cline{9-9}

			& \multicolumn{1}{c}{Parameter} & {\makebox[0.5\tempdima]{1}} & {\makebox[0.5\tempdima]{2}} && {\makebox[0.5\tempdimb]{3}} & {\makebox[0.5\tempdimb]{4}} && {5}\\
			\hline
		1	&	y-Achsenabschnitt	&				&					&& 					&		&&	\\
		2	&	Steigung			&	-.08		&					&& 					&		&&	\\
		\rule{0pt}{4ex}%  EXTRA vertical height
		3	&	Asymptote			&	.16{$^{*}$}	&	.03				&&					&		&&	\\
		4	&	Steigung			&	-.02		&	-.03			&&	-.57{$^{***}$}	&		&&	\\
		\rule{0pt}{4ex}%  EXTRA vertical height
		5	&	\textit{z}-Wert		&	-.17{$^{*}$}&	-.23{$^{**}$}	&&	-.16{$^{*}$}	&	.00	&&	\\
			\hline
			\end{tabular}

			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkung}. \gls{zwert} = Mittelwert aller 18 \textit{z}-standardisierten Subtests.
				\item {$^{*}$}$p<.05$. {$^{**}$}$p<.01$. {$^{***}$}$p<.001$ (zweiseitig).
			\end{tablenotes}
		\end{threeparttable}
	\end{adjustbox}
\end{table}



Grundlage für die Beantwortung der Fragestellung bildete Modell 12, in welchem der \gls{zwert} des \gls{bist}s mit den Aufgabenparametern der \gls{ha} vorhergesagt wurde (siehe \autoref{tab:multiple_regression_all_parameters}).
Die Regressionsanalyse hat ergeben, dass die Prädiktoren gemeinsam mit $9\,\%$ einen signifikanten Varianzanteil im \gls{zwert} erklärten, $F(2,\,174)=8.52$, $p<.001$, $R^2=.09$. Bei einer Kontrolle für den Zusammenhang zwischen den Aufgabenparametern hat sich ergeben, dass sowohl der y-Ach\-sen\-ab\-schnitt ($\upbeta=-.19$, $p=.009$) als auch die Steigung ($\upbeta=-.24$, $p<.001$) den \gls{zwert} signifikant vorhersagten. Tiefe y-Ach\-sen\-ab\-schnitte und geringe Steigungen gingen somit tendenziell mit hohen \gls{zwert}en einher.



Model 13 beinhaltete als Prädiktoren die Aufgabenparameter der Hick- und der \gls{ssauf} (siehe \autoref{tab:multiple_regression_all_parameters}). 
Die Regressionsanalyse hat ergeben, dass die Prädiktoren gemeinsam mit $12\,\%$ einen signifikanten Varianzanteil im \gls{zwert} vorhersagten, $F(4,\,172)=5.58$, $p<.001$, $R^2=.12$. Bei einer Kontrolle für die Zusammenhänge zwischen den Aufgabenparametern hat sich gezeigt, dass der y-Ach\-sen\-ab\-schnitt der \gls{ha}  ($\upbeta~=~-.16$, $p~=~.03$), die Steigung der \gls{ha} ($\upbeta~=~-.24$, $p~=~.001$) und die Asymptote der \gls{ssauf} ($\upbeta~=~-.20$, $p~=~.03$) den \gls{zwert} signifikant vorhersagten. Die Steigung der \gls{ssauf} war mit $\upbeta~=~-.12$ ($p~=~.17$) kein signifikanter Prädiktor des \gls{zwert}s.

\begin{table}[b]
	\centering
	\captionsetup{labelsep = none}
	\caption[Multiple Regressionen zur Vorhersage des \gls{zwert}s des \gls{bist}s durch die Aufgabenparameter der Spa\-ti\-al-Sup\-pres\-sion- und der \gls{ha}]{\newline  \textit{Multiple Regressionen zur Vorhersage des \gls{zwert}s des \gls{bist}s durch die Aufgabenparameter der \gls{ha} (Modell 12) respektive durch die Aufgabenparameter der Hick- und der \gls{ssauf} (Modell 13)} \vspace{.2cm}}
	\label{tab:multiple_regression_all_parameters}
	\newcommand{\rowgroup}[1]{\hspace{-1em}#1}
	\newcommand\Tstrut{\rule{0pt}{2.1ex}}       % top strut http://tex.stackexchange.com/questions/65919/space-between-rows-in-a-table - not implemented!
	\begin{adjustbox}{width=1\textwidth}
		\begin{threeparttable}
			\begin{tabular}{
					>{\quad}
					l
					S[table-format = 1.4]
					S[table-format = 0.4]
					S[table-format = 1.2, add-integer-zero=false]
					S[table-format = <0.3, add-integer-zero=false]
					p{.001cm}
					S[table-format = 1.2, table-space-text-post = $^{***}$]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 1.2]
					S[table-format = 0.2, add-integer-zero=false]
					>{\centering\arraybackslash}p{1.2cm}
				}
				\hline
				
				\multicolumn{1}{c}{Prädiktor}	&	{\textit{B}}	&	{\textit{SE}(\textit{B})}	&	{$\upbeta$}	&	{$p$}	& &	{$F$}	&	{$R^2$}	& {$\Delta F$} & {$\Delta R^2$}	\\
				
				\hline
				
				\rowgroup{Modell 12}	&			&			&			&			&	&	8.52{$^{***}$}	&	.09		&					\\
				H-y-Achsenabschnitt		&	-0.0037	&	0.0014	&	-.19	&	.009	&	&					&			&					\\
				H-Steigung				&	-0.0058	&	0.0017	&	-.24	&	<.001	&	&					&			&					\\
				
				\rule{0pt}{4ex}			%  EXTRA vertical height
				
				\rowgroup{Modell 13}	&			&			&			&			&	&	5.58{$^{***}$}	&	.12		& 2.49	&	.03		\\
				H-y-Achsenabschnitt		&	-0.0031	&	0.0014	&	-.16	&	.03		&	&					&			&					\\
				H-Steigung				&	-0.0057	&	0.0017	&	-.24	&	.001	&	&					&			&					\\
				S-Asymptote				&	-0.0037	&	0.0017	&	-.20	&	.03		&	&					&			&					\\
				S-Steigung				&	-0.7887	&	0.5695	&	-.12	&	.17		&	&					&			&					\\
				\hline
			\end{tabular}
			
			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkungen}. $B$ = unstandardisiertes Regressionsgewicht; $\upbeta$ = standardisiertes Regressionsgewicht; $F$~=~$F$-Wert des Regressionsmodells; $R^2$ = erklärte Varianz; $\Delta F$ = $F$-Wert der Veränderung der erklärten Varianz; $\Delta R^2$ = zusätzlich erklärte Varianz; H = \gls{ha}; S = \gls{ssauf}.
				\item {$^{***}$}$p<.001$ (zweiseitig).
			\end{tablenotes}
		\end{threeparttable}
	\end{adjustbox}
\end{table}

Um zu prüfen, ob die Aufgabenparameter der \gls{ssauf} gegenüber denjenigen der \gls{ha} einen inkrementellen Beitrag zur Varianzaufklärung im \gls{zwert} des \gls{bist}s leisteten, wurde der Zuwachs an erklärter Varianz im \gls{zwert} zwischen Modell 12 und Modell 13 auf Signifikanz getestet. 
Dabei hat sich ergeben, dass $\Delta R^2=.03$ kein signifikanter Zuwachs an erklärter Varianz darstellte, $F(2,\,172)=2.49$, $p=.09$.
Die Asymptote und die Steigung der \gls{ssauf} haben folglich auf Ebene der Aufgabenparameter keinen inkrementellen Beitrag zur Aufklärung individueller Intelligenzunterschiede geleistet.









\subsection{Analyse auf latenter Ebene}

\subsubsection*{Mess- und Strukturgleichungsmodelle}

Bevor die \gls{ha} mit der \gls{ssauf} und dem \gls{gfaktor} in Verbindung gesetzt werden konnte, musste für die \gls{ha} das kongenerische Messmodell bestimmt werden. Das Modell (Modell 14; siehe \autoref{fig:hick_congeneric_model}) 
bildete die empirischen Varianzen und Kovarianzen der \gls{ha} schlecht ab.  Der \gls{cst} zeigte eine überzufällig hohe Abweichung zwischen der theoretischen und der empirischen Var\-ianz-Ko\-var\-ianz\-ma\-trix an und der \gls{cfi} und der \gls{rmsea} lagen weit ausserhalb des akzeptablen Bereichs, $\upchi^2(2)=42.58$, $p<.001$, $\textnormal{CFI}=.87$, $\textnormal{RMSEA}=.33$, $\textnormal{SRMR}=.06$.

\begin{figure}[hbp]
	\centering
	\begin{tikzpicture}
	[font=\sffamily, scale=2, inner sep=0pt,
	latent/.style	= {circle, draw, inner sep=0pt, minimum size=12mm},
	manifest/.style	= {rectangle, draw, inner sep=0pt, minimum width=12mm, minimum height=12mm},
	paths/.style	= {->, >=stealth, shorten >= 1pt},
	error/.style	= {circle, draw=none, fill=white, minimum size=5mm},
	covar/.style	= {<->, >=stealth, shorten >= 1pt, shorten <= 1pt}]
	
	\node at (0, 1.7)		[latent]	(hick)	{H};
	
	\node at (-1.5, 2.9)	[manifest]	(h0)	{0-bit};
	\node at (-1.5, 2.1)	[manifest]	(h1)	{1-bit};
	\node at (-1.5, 1.3)	[manifest]	(h2)	{2-bit};
	\node at (-1.5, 0.5)	[manifest]	(h3)	{2.58-bit};
	
	\node at (-2.3, 2.9)	[error]		(e1)	{\footnotesize .55};
	\node at (-2.3, 2.1)	[error]		(e2)	{\footnotesize .35};
	\node at (-2.3, 1.3)	[error]		(e3)	{\footnotesize .15};
	\node at (-2.3, 0.5)	[error]		(e4)	{\footnotesize .25};
	
	\draw [paths] (hick.west) -- (h0.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .67{$^{1}$}\hphantom{$^**$}};	
	\draw [paths] (hick.west) -- (h1.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .80{$^{***}$}};	
	\draw [paths] (hick.west) -- (h2.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .92{$^{***}$}};	
	\draw [paths] (hick.west) -- (h3.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .87{$^{***}$}};
	
	\draw [paths] (e1) -- (h0.west) {};
	\draw [paths] (e2) -- (h1.west) {};
	\draw [paths] (e3) -- (h2.west) {};
	\draw [paths] (e4) -- (h3.west) {};
	\end{tikzpicture}
	
	\vspace{.2cm}
	\caption[Modell 14: Kongenerisches Messmodell der \gls{ha}]{Modell 14: Kongenerisches Messmodell der \gls{ha} (\textsf{H}). Eingezeichnet sind die standardisierten Koeffizienten.\\
		$^1$Um die Identifizierung der Varianz der latenten Variable zu ermöglichen, wurde diese unstandardisierte Faktorladung auf $1$ fixiert.\\
		$^{***}p~<~.001$.}
	\label{fig:hick_congeneric_model}
\end{figure}







Trotz des schlechten kongenerischen Modell-Fits der \gls{ha} wurde Modell 14 in einem Strukturgleichungsmodell mit dem kongenerischen Messmodell der \gls{ssauf} (Modell 1; siehe \autoref{fig:spatial_suppression_congeneric_model}) und dem \gls{gfaktor} des \gls{bist}s in Verbindung gebracht. Das theoretische Modell (Modell 15; siehe \autoref{fig:spatial_suppression_hick_g_model}) bildete die empirischen Daten ebenfalls schlecht ab. 
\begin{figure}[b]
	\begin{adjustbox}{width=1\textwidth, keepaspectratio}
		\begin{tikzpicture}
		[font=\sffamily, scale=2, inner sep=0pt,
		latent/.style	= {circle,draw,inner sep=0pt,minimum size=12mm},
		manifest/.style	= {rectangle,draw,inner sep=0pt,minimum width=12mm,minimum height=12mm},
		paths/.style	= {->, >=stealth, shorten >= 1pt},
		error/.style	= {circle, draw=none, fill=white, minimum size=5mm},
		covar/.style	= {<->, >=stealth, shorten >= 1pt, shorten <= 1pt}]
		
		
		\node at (0, 1.7)		[latent]	(sup)	{S};
		\node at (0, -1.7)		[latent]	(hick)	{H};
		\node at (1.5, 0)		[latent]	(g)		{\textrm{\textit{g}}};
		
		\node at (-1.5, 2.9)	[manifest]	(s1)	{1.8$^{\circ}$};
		\node at (-1.5, 2.1)	[manifest]	(s2)	{3.6$^{\circ}$};
		\node at (-1.5, 1.3)	[manifest]	(s3)	{5.4$^{\circ}$};
		\node at (-1.5, 0.5)	[manifest]	(s4)	{7.2$^{\circ}$};
		
		\node at (-1.5, -0.5)	[manifest]	(h0)	{0-bit};
		\node at (-1.5, -1.3)	[manifest]	(h1)	{1-bit};
		\node at (-1.5, -2.1)	[manifest]	(h2)	{2-bit};
		\node at (-1.5, -2.9)	[manifest]	(h3)	{2.58-bit};
		
		\node at (3, .8)		[manifest]	(k)		{Kap};
		\node at (3, 0)			[manifest]	(b)		{Bea};
		\node at (3, -.8)		[manifest]	(m)		{Mer};
		
		\node at (-2.3, 2.9)	[error]		(e1)	{\footnotesize .44};
		\node at (-2.3, 2.1)	[error]		(e2)	{\footnotesize .23};
		\node at (-2.3, 1.3)	[error]		(e3)	{\footnotesize .02};
		\node at (-2.3, .5)		[error]		(e4)	{\footnotesize .24};
		
		\node at (-2.3, -.5)	[error]		(e5)	{\footnotesize .54};
		\node at (-2.3, -1.3)	[error]		(e6)	{\footnotesize .35};
		\node at (-2.3, -2.1)	[error]		(e7)	{\footnotesize .16};
		\node at (-2.3, -2.9)	[error]		(e8)	{\footnotesize .25};
		
		\node at (3.8, .8)		[error]		(e9)	{\footnotesize .31};
		\node at (3.8, 0)		[error]		(e10)	{\footnotesize .47};
		\node at (3.8, -.8)		[error]		(e11)	{\footnotesize .71};
		
		\node at (1.5, 0.8)		[error]		(e12)	{\footnotesize .84};
		
		\draw [paths] (sup.west) -- (s1.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .75{$^{1}$}\hphantom{$^**$}};	
		\draw [paths] (sup.west) -- (s2.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .88{$^{***}$}};	
		\draw [paths] (sup.west) -- (s3.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .99{$^{***}$}};	
		\draw [paths] (sup.west) -- (s4.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .87{$^{***}$}};
		
		\draw [paths] (hick.west) -- (h0.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .68{$^{1}$}\hphantom{$^**$}};	
		\draw [paths] (hick.west) -- (h1.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .81{$^{***}$}};	
		\draw [paths] (hick.west) -- (h2.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .92{$^{***}$}};	
		\draw [paths] (hick.west) -- (h3.east) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .87{$^{***}$}};
		
		\draw [paths] (g.east) -- (k.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .83{$^{1}$}\hphantom{$^**$}};	
		\draw [paths] (g.east) -- (b.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .73{$^{***}$}};	
		\draw [paths] (g.east) -- (m.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize .54{$^{***}$}};	
		
		\draw [paths] (e1) -- (s1.west);
		\draw [paths] (e2) -- (s2.west);
		\draw [paths] (e3) -- (s3.west);
		\draw [paths] (e4) -- (s4.west);
		
		\draw [paths] (e5) -- (h0.west);
		\draw [paths] (e6) -- (h1.west);
		\draw [paths] (e7) -- (h2.west);
		\draw [paths] (e8) -- (h3.west);
		
		\draw [paths] (e9) -- (k.east);
		\draw [paths] (e10) -- (b.east);
		\draw [paths] (e11) -- (m.east);
		
		\draw [paths] (e12) -- (g.north);
		
		\path [covar] (hick.north) edge [bend left=45] node[minimum size = 4mm, draw=none,fill=white,midway]  {\footnotesize .14} (sup.south);
		\draw [paths] (sup)  -- (g.west) node[minimum size = 4mm, draw=none,fill=white,midway] {\footnotesize --.19{$^{*}$}\hphantom{$^**$}};
		\draw [paths] (hick) -- (g.west) node[minimum size = 4mm, draw=none,fill=white,midway] {\footnotesize --.33{$^{***}$}};
		
		\end{tikzpicture}
	\end{adjustbox}
	\vspace{.2cm}
	\caption[Modell 15: Strukturgleichungsmodell zur Vorhersage des \gls{gfaktor}s durch die Spa\-ti\-al-Sup\-pres\-sion- und die \gls{ha}]{Modell 15: Latenter Zusammenhang zwischen der \gls{ssauf} (\textsf{S}), der \gls{ha} (\textsf{H}) und dem \gls{gfaktor} des \gls{bist}s. \textsf{Kap} = Kapazität; \textsf{Bea} = Bearbeitungsgeschwindigkeit; \textsf{Mer} = Merkfähigkeit.\\
		$^1$Um die Identifizierung der Varianz der latenten Variable zu ermöglichen, wurde diese unstandardisierte Faktorladung auf $1$ fixiert.\\
		$^{*}p~<~.05$. $^{***}p~<~.001$.}
	\label{fig:spatial_suppression_hick_g_model}
\end{figure}
Der \gls{cst} zeigte eine überzufällig hohe Abweichung zwischen der theoretischen und der empirischen Var\-ianz-Ko\-var\-ianz\-ma\-trix an und der \gls{cfi} und der \gls{rmsea} lagen nicht im akzeptablen Bereich, $\upchi^2(41)=205.68$, $p<.001$, $\textnormal{CFI}=.86$, $\textnormal{RMSEA}=.15$, $\textnormal{SRMR}=.06$. 
Der standardisierte Regressionskoeffizient zwischen der aus den vier Bedingungen der \gls{ssauf} extrahierten latenten Variable und dem \gls{gfaktor} betrug $\upbeta~=~-.19$ ($p~=~.03$). Der standardisierte Regressionskoeffizient zwischen der aus den vier Bedingungen der \gls{ha} extrahierten latenten Variable und dem \gls{gfaktor} betrug $\upbeta~=~-.33$ ($p~<~.001$). Der Korrelationskoeffizient zwischen den aus den vier Bedingungen der Spatial-Suppression- und der \gls{ha} extrahierten latenten Variablen betrug $r~=~.14$ ($p~=~.16$). Gemeinsam erklärten diese beiden latenten Variablen $16\,\%$ der Varianz im \gls{gfaktor}.




\subsubsection*{Fixed-Links-Mess- und Strukturgleichungsmodelle}

Für die Analyse der Zusammenhänge auf latenter Ebene mittels \glspl{flm}n musste für die \gls{ha} zuerst ein Fixed-Links\--Mess\-modell gefunden werden. Das Vorgehen zur Bestimmung des Fixed-Links-Mess\-mod\-el\-ls war dabei identisch mit dem Vorgehen zur Bestimmung des Fixed-Links-Mess\-mod\-el\-ls für die \gls{ssauf} (siehe \autoref{subsec:spatial_suppression_fixed_links_messmodell}). Alle Modell-Fits der in den folgenden Paragraphen berichteten \glspl{flm} sind in \autoref{tab:hick_fixedlinks_measurement_models} aufgeführt.

\begin{table}[htb]
	%\flushleft
	\centering
	\captionsetup{labelsep = none}
	\caption[Modell-Fits der Fixed-Links-Messmodelle der \gls{ha}]{\newline  \textit{Modell-Fits der Fixed-Links-Messmodelle der \gls{ha}} \vspace{.2cm}}
	\label{tab:hick_fixedlinks_measurement_models}
	\begin{adjustbox}{width=1\textwidth, keepaspectratio}
		\begin{threeparttable}
			
			{\renewcommand{\arraystretch}{1.0} % <- modify value to suit your needs: line spacing inside table
				\begin{tabular}{
						%						S[table-format = 2.0, table-space-text-post = $^{*a}$]
						l
						l
						S[table-format = 2.2]
						S[table-format = 1.0]
						S[table-format = <0.3, add-integer-zero=false]
						S[table-format = 0.3, add-integer-zero=false]
						S[table-format = 0.3, add-integer-zero=false]
						S[table-format = 0.3, add-integer-zero=false]
						%				S[table-format = 1.2, add-integer-zero=false]
					}
					
					\hline
					\multicolumn{1}{c}{Modell}		& \multicolumn{1}{c}{Ladungsverlauf}	&	{$\upchi^2$}	& \textit{df}	& {\textit{p}}	&	{\textnormal{CFI}} 	&	{\textnormal{RMSEA}}	&	{\textnormal{SRMR}}\\
					\hline
					16{$^{*}$}	&	$y=\log_{e}x$					&	57.55	&	4	&	<.001	&	.825	&	.275	&	.197	\\
					17			&	$y=x$							&	37.60	&	4	&	<.001	&	.890	&	.218	&	.169	\\
					18			&	$y=\log_{2}x$					&	32.20	&	4	&	<.001	&	.908	&	.200	&	.136	\\
					19			&	$y=2^x$							&	13.33	&	4	&	.010	&	.970	&	.115	&	.072	\\
					20			&	$y=x^2$							&	11.37	&	4	&	.023	&	.976	&	.102	&	.070	\\
					21			&	$y=x$							&	8.76	&	4	&	.067	&	.984	&	.082	&	.089	\\
					22			&	$y=\dfrac{1}{1+e^{(-x/.8)}}$	&	4.50	&	4	&	.342	&	.998	&	.027	&	.076	\\
					%								\rule{0pt}{1ex} \\%  EXTRA vertical height
					\hline
					
					
				\end{tabular}%
			}
			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkungen.} Der Ladungsverlauf bezieht sich auf die unstandardisierten Faktorladungen der dynamischen latenten Variable. Die unstandardisierten Faktorladungen der konstanten latenten Variable betrugen immer 1. Für Modelle 16, 17, 19 und 20 gilt $x\in\{1,2,3,4\}$. Für Modelle 18 und 21 gilt $x\in\{1,2,4,6\}$ und für Modell 21 gilt $x\in\{-3,-1,1,3\}$. $\upchi^2 =$ Satorra-Bentler \citeyearpar{Satorra1994} korrigierter $\upchi^2$-Wert; \textit{df} = Freiheitsgrade; \gls{cfi} = \acrlong{cfi}; \gls{rmsea} = \acrlong{rmsea}; \gls{srmr} = \acrlong{srmr}.
				\item {$^{*}$}Das Modell konnte nicht interpretiert werden, weil die Fehlervarianz der 0-bit-Bedingung negativ geschätzt wurde.
			\end{tablenotes}%
		\end{threeparttable}
	\end{adjustbox}	
\end{table}



Das erste berechnete \gls{flm} (Modell 16) berücksichtige die von Blank \citep[1934; zitiert nach][S. 11]{Hick1952} formulierte logarithmische Beziehung zwischen der Anzahl Antwortalternativen und der Reaktionszeit. Die unstandardisierten Faktorladungen der dynamischen latenten Variable wurden deshalb mit einer logarithmischen Funktion ($y=\log_{e}x,\,x\in\{1, 2, 3, 4\}$) bestimmt. Dieses Modell konnte nicht interpretiert werden, weil die Fehlervarianz der 0-bit-Bedingung negativ geschätzt wurde.

\citet{Schweizer2006a} hat in seiner Untersuchung für die dynamische latente Variable der \gls{ha} einen linearen Verlauf eingesetzt. 
Die unstandardisierten Faktorladungen der dynamischen latenten Variable in Modell 17 wurden deshalb linear ansteigend ($y=x,\,x\in\{1, 2, 3, 4\}$) fixiert. Das Modell bildete die empirischen Varianzen und Kovarianzen der \gls{ha} nicht gut ab. Der $\upchi^2$-Wert war hochsignifikant und der \gls{cfi}, der \gls{rmsea} und das \gls{srmr} lagen ausserhalb des akzeptablen Bereichs.

In Modell 18 wiesen die unstandardisierten Faktorladungen der dynamischen latenten Variable einen Verlauf entsprechend den verwendeten Bit-Bedingungen auf ($y=\log_{2}x,\,x\in\{1, 2, 4, 6\}$). Das Modell bildete die empirischen Varianzen und Kovarianzen der \gls{ha} nicht adäquat ab. Zwar reduzierte sich der $\upchi^2$-Wert im Vergleich zu Modell 17 leicht, der \gls{cst} war aber immer noch signifikant. Weiter deuteten der \gls{cfi}, der \gls{rmsea} und das \gls{srmr} mit Werten ausserhalb des akzeptablen Bereichs auf eine schlechte Modellpassung hin.

Die unstandardisierten Faktorladungen der dynamischen latenten Variablen von Modell 19 wurden mit einer exponentiellen Funktion ($y=2^x,\,x\in\{1, 2, 3, 4\}$) bestimmt. Der \gls{cst} zeigte eine überzufällig hohe Abweichung zwischen der theoretischen und der empirischen Var\-ianz-Ko\-var\-ianz\-ma\-trix an. Gemeinsam mit dem hohen \gls{rmsea} wies dies darauf hin, dass das Modell die empirischen Varianzen und Kovarianzen der \gls{ha} nicht angemessen abbildete.

In Modell 20 wurden die unstandardisierten Faktorladungen der dynamischen latenten Variable mit dem von \citet{Schweizer2006a} verwendeten quadratischen Verlauf ($y=x^2,\,x\in\{1, 2, 3, 4\}$) gebildet. Der $\upchi^2$-Wert reduzierte sich im Vergleich zu Modell 19 zwar leicht, war aber immer noch signifikant. Die schlechte Passung des Modells wurde weiter durch einen hohen \gls{rmsea} angezeigt.

Modell 21 testete die Annahme, dass die Ladungen der unstandardisierten Faktorladungen der dynamischen latenten Variable entsprechend der Anzahl Antwortalternativen verlaufen ($y=x,\,x\in\{1, 2, 4, 6\}$). Der \gls{cst} erkannte keine signifikante Abweichung zwischen der von Modell 21 implizierten und der empirischen Var\-ianz-Ko\-var\-ianz\-ma\-trix. Der \gls{rmsea} und das \gls{srmr} hingegen lagen ausserhalb des akzeptablen Bereichs.

Die unstandardisierten Faktorladungen der dynamischen latenten Variable von Modell 22 (siehe \autoref{fig:hick_fixedlinks_measurement_model}) wurden mit einer logistischen Funktion bestimmt ($y={1}/[{1 + e^{(-x/.8)}}],\,x\in\{-3,-1,1,3\}$). Verglichen mit den Modellen 17 bis 21 wich die von Modell 22 implizierte Var\-ianz-Ko\-var\-ianz\-ma\-trix am wenigsten von der empirischen Var\-ianz-Ko\-var\-ianz\-ma\-trix ab. Der \gls{cst} war nicht signifikant und der \gls{cfi}, der \gls{rmsea} und das \gls{srmr} deuteten auf eine gute Modellpassung hin. 
Die Varianz der konstanten latenten Variable betrug $653.98$ ($z=5.75$, $p<.001$) und die Varianz der dynamischen latenten Variable betrug $2573.97$ ($z=6.90$, $p<.001$). Die Skalierung der Varianzen \citep{Schweizer2011a} hat ergeben, dass die konstante latente Variable $39\,\%$ und die dynamische latente Variable $61\,\%$ von der in den manifesten Variablen gemeinsamen Varianz banden.


\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}
	[font=\sffamily, scale=2, inner sep=0pt,
	latent/.style	= {circle,draw,inner sep=0pt,minimum size=12mm},
	manifest/.style	= {rectangle,draw,inner sep=0pt,minimum width=12mm,minimum height=12mm},
	paths/.style	= {->, >=stealth, shorten >= 1pt},
	error/.style	= {circle, draw=none, fill=white, minimum size=5mm},
	covar/.style	= {<->, >=stealth, shorten >= 1pt, shorten <= 1pt}]
	
	\node at (1, 2.4)	[latent]	(hk)	{H\textsubscript{kon}};
	\node at (1, 1)		[latent]	(hd)	{H\textsubscript{dyn}};
	
	\node at (-1.5, 2.9)	[manifest]	(h0)	{0-bit};
	\node at (-1.5, 2.1)	[manifest]	(h1)	{1-bit};
	\node at (-1.5, 1.3)	[manifest]	(h2)	{2-bit};
	\node at (-1.5, 0.5)	[manifest]	(h3)	{2.58-bit};
	
	\node at (-2.3, 2.9)	[error]		(e1)	{\footnotesize .19};
	\node at (-2.3, 2.1)	[error]		(e2)	{\footnotesize .21};
	\node at (-2.3, 1.3)	[error]		(e3)	{\footnotesize .14};
	\node at (-2.3, .5)		[error]		(e4)	{\footnotesize .24};
	
	\draw [paths] (hk.west) -- (h0.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .90{$^{1}$}};
	\draw [paths] (hk.west) -- (h1.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .81{$^{1}$}};
	\draw [paths] (hk.west) -- (h2.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .50{$^{1}$}};
	\draw [paths] (hk.west) -- (h3.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .40{$^{1}$}};
	
	\draw [paths] (hd.west) -- (h0.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .04{$^{0.02}$}};
	\draw [paths] (hd.west) -- (h1.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .36{$^{0.22}$}};
	\draw [paths] (hd.west) -- (h2.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .78{$^{0.78}$}};
	\draw [paths] (hd.west) -- (h3.east) node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize .78{$^{0.98}$}};
	
	\draw [paths] (e1) -- (h0.west);
	\draw [paths] (e2) -- (h1.west);
	\draw [paths] (e3) -- (h2.west);
	\draw [paths] (e4) -- (h3.west);
	\end{tikzpicture}
	
	\vspace{.2cm}
	\caption[Modell 22: Fixed-Links-Messmodell der \gls{ha}]{Modell 22: Fixed-Links-Messmodell der \gls{ha} (\textsf{H}). Eingezeichnet sind die standardisierten Koeffizienten. Hochgestellt sind die fixierten unstandardisierten Faktorladungen. \textsf{\textsubscript{kon}} = konstante latente Variable; \textsf{\textsubscript{dyn}} = dynamische latente Variable.}
	\label{fig:hick_fixedlinks_measurement_model}
\end{figure}

Im Vergleich zum kongenerischen Messmodell der \gls{ha} (Modell 14) vermochte das Fixed-Links-Messmodell (Modell 22) die empirischen Daten deutlich besser abzubilden. Die bessere Passung von Modell 22 äusserte sich im Vergleich zu Modell 14 in einem nicht-signifikanten $\upchi^2$-Wert, in den akzeptablen \gls{cfi} und \gls{rmsea} sowie in zwei zusätzlichen Freiheitsgraden. Modell 22 war Modell 14 somit aufgrund adäquaterer Abbildung der empirischen Daten und höherer Sparsamkeit vorzuziehen.

In einem letzten Schritt wurde das Fixed-Links-Messmodell der \gls{ssauf} (Modell 8) mit dem Fixed-Links-Messmodell der \gls{ha} (Modell 22) und dem \gls{gfaktor} aus dem \gls{bist} in Verbindung gebracht (Modell 23; siehe \autoref{fig:spatialsuppression_hick_fixedlinks_sem}). Das Modell bildete die empirischen Varianzen und Kovarianzen gut ab. Der \gls{cst} war nicht signifikant und der \gls{cfi}, der \gls{rmsea} und das \gls{srmr} lagen im akzeptablen Bereich, $\upchi^2(40)=48.81$, $p=.16$, $\textnormal{CFI}=.99$, $\textnormal{RMSEA}~=~.04$, $\textnormal{SRMR}~=~.08$.
\begin{figure}[b]
	\centering
	\begin{tikzpicture}
	[font=\sffamily, scale=2, inner sep=0pt,
	latent/.style	= {circle,draw,inner sep=0pt,minimum size=12mm},
	manifest/.style	= {rectangle,draw,inner sep=0pt,minimum width=12mm,minimum height=12mm},
	paths/.style	= {->, >=stealth, shorten >= 1pt},
	error/.style	= {circle, draw=none, fill=white, minimum size=5mm},
	covar/.style	= {<->, >=stealth, shorten >= 1pt, shorten <= 1pt}]
	
	\node at (1, 2.4)		[latent]	(sk)	{S\textsubscript{kon}};
	\node at (1, 1)			[latent]	(sd)	{S\textsubscript{dyn}};
	\node at (1, -1)		[latent]	(hk)	{H\textsubscript{kon}};
	\node at (1, -2.4)		[latent]	(hd)	{H\textsubscript{dyn}};
	\node at (2.5, 0)		[latent]	(g)		{\textrm{\textit{g}}};
	\node at (2.5, 0.8)		[error]		(e12)	{\footnotesize .84};
	
	\draw [paths] (e12) -- (g.north);
	\draw [paths] (sk) -- (g.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize --.21\hphantom{$^{**}$}};
	\draw [paths] (sd) -- (g.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize --.08\hphantom{$^{**}$}};
	\draw [paths] (hk) -- (g.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize --.17\hphantom{$^{**}$}};
	\draw [paths] (hd) -- (g.west) node[minimum size = 4mm, draw=none, fill=white, midway] {\footnotesize --.26{$^{**}$}};
	
	\path [covar] (hk.west) edge [bend left=45] node[minimum size = 4mm, draw=none, fill=white, near end]   {\footnotesize .21{$^{**}$}} (sk.west);
	\path [covar] (hk.west) edge [bend left=25] node[minimum size = 4mm, draw=none, fill=white, midway]     {\footnotesize .15} (sd.west);
	\path [covar] (hd.west) edge [bend left=45] node[minimum size = 4mm, draw=none, fill=white, near start] {\footnotesize --.13} (sd.west);
	\path [covar] (hd.west) edge [bend left=65] node[minimum size = 4mm, draw=none, fill=white, midway]     {\footnotesize --.00} (sk.west);
	
	\end{tikzpicture}
	
	\vspace{.2cm}
	\caption[Modell 23: Fixed-Links-Strukturgleichungsmodell zur Vorhersage des \gls{gfaktor}s durch die Spa\-ti\-al-Sup\-pres\-sion- und die \gls{ha}]{Modell 23: Latenter Zusammenhang zwischen dem Fixed-Links-Messmodell der \gls{ssauf} (\textsf{S}; Modell 8), dem Fixed-Links-Messmodell  der \gls{ha} (\textsf{H}; Modell 22) und dem \gls{gfaktor} aus dem \gls{bist}. Abgebildet ist das Strukturmodell. Eingezeichnet sind die standardisierten Koeffizienten. \textsf{\textsubscript{kon}} = konstante latente Variable; \textsf{\textsubscript{dyn}} = dynamische latente Variable.\\
		$^{**}p~<~.01$.}
	\label{fig:spatialsuppression_hick_fixedlinks_sem}
\end{figure}
Die standardisierten Regressionskoeffizienten betrugen zwischen der konstanten latenten Variable der \gls{ssauf} und dem \gls{gfaktor} $\upbeta~=~-.21$ ($p~=~.06$), zwischen der dynamischen latenten Variable der \gls{ssauf} und dem \gls{gfaktor} $\upbeta~=~-.08$ ($p~=~.38$), zwischen der konstanten latenten Variable der \gls{ha} und dem \gls{gfaktor} $\upbeta~=~-.17$ ($p~=~.06$) und zwischen der dynamischen latenten Variable der \gls{ha} und dem \gls{gfaktor} $\upbeta~=~-.26$ ($p~=~.002$). Die Korrelationskoeffizienten betrugen zwischen den beiden konstanten latenten Variablen $r=.21$ ($p=.005$), zwischen den beiden dynamischen latenten Variablen $r=-.13$ ($p=.11$), zwischen der konstanten latenten Variable der \gls{ha} und der dynamischen latenten Variable der \gls{ssauf} $r=.15$ ($p=.09$) und zwischen der konstanten latenten Variable der \gls{ssauf} und der dynamischen latenten Variable der \gls{ha} $r=.00$ ($p=.97$). Gemeinsam erklärten die konstanten und dynamischen latenten Variablen der Spatial-Suppression- und \gls{ha} $16\,\%$ der Varianz im \gls{gfaktor}. 




Im Vergleich zum klassischen Strukturgleichungsmodell (Modell 15) vermochte das Fixed-Links-Struk\-tur\-glei\-chungs\-mo\-dell (Modell 23) die empirischen Daten deutlich besser abzubilden. Die bessere Passung von Modell 23 äusserte sich im Vergleich zu Modell 15 in einem nicht-signifikanten $\upchi^2$-Wert sowie in akzeptablen \gls{cfi} und \gls{rmsea}. Bezüglich der Varianzaufklärung im \gls{gfaktor} waren Modell 15 ($16\,\%$) und Modell 23 ($16\,\%$) identisch. Modell 23 war Modell 15 somit aufgrund adäquaterer Abbildung der empirischen Daten vorzuziehen.

Abschliessend zur fünften Fragestellung kann Folgendes festgehalten werden: 
Auf manifester Ebene vermochte die \gls{ssauf} (sowohl auf Stufe der Aufgabenbedingungen als auch auf Stufe der Aufgabenparameter) bei einer Kontrolle des Zusammenhangs zwischen der \gls{ha} und psychometrischer Intelligenz keinen inkrementellen Beitrag zur Aufklärung individueller Intelligenzunterschiede zu leisten.
Auf latenter Ebene zeigte sich in einem klassischen Strukturgleichungsmodell (Modell 15) ein schwacher bis mittlerer negativer Zusammenhang zwischen der aus den vier Bedingungen der \gls{ssauf} abgeleiteten latenten Variable und dem \gls{gfaktor}. Tiefe Faktorwerte auf der latenten Variable der \gls{ssauf} waren folglich tendenziell mit hohen Faktorwerten im \gls{gfaktor} verbunden. 
Dieser latente Zusammenhang erklärte knapp $4\,\%$ der Varianz im \gls{gfaktor} und leistete damit bei Berücksichtigung des Zusammenhangs zwischen der \gls{ha} und dem \gls{gfaktor} einen inkrementellen Beitrag zur Aufklärung individueller Intelligenzunterschiede. Diese Resultate müssen jedoch aufgrund des schlechten Modell-Fits mit Vorsicht interpretiert werden.
Bei der Analyse der Zusammenhänge mittels Fixed-Links-Struk\-tur\-glei\-chungs\-mo\-dell zeigte sich zwischen der konstanten latenten Variable der \gls{ssauf} und der konstanten latenten Variable der \gls{ha} ein schwacher bis mittlerer positiver Zusammenhang. Hohe Faktorwerte auf der einen latenten Variable waren somit tendenziell mit hohen Faktorwerten auf der anderen latenten Variable verbunden. Ein signifikanter Prädiktor des \gls{gfaktor}s war bei dem gewählten $\upalpha$-Fehler von $5\,\%$ einzig die dynamische latente Variable der \gls{ha}, welche einen mittleren negativen Zusammenhang mit dem \gls{gfaktor} aufwies. Tiefe Faktorwerte auf der dynamischen latenten Variable der \gls{ha} waren folglich tendenziell mit hohen Faktorwerten im \gls{gfaktor} verbunden.











% =================================================================
% D I S C U S S I O N
% =================================================================
\chapter{Diskussion \label{cha:Diskussion}}
%\ac{MLS}

Der \gls{ssans} zur Erklärung individueller Intelligenzunterschiede \citep{Melnick2013} bietet einen neuen und vielversprechenden Ausgangspunkt, wenn es um die Bestimmung der kognitiven Grundlagen für Intelligenzunterschiede geht.
Das übergeordnete Ziel der vorliegenden Arbeit war es zu prüfen, ob sich die \gls{ssauf} als Prädiktor psychometrischer Intelligenz bewährt und inwiefern der \gls{ssans} \citep{Melnick2013} zur Erklärung individueller Intelligenzunterschiede neuartige Erklärungsmöglichkeiten liefert, welche nicht bereits der \gls{msa} \citep[z. B.][]{Deary2000a, Jensen1982a, Jensen1982b, Jensen2006, Vernon1983} bietet. 

Im folgenden Abschnitt werden die wichtigsten Resultate der fünf Fragestellungen diskutiert. Danach folgt ein Abschnitt, der sich mit Limitation der vorliegenden Arbeit befasst, bevor in einem letzten Abschnitt der generelle Erkenntnisgewinn diskutiert wird.




\section{Fragestellungen}

\subsection{Eine Bestätigung des Befunds von \citet{Melnick2013}?}

Die von \citeauthor{Melnick2013} berichteten manifesten Zusammenhänge zwischen der \gls{ssauf} und psychometrischer Intelligenz konnten in der vorliegenden Arbeit durchwegs nicht bestätigt werden. 
Während \citeauthor{Melnick2013} einen starken Zusammenhang zwischen dem \gls{si} und psychometrischer Intelligenz berichteten (Studie 1: $r~=~.64$ und Studie 2: $r~=~.71$) konnte in der vorliegenden Arbeit kein bedeutsamer Zusammenhang festgestellt werden ($r=.00$). 
Weiter fiel die von \citeauthor{Melnick2013} in Studie~$2$ geschilderte Korrelation zwischen der $1.8^{\circ}$-Bedingung und psychometrischer Intelligenz ($r=-.46$) in der vorliegenden Arbeit signifikant geringer aus ($r=-.16$) und deutete lediglich auf einen schwachen Zusammenhang hin.
Auch die von \citeauthor{Melnick2013} in Studie~$2$ angegebenen Semipartialkorrelationen zwischen der kleinsten Mustergrösse ($1.8^{\circ}$-Bedingung) respektive der grössten Mustergrösse ($7.2^{\circ}$-Bedingung) und psychometrischer Intelligenz ($r=-.71$ respektive $r=.55$) konnten nicht bestätigt werden, da sie signifikant tiefer zu liegen kamen und bei einer Irrtumswahrscheinlichkeit von weniger als $5\,\%$ nicht von $0$ unterschieden werden konnten ($r=-.11$ respektive $r=-.04$).

Welche Gründe könnten für die widersprüchlichen Ergebnisse verantwortlich sein? 
Die Erkennungsschwellen der \gls{ssauf} wiesen in der vorliegenden Arbeit ($r_{tt} = .96$) wie bei \citeauthor{Melnick2013} (\citeyear{Melnick2013}; $r_{tt} = .99$) sehr hohe Splithalf-Reliabilitäten auf. Die Erkennungsschwellen haben somit sehr genau die Zeitdauer erfasst, die benötigt wurde um die Bewegungsrichtung korrekt zu erkennen. Auch hat sich in der vorliegenden Arbeit die Wahrnehmungsleistung mit zunehmender Mustergrösse wie bei \citeauthor{Melnick2013} verschlechtert (siehe \autoref{subsec:SSres}). Dies deutet darauf hin, dass die Reliabilität der \gls{ssauf} nicht die Ursache für die fehlende Bestätigung der Befunde von \citeauthor{Melnick2013} zu sein scheint.

Auch der \gls{si} liefert bei näherer Betrachtung keine Erklärung für das Ergebnis. Zwar lag der Mittelwert des \gls{si} in Studie 2 von \citet{Melnick2013} höher (Mittelwert $\pm$ Standardabweichung $=0.320\,\pm\,0.155$, Minimum $=0.016$, Maximum $=0.703$; D. Tadin, persönl. Mitteilung, 25.09.2015) als in der vorliegenden Arbeit (Mittelwert $\pm$ Standardabweichung $=0.222\,\pm\,0.160$, Minimum $= -0.185$, Maximum $= 0.886$)\footnote{Ein \textit{t}-Test für unabhängige Stichproben ergab, dass sich die beiden Mittelwerte signifikant voneinander unterschieden, $t(88)=4.01$, $p<.001$. Die Effektstärke (Cohens \textit{d} für unabhängige Stichproben) für diesen Mittelwertsunterschied betrug $d=.61$ und lag damit im hohen Bereich.}, die Streuungen hingegen unterschieden sich nicht\footnote{Gemäss einem Levene-Test musste die Annahme der Varianzgleichheit der beiden Streuungen nicht verworfen werden, $F(1,\,228)=0.18$, $p=.67$.}. 
Weil bei der Berechnung einer Produkt-Moment-Korrelation die Streuungen der Variablen und nicht die Mittelwerte einen Einfluss auf den Zusammenhang haben \citep[S. 506]{Eid2013}, kann der vorliegende Mittelwert des \gls{si} nicht der Grund für die beobachtete Null-Korrelation zwischen dem \gls{si} und psychometrischer Intelligenz sein. Zusätzlich sah auch D. Tadin (persönl. Mitteilung, 30.08.2015) die absolute Höhe des Mittelwerts des \gls{si} nicht als entscheidend, um den von \citeauthor{Melnick2013} berichteten Zusammenhang zu bestätigen.

Bezüglich der erfassten psychometrischen Intelligenz lassen sich die vorliegenden Daten nicht direkt mit den Daten von \citet{Melnick2013} vergleichen. In der Untersuchung von \citeauthor{Melnick2013} wurde psychometrische Intelligenz mit der Kurzform der Wechsler-Adult-Intelligence-Scale III (\citealp{Axelrod2002}; Studie 1) und mit der Wechsler-Adult-In\-tell\-igence-Scale IV (\citealp{Wechsler2008}; Studie 2) erfasst. Diese beiden Instrumente sind genormt und ermöglichen eine Bestimmung von IQ-Punkten. In der vorliegenden Arbeit wurde zur Erfassung der psychometrischen Intelligenz eine modifizierte Kurzversion des \gls{bist}s eingesetzt (siehe \autoref{sec:Erfassung_der_psychometrischen_Intelligenz}). Weil für diese modifizierte Kurzversion keine Normen bestehen, konnten keine IQ-Punkte bestimmt werden. Als Alternative zu IQ-Punkten wurden deshalb als Mass für psychometrische Intelligenz alle vorgelegten \textit{z}-standardisierten Subtests gemittelt. Damit liess sich für jede \gls{vp} ein \textit{z}-standardisiertes Mittel (ein \gls{zwert}) ihrer Leistung bestimmen. Dieser \gls{zwert} lieferte jedoch keine Informationen darüber, ob die vorliegende Stichprobe im Durchschnitt eher niedrig-, mittel- oder hochintelligent war. Diese Ungewissheit lässt sich allerdings mit der Tatsache entkräften, dass an der Untersuchung nicht nur \glspl{vp} mit höherem Bildungsabschluss, sondern auch viele \glspl{vp} mit niedrigerem Bildungsniveau teilnahmen (siehe \autoref{sec:Stichprobe}). 
Zudem wich die Verteilung des \gls{zwert}s nicht von der Normalverteilung ab (siehe \autoref{subsec:BIS-Test}), was als Hinweis dafür gesehen werden kann, dass die Stichprobe ausreichend heterogen zusammengesetzt war und sie die in der Population vorliegende Merkmalsverteilung angemessen reproduzierte. Diese Anhaltspunkte lassen die Schlussfolgerung zu, dass die Befunde von \citeauthor{Melnick2013} nicht alleine deshalb nicht bestätigt werden konnten, weil ein anderer Intelligenztest eingesetzt wurde.


%\begin{itemize}
%	\item Korrelationen der 3.6 und 5.4 Bedingung mit psychometrischer Intelligenz aufnehmen? Bei Melnick war nur 1.8 Bedingung korreliert.
%	\item 50 bis 100 ms Schwellen (D. Tadin, persönl. Mitteilung, 13.10.2015)
%	\item Alter der Stichprobe von Melnick?
%	\item Allgemein beachtliche/erstaunliche Ergebnisse?
%\end{itemize}



\subsection{Ein alternatives Mass für Spatial-Suppression? \label{subsec:Ein_alternatives_Mass_für_SS?}}

In bisherigen Untersuchungen wurde das Ausmass an \gls{ss} mit dem \gls{si} quantifiziert \citep{Lappin2009, Melnick2013, Tadin2006, Tadin2011}. Gebildet wurde der \gls{si} dabei (wie auch in der vorliegenden Arbeit) als Differenz zwischen der Erkennungsschwelle für grosse Muster und der Erkennungsschwelle für kleine Muster. Diese Differenzbildung wirkt sich in Situationen, in welchen der Minuend beziehungsweise der Subtrahend korreliert sind und die Reliabilität der beiden nicht perfekt ist, negativ auf die Reliabilität des Differenzmasses aus (siehe \autoref{subsec:Der_Spatial-Suppression-Ansatz}).
Auch \citet{Melnick2013} haben erkannt, dass der \gls{si} als Mass für \gls{ss} nicht ideal ist. Sie haben in ihrer Untersuchung richtigerweise darauf hingewiesen, dass die Höhe des \gls{si} davon abhängig ist, welche Mustergrössen in einer Untersuchung verwendet werden sowie zwischen welchen Mustergrössen die Differenz gebildet wird. So lassen sich beispielsweise die Ergebnisse zum \gls{si} zwischen den Untersuchungen von \citet{Tadin2006}, \citet{Tadin2011} und \citeauthor{Melnick2013} nicht direkt vergleichen, weil sie den \gls{si} als Differenz zwischen unterschiedlichen Mustergrössen gebildet haben. Als Lösung dafür haben \citeauthor{Melnick2013} vorgeschlagen, die Erkennungsschwellen mit einem exponentiellen Modell zu beschreiben und die daraus abgeleitete Steigung als Mass für \gls{ss} zu verwenden. Damit sind beide Schwachpunkte des \gls{si} behoben: Die Steigung stellt kein Differenzmass dar (das heisst sie leidet nicht unter einer verminderten Reliabilität) und sie lässt sich unabhängig von den verwendeten Mustergrössen zwischen verschiedenen Untersuchungen vergleichen.

\citet{Melnick2013} haben die Erkennungsschwellen mit einem exponentiellen Modell beschrieben und einen starken Zusammenhang zwischen der ermittelten Steigung und dem \gls{si} ($r=.99$) festgestellt. Dieser Befund konnte in der vorliegenden Arbeit bei rein inferenzstatistischer Betrachtung nicht bestätigt werden ($r=.96$). Inhaltlich muss bei diesem Zusammenhang aber immer noch von einem ausserordentlich hohen Zusammenhang gesprochen werden.
Eindeutig nicht bestätigt werden konnte hingegen der von \citeauthor{Melnick2013} berichtete starke Zusammenhang zwischen der Steigung und psychometrischer Intelligenz ($r~=~.68$). In der vorliegenden Arbeit bestand keine Beziehung zwischen den beiden Variablen ($r=.00$).

Grundsätzlich festzuhalten ist, dass sich ein exponentielles Modell zur Beschreibung der Erkennungsschwellen sehr gut eignete. Ebenso schienen die Zusammenhänge der abgeleiteten Aufgabenparameter (Asymptote und Steigung) mit psychometrischer Intelligenz nicht massgeblich durch Personen beeinflusst worden zu sein, deren Erkennungsschwellen schlecht mit einem exponentiellen Modell abgebildet werden konnten (siehe \autoref{sec:2Fragestellung}). Dieser Umstand vereinfachte die Interpretation der Ergebnisse. Der bestätigte starke Zusammenhang zwischen dem \gls{si} und der Steigung deutete darauf hin, dass die Steigung ziemlich genau dasselbe wie der \gls{si} erfasste. In Anbetracht des nicht bestätigten Zusammenhangs zwischen dem \gls{si} und psychometrischer Intelligenz war es somit nicht erstaunlich, dass zwischen der Steigung und psychometrischer Intelligenz eine Null-Korrelation beobachtet wurde. Die Erfassung von \gls{ss} mittels der Steigung scheint gegenüber dem \gls{si} bei einem ersten Blick auf die hier berichteten Resultate keinen Mehrwert zu besitzen, weil die Steigung psychometrische Intelligenz nicht besser vorhersagte als der \gls{si}. Aus Gründen der höheren Reliabilität und der besseren Vergleichbarkeit zwischen Studien ist die exponentielle Steigung jedoch das geeignetere Mass für \gls{ss} als der \gls{si}.

\citet{Melnick2013} haben in Ihrer Untersuchung nur die Steigung mit psychometrischer Intelligenz in Verbindung gebracht. Den Zusammenhang zwischen der Asymptote und der Steigung sowie die Beziehung zwischen der Asymptote und psychometrischer Intelligenz haben sie nicht berichtet. Diese Zusammenhänge wurden in der vorliegenden Arbeit untersucht. Dabei hat sich ein stark\textcolor{red}{er} negativer Zusammenhang zwischen der Asymptote und der Steigung ergeben ($r=-.57$). Ein tiefer Ursprung des exponentiellen Verlaufs der Wahrnehmungsverschlechterung ging folglich tendenziell mit einer stärkeren Wahrnehmungsverschlechterung (einer stärkeren \gls{ss}) einher.
Dieser Befund lässt sich gut mit der Erklärung von \citeauthor{Melnick2013} für den von Ihnen beobachteten positiven Zusammenhang zwischen dem \gls{si} und psychometrischer Intelligenz vereinen. Wenn intelligente Personen tatsächlich kleine Muster schneller verarbeiten und gleichzeitig mit zunehmender Mustergrösse eine stärkere Verschlechterung der Wahrnehmungsleistung erfahren als weniger intelligente Personen, dann sollten bei der Analyse der Bedingungen mit einem exponentiellen Modell die Asymptote und die Steigung negativ zusammenhängen. 
Konsistent mit diese Annahme von \citeauthor{Melnick2013} hing in der vorliegenden Arbeit die Asymptote schwach negativ mit psychometrischer Intelligenz zusammen ($r=-.16$). Ein tiefer Ursprung des exponentiellen Verlaufs der Wahrnehmungsverschlechterung hing somit tendenziell mit hoher psychometrischer Intelligenz zusammen. Auch wenn die Asymptote inhaltlich schwierig zu interpretieren ist, liefert dieser negative Zusammenhang einen weiteren Hinweis dafür, dass intelligentere Personen ganz generell betrachtet tendenziell schneller arbeitende Prozesse besitzen als weniger intelligente Personen \citep{Jensen1987a, Neubauer1997a, Neubauer1997b}.




\subsection{Der latente Zusammenhang zwischen der Spa\-tial-Sup\-pres\-sion-Auf\-gabe und dem \textit{g}-Faktor}

Um den Umstand zu berücksichtigen, dass sich ein beobachteter Messwert immer aus einem wahren Anteil der Merkmalsausprägung und einem zufällig zustande gekommenen Fehleranteil zusammensetzt \citep{Moosbrugger2007}, wurde der Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz auf latenter Ebene untersucht. Damit konnte der Messfehler identifiziert und von der Analyse ausgeschlossen werden \citep[S. 9]{Kline2011}, was eine validere Schlussfolgerung über den Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz zuliess.

Das kongenerische Messmodell der \gls{ssauf}, das einen Faktor für die Erklärung der Zusammenhänge unter den Bedingungen annahm, bildete die empirischen Daten schlecht ab. Das kongenerische Messmodell des \gls{bist}s zur Extraktion des \gls{gfaktor}s, der latenten Operationalisierung psychometrischer Intelligenz, konnte aus messtechnischen Gründen nicht isoliert getestet werden (siehe \autoref{sec:3Fragestellung}). Bei der Zusammenführung dieser beiden Modelle in einem klassischen Strukturgleichungsmodell hat sich dann ein schwacher bis mittlerer negativer Zusammenhang ($\upbeta=-.23$) zwischen der \gls{ssauf} und dem \gls{gfaktor} gezeigt. Nicht zu vernachlässigen ist, dass das theoretische Modell die empirischen Zusammenhänge dabei schlecht abbildete und die aus den vier Bedingungen der \gls{ssauf} extrahierte latente Variable lediglich $5\,\%$ der Varianz im \gls{gfaktor} erklärte.

Was verbirgt sich hinter der aus den vier Bedingungen der \gls{ssauf} extrahierten latenten Variable? Die durchwegs hohen positiven Faktorladungen der vier Bedingungen auf den Faktor legen kombiniert mit dem negativen Zusammenhang zum \gls{gfaktor} die Vermutung nahe, dass darin die generelle (von den Mustergrössen unabhängige) Geschwindigkeit abgebildet wurde, mit der die Bewegungsrichtung der Muster erkannt wurde. 
Gestützt wird diese Vermutung durch die auf manifester Ebene beobachteten bivariaten Produkt-Moment-Korrelationen zwischen den Bedingungen der \gls{ssauf} und psychometrischer Intelligenz. Die Bedingungen der \gls{ssauf} korrelierten mit Ausnahme des Zusammenhangs zwischen der $7.2^{\circ}$-Bedingung und dem \gls{zwert} des \gls{bist}s alle schwach negativ mit psychometrischer Intelligenz ($r=-.16$ bis $-.19$; siehe \autoref{tab:product_moment_correlations_manifest}). Eine schnellere Erkennung der Bewegungsrichtung war somit (unabhängig von der verwendeten Mustergrösse) tendenziell mit hohen Intelligenzwerten verbunden. 

%Der schwache bis mittlere negative Zusammenhang zwischen der \gls{ssauf} und dem \gls{gfaktor} lässt sich unter der Annahme, dass die latente Variable die grundlegende Geschwindigkeit abbildet, mit der die Muster erkannt wurden, mit gesicherten Befunden zum Zusammenhang zwischen der \gls{ita} 
%
%
%Diese Beobachtung lässt sich gut in gesicherte Befunde zum Zusammenhang zwischen der  eingliedern.
%
% -- und in Übereinstimmung mit gesicherten Befunden zum .
%
%Diese Beobachtung lässt sich gut in gesicherte Befunde zum 

Die Annahme, dass die latente Variable \gls{ss} abbildete ist aus zwei Gründen unwahrscheinlich: Zum einen hätten sich negative oder zumindest sehr geringe Faktorladungen auf der $1.8^{\circ}$- oder der $3.6^{\circ}$-Bedingung zeigen müssen, da \gls{ss} als die relative mit zunehmender Mustergrösse beobachtete Wahrnehmungsverschlechterung definiert ist \citep{Melnick2013, Tadin2003, Tadin2006, Tadin2011}. Zum anderen hätte sich zwischen der latenten Variable und dem \gls{gfaktor} ein positiver Zusammenhang zeigen müssen, weil \gls{ss} (operationalisiert mit dem \gls{si}) bei \citet{Melnick2013} stark positiv mit psychometrischer Intelligenz zusammenhing.
Weil weder das Eine noch das Andere beobachtet wurde scheint es nicht plausibel, dass die latente Variable \gls{ss} abbildete.





%\subsection{Fixed-Links-Analyse des Zusammenhangs zwischen der Spa\-tial-Sup\-pres\-sion-Auf\-gabe und dem \textit{g}-Faktor}
%\subsection{Leidet die Spa\-tial-Sup\-pres\-sion-Auf\-gabe unter dem Im\-pu\-ri\-ty-Pro\-blem und können Fixed-Links-Modelle aufgabenrelevante Prozesse voneinander trennen?}
\subsection{Kann die Spa\-tial-Sup\-pres\-sion-Auf\-gabe mit einem \\Fixed-Links-Mo\-dell beschrieben werden und wie hängen die getrennten Prozesse mit dem \textit{g}-Faktor zusammen?}

Die Analyse von Zusammenhängen mittels klassischer Faktorenanalysen erlaubt es, wahre Varianz von Fehlervarianz zu trennen \citep[S. 9]{Kline2011}. Nicht gelöst wird dabei das \gls{ip} (siehe \autoref{subsec:Loesungsansaetze}). Um das \gls{ip} anzugehen, wurde die \gls{ssauf} mit einem \gls{flm} beschrieben und ihren Zusammenhang mit psychometrischer Intelligenz in einem Fixed-Links-Struk\-tur\-glei\-chungs\-mo\-dell analysiert.

Das \gls{flm} der \gls{ssauf}, das zwei unabhängige Faktoren für die Erklärung der Zusammenhänge unter den Bedingungen annahm, bildete die empirischen Daten  gut ab. Während die unstandardisierten Faktorladungen der konstanten latenten Variable alle $1$ betrugen, folgten die unstandardisierten Faktorladungen der dynamischen latenten Variable einem linearen Verlauf ($y=x,\,x\in\{0, 1, 2, 3\}$). Zu beachten ist dabei, dass der Einfluss der in der dynamischen latenten Variable abgebildeten Prozesse auf die Leistung in den Bedingungen in Wirklichkeit nicht linear verlief. Weil in der vorliegenden Arbeit alle Berechnungen mit den $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-len durchgeführt wurden (mit Ausnahme der exponentiellen Regression, siehe \autoref{subsec:Spatial-Suppression_Versuchsablauf}), muss der lineare Verlauf vor der Interpretation invertiert werden. Dabei ergibt sich ein exponentieller Einfluss der in der dynamischen latenten Variable abgebildeten Prozesse auf die Erkennungsschwellen der \gls{ssauf}. Des Weiteren hat die Skalierung der latenten Varianzen ergeben, dass die konstante latente Variable $72\,\%$ und die dynamische latente Variable $28\,\%$ der in den manifesten Variablen gemeinsamen Varianz band. 
Die in der konstanten latenten Variable abgebildeten Prozesse waren folglich deutlich stärker für Unterschiede zwischen Personen in der Erkennungsschwelle verantwortlich als die in der dynamischen latenten Variable gebundenen Prozesse.


Bei der Zusammenführung des \gls{flm}s der \gls{ssauf} mit dem \gls{gfaktor} hat sich ebenfalls eine gute Passung zwischen theoretischem Modell und empirischen Daten ergeben. Zwischen der konstanten latenten Variable der \gls{ssauf} und dem \gls{gfaktor} zeigte sich ein schwacher bis mittlerer negativer Zusammenhang ($\upbeta~=~-.25$). Zwischen der dynamischen latenten Variable der \gls{ssauf} und dem \gls{gfaktor} bestand ein so schwacher Zusammenhang ($\upbeta~=~-.08$), dass er bei einem $\alpha$-Fehler von $5\,\%$ nicht von $0$ unterschieden werden konnte. Die konstante und die dynamische latente Variable erklärten gemeinsam $7\,\%$ der Varianz im \gls{gfaktor}.

Was für Prozesse wurden in der konstanten latenten Variable abgebildet? Sicher ist, das es aufgabenrelevante Prozesse sind, deren Einflüsse sich über die experimentellen Bedingungen hinweg nicht verändert haben. Der negative Zusammenhang zwischen der konstanten latenten Variable und dem \gls{gfaktor} lässt die Interpretation zu, dass es Prozesse sind, welche die (von den Mustergrössen unabhängige) grundlegende Geschwindigkeit bestimmen, mit der Information verarbeitet wird \citep[für ähnliche Annahmen über die Inhalte der konstanten latenten Variable siehe][]{Schweizer2007, Stauffer2014}.
Diese Vermutung lässt sich gut mit den Resultaten der exponentiellen Regression zum negativen Zusammenhang zwischen der Asymptote und psychometrischer Intelligenz vereinen. Die Asymptote bildete auf manifester Ebene ebenfalls die von der experimentellen Manipulation unabhängige generelle Geschwindigkeit ab, mit der Information verarbeitet wurde (siehe \autoref{subsec:Ein_alternatives_Mass_für_SS?}). 
Dass die konstante latente Variable ($\upbeta~=~-.25$) dabei etwas stärker mit psychometrischer Intelligenz zusammenhing als die Asymptote ($r~=~-.16$) lässt sich damit erklären, dass die Analyse auf latenter Ebene mittels \gls{flm} den Messfehler isoliert und dadurch zu höheren Zusammenhängen kommen kann als die manifeste Analyse mittels exponentieller Regression.

Die dynamische latente Variable hat Varianz von aufgabenrelevanten Prozessen gebunden, deren Einflüsse sich mit der experimentellen Manipulation verändert haben. Der Einfluss der Prozesse nahm mit zunehmender Mustergrösse exponentiell zu. Weil \citet{Melnick2013} \gls{ss} mit einem exponentiellen Modell beschrieben haben, kann angenommen werden, dass sich hinter diesem exponentiellen Verlauf  \gls{ss} verbirgt. Der nicht-signifikante Zusammenhang zwischen der dynamischen latenten Variable und dem \gls{gfaktor} ($\upbeta~=~-.08$) steht dabei in der vorliegenden Arbeit in Übereinstimmung mit den Zusammenhängen zwischen anderen Massen für \gls{ss} und psychometrischer Intelligenz: Der \gls{si} sowie die exponentielle Steigung korrelierten nicht mit psychometrischer Intelligenz ($r~=~.00$ respektive $r~=~.00$).




\subsection{Der Zusammenhang zwischen der Spatial-Sup\-pres\-sion-Aufgabe, der Hick-Aufgabe und psy\-cho\-me\-trischer In\-tel\-li\-genz}
%\subsection{Der Zusammenhang zwischen Spatial-Suppression, \\Men\-tal-Speed und psychometrischer Intelligenz}

In einem letzten Schritt wurde der Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz um \gls{ms} erweitert. Damit wurde geprüft, ob die \gls{ssauf} im Zusammenhang mit psychometrischer Intelligenz einen Aspekt der menschlichen Informationsverarbeitung abbildet, der neuartig ist und nicht bereits von der \gls{ha} erfasst beziehungsweise erklärt wird. Die Analysen wurden auf manifester als auch auf latenter Ebene durchgeführt.

\subsubsection{Auf manifester Ebene}

%Mit einer multiplen Regression zur Vorhersage psychometrischer Intelligenz durch die Hick- und der \gls{ssauf} wurde geprüft, inwieweit die \gls{ssauf} zur Aufklärung individueller Intelligenzunterschiede neuartige Erklärungsmöglichkeiten bietet oder ob die \gls{ha} den Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz zu erklären vermag. Die multiple Regression wurde mit den Aufgabenbedingungen und den Aufgabenparameter durchgeführt.

Die Reaktionszeiten der \gls{ha} stiegen auf Gruppenebene mit zunehmender Anzahl Antwortalternativen an \citep{Hick1952} und die Aufgabenbedingungen korrelierten  erwartungsgemäss negativ mit psychometrischer Intelligenz \citep[$r~=~-.19$ bis $-.28$; vgl.][]{Sheppard2008}.
Bei der Vorhersage der Reaktionszeiten der \gls{ha} mit einem linearen Modell zeigte sich, dass sich damit die Reaktionszeiten für einen grossen Teil der Stichprobe gut beschrieben liessen (siehe \autoref{subsec:Aufgabenparameter_Hick}). Die daraus abgeleiteten Aufgabenparameter hingen konsistent mit etablierten Befunden negativ mit psychometrischer Intelligenz zusammen \citep[vgl.][]{Roth1964, Jensen1982b, Jensen1987a, Jensen1998b, Neubauer1997a, Neubauer1997b, Rammsayer2007}: Der y-Ach\-sen\-ab\-schnitt korrelierte schwach negativ ($r~=~-.17$) und die Steigung schwach bis mittel negativ ($r~=~-.23$) mit psychometrischer Intelligenz. 

Bei der Vorhersage psychometrischer Intelligenz hat sich sowohl auf Ebene der Aufgabenbedingungen als auch auf Ebene der Aufgabenparameter gezeigt, dass die \gls{ssauf} bei einer Kontrolle des Zusammenhangs zwischen der \gls{ha} und psychometrischer Intelligenz keine zusätzliche Varianz erklären konnte.
Diese Analysen auf manifester Ebene deuteten darauf hin, dass die \gls{ssauf} im Zusammenhang mit psychometrischer Intelligenz keinen Aspekt der menschlichen Informationsverarbeitung erfasst, der neuartig ist und nicht schon von der \gls{ha} erklärt wird.

%Bei der Vorhersage psychometrischer Intelligenz durch die Aufgabenbedingungen der Hick- und der \gls{ssauf} hat sich gezeigt, dass die Aufgabenbedingungen der \gls{ssauf} bei einer Kontrolle des Zusammenhangs zwischen den Aufgabenbedingungen der \gls{ha} und psychometrischer Intelligenz keine zusätzliche Varianz erklären konnten. Gemeinsam erklärten die Aufgabenbedingungen $11\,\%$ der Varianz im \gls{zwert} des \gls{bist}s.
%
%Bei der Vorhersage psychometrischer Intelligenz durch die Aufgabenparameter der Hick- und der \gls{ssauf} hat sich ergeben, dass die Aufgabenparamter der \gls{ssauf} (Asymptote und Steigung) bei einer Kontrolle des Zusammenhangs zwischen den Aufgabenparameter der \gls{ha} (y-Achsenabschnitt und Steigung) und psychometrischer Intelligenz ebenfalls keine zusätzliche Varianz erklären konnten. Gemeinsam erklärten die Aufgabenparameter $12\,\%$ der Varianz im \gls{zwert} des \gls{bist}s.
%
%Auf manifester Ebene leistete die \gls{ssauf} somit keinen inkrementellen Beitrag zur Aufklärung individueller Intelligenzunterschiede. Sowohl die Analyse auf Ebene der Aufgabenbedingungen als auch auf Ebene der Aufgabenparameter deutet darauf hin, dass die \gls{ssauf} keinen Aspekt der menschlichen Informationsverarbeitung erfasst, der neuartig ist und nicht schon von der \gls{ha} erfasst wird.





\subsubsection{Auf latenter Ebene}

% Klassisches Strukturgleichungsmodell

Die kongenerischen Messmodelle der Hick- und der \gls{ssauf}, die je einen Faktor für die Erklärung der Zusammenhänge unter den Bedingungen annahmen, bildeten die empirischen Daten schlecht ab. Das kongenerische Messmodell des \gls{bist}s zur Extraktion des \gls{gfaktor}s konnte wie bereits erwähnt aus messtechnischen nicht isoliert getestet werden. 
Bei der Zusammenführung dieser drei Modelle in einem klassischen Strukturgleichungsmodell hat sich ein mittlerer negativer Zusammenhang ($\upbeta=~-.33$) zwischen der \gls{ha} und dem \gls{gfaktor} gezeigt. Zwischen der \gls{ssauf} und dem \gls{gfaktor} bestand ein schwach\textcolor{red}{er} negativer Zusammenhang ($\upbeta=~-.19$). Die Hick- und die \gls{ssauf} korrelierten nicht signifikant ($r~=~.14$) und erklärten gemeinsam $16\,\%$ der Varianz im \gls{gfaktor}. Nicht zu vernachlässigen ist dabei, dass dieses klassische Strukturgleichungsmodell die empirischen Zusammenhänge schlecht abbildete.

Der mittlere Zusammenhang zwischen der \gls{ha} und dem \gls{gfaktor} kann als Bestätigung früherer Untersuchungen angesehen werden, welche die \gls{ha} auf latenter Ebene mit psychometrischer Intelligenz in Verbindung gebracht haben und dabei einen vergleichbaren Zusammenhang ermittelt haben \citep[z. B.][]{Borter2016, Helmbold2007, Rammsayer2007}.
Interessant war, dass die \gls{ssauf} über den Zusammenhang zwischen der \gls{ha} und dem \gls{gfaktor} hinaus Varianz im \gls{gfaktor} zu erklären vermochte. Auch wenn dieser Zusammenhang schwach ausfiel, lieferte diese Analyse in der vorliegenden Arbeit das erste Mal einen Hinweis dafür, dass die \gls{ssauf} im Zusammenhang mit dem \gls{gfaktor} einen Aspekt der menschlichen Informationsverarbeitung abbildet, der nicht schon von der \gls{ha} erklärt wird. Gestützt wird diese Interpretation durch den nicht-signifikanten latenten Zusammenhang zwischen der Hick- und der \gls{ssauf}. 
Damit kann die \gls{ssauf} als Mediator des Zusammenhangs zwischen der \gls{ha} und dem \gls{gfaktor} ausgeschlossen werden.
Aufgrund der bereits diskutierten hohen positiven Faktorladungen der vier Bedingungen der \gls{ssauf} auf den Faktor ist anzunehmen, dass darin nicht \gls{ss} abgebildet wurde, sondern die generelle (von den Mustergrössen unabhängige) Geschwindigkeit, mit der die Bewegungsrichtung der Muster erkannt wurde. Geprüft werden konnte diese Annahme mit diesem berechneten klassischen Strukturgleichungsmodell allerdings nicht. Über diese Vermutung Aufschluss geben konnten die Ergebnisse der \glspl{flm}, welche als nächstes diskutiert werden.




% Fixed-Links-Analysen

Das \gls{flm} der \gls{ha}, das zwei unabhängige Faktoren für die Erklärung der Zusammenhänge unter den Bedingungen annahm, bildete die empirischen Daten gut ab. Während die unstandardisierten Faktorladungen der konstanten latenten Variable alle $1$ betrugen, folgten die unstandardisierten Faktorladungen der dynamischen latenten Variable einem logistischen Verlauf ($y={1}/[{1 + e^{(-x/.8)}}],\,x\in\{-3,-1,1,3\}$). Die Skalierung der latenten Varianzen hat ergeben, dass die konstante latente Variable $39\,\%$ und die dynamische latente Variable $61\,\%$ der in den manifesten Variablen gemeinsamen Varianz band. Die in der dynamischen latenten Variable abgebildeten Prozesse übten folglich im Vergleich mit den in der konstanten latenten Variable gebundenen Prozessen mehr Einfluss auf die Leistung in den Bedingungen aus.
Bei der Zusammenführung der \glspl{flm} der Hick- und der \gls{ssauf} mit dem \gls{gfaktor} hat sich ebenfalls eine gute Passung zwischen theoretischem Modell und empirischen Daten ergeben. Statistisch bedeutsamer Prädiktor des \gls{gfaktor}s war nur die dynamische latente Variable der \gls{ha}, welche einen mittleren negativen Zusammenhang mit dem \gls{gfaktor} aufwies ($\upbeta~=~-.26$). 
Zwischen den konstanten und dynamischen latenten Variablen der Hick- und der \gls{ssauf} korrelierten einzig die beiden konstanten latenten Variablen signifikant ($r~=~.21$). Die konstanten und dynamischen latenten Variablen der Hick- und \gls{ssauf} erklärten gemeinsam $16\,\%$ der Varianz im \gls{gfaktor}.

Was für Prozesse wurden in der konstanten latenten Variable der \gls{ha} abgebildet?
Wie bei der Interpretation der konstanten latenten Variable der \gls{ssauf} kann auch hier nur vermutet werden, welche Prozesse die Varianz erzeugt haben. Klar ist, das es Prozesse sind, die von der experimentellen Manipulation nicht beeinflusst wurden. Es könnte also sein, dass es auch hier Prozesse sind, welche die grundlegende (von der Anzahl Antwortalternativen unabhängige) Geschwindigkeit bestimmen, mit der Reize im Kortex wahrgenommen und verarbeitet werden \citep{Jensen1998b}.
Für die Varianz aber auch verantwortlich sein könnten von der experimentellen Manipulation unabhängige situative Prozesse, wie zum Beispiel Unterschiede zwischen Personen in der allgemeinen Wachsamkeit oder der allgemeinen Motivation, die Aufgabe zu bearbeiten. 
Der schwache bis mittlere positive Zusammenhang zwischen der konstanten latenten Variable der Hick- und der \gls{ssauf} deutet darauf hin, dass zumindest ein Teil der erfassten Prozesse aufgabenunspezifisch ist, das heisst sowohl in der Hick- als auch der \gls{ssauf} die Leistung beeinflusst hat. Die Vermutung, dass in den beiden konstanten latenten Variablen unter anderem die generelle Geschwindigkeit abgebildet wurde, mit der Information verarbeitet wird, muss mit diesem Zusammenhang zumindest nicht verworfen werden. 

Die dynamische latente Variable der \gls{ha} hat Varianz von Prozessen gebunden, die experimentell manipuliert wurden. Manipuliert wurde die Anzahl Antwortalternativen. Es ist deshalb plausibel anzunehmen, dass in der dynamischen latenten Variable Varianz aufgrund unterschiedlicher Verarbeitungsgeschwindigkeiten von Personen abgebildet wurde \citep[vgl.][]{Jensen1998b, Roth1964}. 
Der Einfluss der Verarbeitungsgeschwindigkeit auf die Reaktionszeiten nahm (aufgrund der gewählten Faktorladungen) mit zunehmender Anzahl Antwortalternativen zu, wobei dieser Einfluss einer logistischen Funktion folgte und somit von der $2$-Bit- zur $2.58$-Bit-Bedingung stark abflachte. Das deutet darauf hin, dass sich der Einfluss der Verarbeitungsgeschwindigkeit auf die Reaktionszeit bei einer weiteren Hinzunahme einer Antwortalternative (der $3$-Bit-Bedingung) nicht bedeutsam erhöht hätte.
Eine Erklärung dafür könnte sein, dass mit weiter zunehmender Anzahl Antwortalternativen zusätzlich Varianz entsteht, die durch andere Prozesse verursacht wird als durch die Verarbeitungsgeschwindigkeit. Es könnte beispielsweise sein, dass mit zunehmender Anzahl Antwortalternativen räumliche Aufmerksamkeit \citep[][]{Hoffman1981} eine immer wichtiger werdende Rolle für eine schnelle Antwort einnimmt. Zusätzliche Varianz in der $3$-Bit-Bedingung wäre dann nicht auf Unterschiede zwischen Personen in der Verarbeitungsgeschwindigkeit sondern in der räumlichen Aufmerksamkeit zurückzuführen.

Die mit der dynamischen latenten Variable der \gls{ha} erfasste Verarbeitungsgeschwindigkeit zeigte einen mittleren negativen Zusammenhang mit dem \gls{gfaktor} ($\upbeta~=~-.26$). Die konstante latente Variable sagte den \gls{gfaktor} hingegen nicht signifikant vorher ($\upbeta~=~-.17$).
Wenn man die konstante und die dynamische latente Variable der \gls{ha} mit den auf manifester Ebene abgeleiteten Aufgabenparametern, dem y-Achsen\-ab\-schnitt und der Steigung, inhaltlich vergleicht, erkennt man, dass die konstante latente Variable dem y-Achsen\-ab\-schnitt und die dynamische latente Variable der Steigung entspricht. Unter dieser Betrachtungsweise lassen sich die Zusammenhänge der konstanten und dynamischen latenten Variablen mit dem \gls{gfaktor} gut mit bestehenden Resultaten zum Zusammenhang zwischen den Aufgabenparametern und psychometrischer Intelligenz erklären. Bei der Vorhersage von psychometrischer Intelligenz wird der Steigung bekanntermassen grössere Bedeutung zugeschrieben als dem y-Achsen\-ab\-schnitt \citep[z. B.][]{Jensen1987a, Jensen1998b, Roth1964}. In der vorliegenden Arbeit liess sich dieses Muster auf latenter Ebene wiedererkennen.
Bekräftigt wird diese Interpretation der höheren Bedeutsamkeit der Verarbeitungsgeschwindigkeit durch die Skalierung der latenten Varianzen der \gls{ha}. Diese hat ergeben, dass die dynamische latente Variable mehr von der den Bedingungen gemeinsamen Varianz band ($61\,\%$) als die konstante Variable ($39\,\%$). Die mit der dynamischen latenten Variable erfasste Verarbeitungsgeschwindigkeit war folglich stärker für Unterschiede zwischen Personen in der Reaktionszeit verantwortlich als die Prozesse der konstanten latenten Variable.





Die mit der dynamischen latenten Variable der \gls{ssauf} erfasste \gls{ss} zeigte keinen statistisch bedeutsamen Zusammenhang mit dem \gls{gfaktor} ($\upbeta~=~-.08$). Dieser Befund bestätigte alle vorangegangen Analysen zum Zusammenhang zwischen \gls{ss} und psychometrischer Intelligenz: Der \gls{si} ($r~=~.00$), die exponentielle Steigung ($r~=~.00$) und die dynamische latente Variable im Fixed-Links-Strukturgleichungsmodell zwischen der \gls{ssauf} und dem \gls{gfaktor} ($\upbeta~=~-.08$) hingen nicht signifikant mit psychometrischer Intelligenz zusammen.
Die konstante latente Variable der \gls{ssauf} zeigte inferenzstatistisch betrachtet keinen bedeutsamen Zusammenhang mit dem \gls{gfaktor} ($\upbeta~=~-.21$). Bei rein deskriptiver Betrachtung zeigte die konstante latente Variable jedoch einen stärkeren Zusammenhang mit dem \gls{gfaktor} als die dynamische latente Variable. Diese Beobachtung lässt sich analog zur \gls{ha} gut mit dem Ergebnis zu den im \gls{flm} skalierten Varianzen vereinen. Dabei hat sich ergeben, dass die konstante latente Variable deutlich mehr Varianz band ($72\,\%$) als die dynamische latente Variable ($28\,\%$), also für die Erklärung der Unterschiede zwischen Personen in den Erkennungsschwellen wichtiger war. Im Zusammenhang mit dem \gls{gfaktor} hat sich rein deskriptiv betrachtet ein vergleichbares Muster angedeutet.


%Die konstante latente Variable scheint für die Erklärung des \gls{gfaktor}s wichtiger zu sein als die dynamische latente Variable.






\section{Limitationen}

Bevor die bis hierhin diskutierten Ergebnisse ganzheitlich betrachtet werden können, müssen zwei wichtige Limitationen der vorliegenden Arbeit diskutiert werden. Zum einen geht es um die Interpretation der in den latenten Variablen gebundenen Prozesse und zum anderen um die technische Darbietung der \gls{ssauf}.


\subsection{Interpretation der latenten Variablen}

Latente Variablen erfassen Varianz von Prozessen, die nicht direkt beobachtbar sind. Um sicher zu stellen, dass sich hinter einer Varianz tatsächlich die vermuteten Prozesse verbergen, müssen die Annahmen geprüft werden. Das wurde in der vorliegenden Arbeit nicht gemacht. Die Interpretationen der latenten Variablen der Hick- und der \gls{ssauf} sind deshalb lediglich als mutmassliche Inhalte zu verstehen. Ob beispielsweise die konstante latente Variable der \gls{ssauf} tatsächlich Prozesse abgebildet hat, welche die (von den Mustergrössen unabhängige) grundlegende Geschwindigkeit bestimmen, mit der Information verarbeitet wird, kann mit der vorliegenden Arbeit nicht überprüft werden. Um diese Frage zu beantworten und sicher zu stellen, dass keine Fehlinterpretationen vorliegen, muss sich eine zukünftige Arbeit um die Validierung der mutmasslichen Inhalte kümmern.

Weiter besteht bei der Auswahl eines \gls{flm}s anhand des Kriteriums der besten Modellpassung das Problem, dass der ermittelte Ladungsverlauf stichprobenabhängig ist. 
Andere Untersuchungen zur \gls{ha} haben beispielsweise ebenfalls einen monoton steigenden Ladungsverlauf für die dynamische latente Variable ermittelt, der exakte Verlauf folgte aber keiner logistischen Funktion \citep{Borter2013, Pahud2017}. Bei der Interpretation des Verlaufs eines Prozesses darf deshalb nicht vergessen gehen, dass in einer neuen Stichprobe der Verlauf anders aussehen könnte. Sobald genügend Untersuchungen vorliegen, welche dieselbe Aufgabe mit einem \gls{flm} beschrieben haben, könnten die ermittelten Ladungsverläufe verglichen und bewertet werden. Damit würde man sich dem wahren Ladungsverlauf im Sinne einer Metaanalyse nähern.





\subsection{Darbietung der Spatial-Suppression-Aufgabe}

%\citep[Spatial-Summation;][]{Kapadia1999, Levitt1997, Pack2005}

Nach Abschluss der Datenerhebung hat sich im Austausch mit D. Tadin (persönl. Mitteilung, 13.09.2016) herausgestellt, dass der  Programmcode für die Darbietung der \gls{ssauf} nicht optimal auf den in der vorliegende Arbeit verwendeten Computermonitor abgestimmt war. Daraus folgten zwei Konsequenzen: Zum einen war der Kontrast, mit dem die Streifenmuster präsentiert wurden, geringer als angenommen und zum anderen änderte sich die Ortsfrequenz der präsentierten Streifenmuster.

Das Ausmass an \gls{ss} ist direkt abhängig vom Kontrast der Streifenmuster \citep{Tadin2003}. Bei steigendem Kontrast nimmt die mit zunehmender Mustergrösse relative Wahrnehmungsverschlechterung zu, und bei sinkendem Kontrast nimmt die mit zunehmender Mustergrösse relative Wahrnehmungsverschlechterung ab \citep{Tadin2003}. Nach Abschluss der Datenerhebung war es nicht möglich, das durch den nicht optimal abgestimmten Programmcode verursachte Ausmass der Kontrastreduzierung zu bestimmen (D. Tadin, persönl. Mitteilung, 13.09.2016). Sicher ist aber, dass der in der vorliegenden Arbeit verwendet Kontrast nicht wie vor Beginn der Datenerhebung berechnet bei $99\,\%$ lag. Falls der nicht optimal abgestimmte Programmcode dazu geführt haben sollte, dass der tatsächliche Kontrast bei der Darbietung der Streifenmuster unter den von \citet{Melnick2013} verwendeten $42\,\%$ lag, könnte dies eine Erklärung dafür sein, dass der Mittelwert des \gls{si} in der vorliegenden Arbeit im Vergleich zu \citeauthor{Melnick2013} tiefer zu liegen kam.

Um wie viel sich die vorgesehene Ortsfrequenz der Streifenmuster ($1^{\circ}$~Sehwinkel pro Periode) durch den nicht optimal abgestimmten Programmcode bei der Darbietung der Streifenmuster veränderte, ist ebenfalls nicht klar (D. Tadin, persönl. Mitteilung, 13.09.2016). Im Gegensatz zum Kontrast des Streifenmusters, bei welchem gut untersucht wurde, was für einen Effekt er auf die Wahrnehmungsleistung hat \citep[][]{Tadin2003, Kapadia1999, Levitt1997, Pack2005}, liegen zum Effekt der Ortsfrequenz des Streifenmusters auf die Erkennungsschwelle keine Untersuchungen vor. Es ist deshalb schwierig zu beurteilen, inwiefern die Schlussfolgerungen der vorliegenden Arbeit durch die veränderte Ortsfrequenz der Streifenmuster gefährdet sind.

Wie erwähnt ist bei beiden Einschränkungen (dem reduzierten Kontrast und der veränderten Ortsfrequenz) nicht klar, welchen Einfluss sie auf die Ergebnisse hatten. Trotz dieser Unsicherheit deuten einige Punkte darauf hin, dass die Resultate der \gls{ssauf} interpretierbar sind: Die Wahrnehmungsleistung der \glspl{vp} hat sich mit zunehmender Mustergrösse wie bei \citet{Melnick2013} verschlechtert, die Erkennungsschwellen zeichneten sich durch sehr hohe Split\-half-Reliabilitäten aus und die Erkennungsschwellen liessen sich wie bei \citeauthor{Melnick2013} sehr gut mit einem exponentiellen Modell beschreiben. 
Für die folgende generelle Diskussion wird deshalb angenommen, dass der reduzierte Kontrast und die veränderte Ortsfrequenz der Streifenmuster keinen so starken Einfluss auf die Ergebnisse ausübten, dass sie eine Interpretation verbietet.

%Auch wenn nicht mit Sicherheit davon ausgegangen werden kann, dass der reduzierte Kontrast und die veränderte Ortsfrequenz der Streifenmuster keinen Einfluss auf die hier berichteten Ergebnisse hatten, wird das in der folgenden generelle Diskussion angenommen. 

%\begin{itemize}
%	\item Programmcode (D. Tadin, persönl. Mitteilung, 13.09.2016)
%	\item $360$ Hz Code auf $144$ Hz Monitor? \citet{Lappin2009, Tadin2006} haben Schwellen von $20$ und $30$~ms!für kleine muster BEIDE 120 Hz monitor!
%	\item Vs. Splithalf-Reliabilitäten
%	\item Grundsätzlich scheint Aufgabe funktioniert zu haben (ANOVA, Rel, etc.)
%\end{itemize}


\section{Generelle Diskussion}

Bei einer ganzheitlichen Betrachtung der Ergebnisse zum Zusammenhang zwischen der \gls{ssauf} und psychometrischer Intelligenz kann festgestellt werden, dass sich die Aufgabe als Prädiktor von psychometrischer Intelligenz nicht bewährt hat \citep[vgl.][]{Melnick2013}. Die manifesten Zusammenhänge zwischen der \gls{ssauf} und psychometrischer Intelligenz konnten in der vorliegenden Arbeit im Vergleich mit den Resultaten von \citet{Melnick2013} überhaupt nicht beobachtet werden oder fielen bedeutsam schwächer aus. 
Die Analyse der \gls{ssauf} auf latenter Ebene hat gezeigt, dass sich die für das Lösen der Aufgabe benötigten Prozesse in zwei unabhängige Faktoren trennen lassen. Der erste Faktor bildete Prozesse ab, welche die generelle Geschwindigkeit bestimmen, mit der die Bewegungsrichtung der Muster erkannt wurde. Der zweite Faktor bildete \gls{ss} ab. Im Zusammenhang mit psychometrischer Intelligenz wurde festgestellt, dass nicht \gls{ss} für den schwachen bis mittleren negativen Zusammenhang zwischen der Aufgabe und dem \gls{gfaktor} verantwortlich ist, sondern dass es die Prozesse sind, welche die generelle Geschwindigkeit bestimmt haben, mit der die Bewegungsrichtung der Muster erkannt wurde.

Mit der Hinzunahme eines \glspl{msm}s, der \gls{ha}, wurde geprüft, ob die \gls{ssauf} einen Aspekt der menschlichen Informationsverarbeitung abbildet, der neuartig ist nicht bereits von der \gls{ha} erfasst wird. Die Analysen haben ergeben, dass die \gls{ssauf} auf manifester Ebene keine zusätzliche Varianz in psychometrischer Intelligenz zu erklären vermochte. Dies deutete darauf hin, dass die \gls{ssauf} ausschliesslich \gls{ms} abbildet, welcher ebenso gut mit der \gls{ha} erfasst werden kann. Auf latenter Ebene hingegen zeigte sich in einem klassischen Strukturgleichungsmodell zwischen der \mbox{Spatial-Suppression-,} der \gls{ha} und dem \gls{gfaktor}, dass die \gls{ssauf} einen eigenständigen Varianzanteil im \gls{gfaktor} erklärt. Die Analyse der gleichen Zusammenhänge mit einem Fixed-Links-Strukturgleichungsmodell deutete darauf hin, dass es auch hier nicht das Ausmass an \gls{ss} ist, dass mit dem \gls{gfaktor} zusammenhängt, sondern dass es die generelle Geschwindigkeit ist, mit der die Muster verarbeitet wurden. Diese generelle Geschwindigkeit von Prozessen in der \gls{ssauf} stand dabei in schwachem bis mittleren positiven Zusammenhang mit Prozessen, welche die grundlegende Geschwindigkeit bei der Bearbeitung der \gls{ha} bestimmten. Interessant war zu beobachten, dass diese grundlegende Geschwindigkeit von Prozessen in der \gls{ssauf} nicht mit der Verarbeitungsgeschwindigkeit in der \gls{ha} zusammenhing. 
Diese Befunde deuten darauf hin, dass für die Bearbeitung der Spatial-Suppression- und der \gls{ha} zwar teilweise die gleichen grundlegenden, basalen Prozesse benötigt werden, es aber nicht die Verarbeitungsgeschwindigkeit im Sinne des \gls{msa}es \citep[z. B.][]{Deary2000a, Jensen1982a, Jensen1982b, Jensen2006, Vernon1983} ist.

Aus messtechnischer Hinsicht kann darauf hingewiesen werden, dass \glspl{flm} die empirischen Zusammenhänge adäquater und sparsamer beschrieben als klassische Faktorenanalysen. Sie haben sich erneut als hilfreich erwiesen, die an experimentell manipulierten Aufgabe beteiligten Prozesse voneinander zu trennen und damit ein differenzierteres Bild der Zusammenhänge mit psychometrischer Intelligenz zu ermöglichen \citep[][]{Ren2013, Schweizer2007, Stankov2007, Wang2015}

Der \gls{ssans} \citep{Melnick2013} zu Erklärung individueller Intelligenzunterschiede



\gls{msa} \citep[z. B.][]{Deary2000a, Jensen1982a, Jensen1982b, Jensen2006, Vernon1983} bietet.



\vspace{3cm}
%
%Das Ziel der vorliegenden Arbeit war es zu prüfen, ob sich die \gls{ssauf} als Prädiktor psychometrischer Intelligenz bewährt und inwiefern der \gls{ssans} \citep{Melnick2013} zu Erklärung individueller Intelligenzunterschiede neuartige Erklärungsmöglichkeiten lifert, welche nicht bereits der \gls{msa} \citep[z. B.][]{Deary2000a, Jensen1982a, Jensen1982b, Jensen2006, Vernon1983} bietet.
%
%Der Erkenntnisgewinn der vorliegenden lässt sich in vier Punkten 
%
%
%
%
%
%Allgemein:
%1. SpSup kein zusammenhang mit intelligenz
%2. wenn dann genereller speed - nicht Mental-Speed! dynamische korreliert nicht mit konstanter!
%3. mental speed ähnlich?
%4. neue untersuchung muss klarheit schaffen! zukünftige Untersuchungen
%
%
%
%
%
%
%
%
%
%1. Fragestellung:
%- SI -> SS nicht mit I
%- nur kleine mustergrösse mit I
%- alle anderen korrelationen = 0
%
%2. Fragestellung:
%- SS und I nicht
%- generelle schnellerer Prozesse von intelligenten Perosnen (Asymptote)
%- Steigung besser as SI
%
%3. Fragestellung:
%- SS -.23 mit g -- generelle Geschwindigkeit für Mustererkennung -> entspricht der konstanten von FS4!?
%- Whs nicht spatial-suppression (faktorladungen ähnlich, zusammenhang mit g negativ)!
%
%4. Fragestellung:
%- kon: grundlegende Geschwindigkeit -.25, dyn: SS n.s.
%- varianzaufteilung?
%- im Zusammenhang mit g ist kon wichtiger weil sign zusammenhang und varianz grösser - konsistent mit fragestellung 3 und annahme, dass darin generelle geschwindigkeit abgebildet wrude und nicht SS!
%
%5. Fragestellung:
%- klassisches SGM: erstmals hinweis dass Aufgabe prädiktor von g sein
%- manifest: keine zusätzliche erklärung (bed + para)
%- latent: nur Hdyn prädiktor von g
%- latent: kon's korrelieren!
%- latent: 16 percent var
%- latent: latente Analyse erklärt mehr varianz auf manifeste (11 und 12 bei multipler regression)
%
%Abschliessende Zusammenfassung mit positiver Aussicht
%
%Aus messtechnischer Hinsicht ist darauf hinzuweisen, dass das \gls{flm} die \gls{ssauf} sparsamer und besser abbildete als die klassische Faktorenanalyse. Auch im Zusammenhang mit dem \gls{gfaktor} bildete das Fixed-Links-Struk\-tur\-glei\-chungs\-mo\-dell die Beziehungen zwischen den Variablen deutlich besser ab als das klassische Strukturgleichungsmodell. Das \gls{flm} hat mit der statistischen Trennung der an der Aufgabe beteiligten Prozesse also dazu beigetragen, dass die der Aufgabe zugrunde liegende Struktur aufgedeckt wurde und sich der Zusammenhang der Aufgabe mit dem \gls{gfaktor} differenzierter Betrachten liess als in einem klassischen Strukturgleichungsmodell.
%
%Aus messtechnischer Hinsicht kann erneut darauf hingewiesen werden, dass das \gls{flm} der \gls{ha} die empirischen Zusammenhänge besser und sparsamer beschrieb als die klassische Faktorenanalyse. Ebenso hat sich im Fixed-Links-Struk\-tur\-glei\-chungs\-mo\-dell zwischen der \gls{ha}, der \gls{ssauf} und dem \gls{gfaktor} einen deutlich besseren Modell-Fit ergeben als mit einem klassischen Strukturgleichungsmodell. \glspl{flm} haben somit dazu beigetragen, dass die an den Aufgaben beteiligten Prozessen auf statistischer Ebene voneinander getrennt werden konnten und sich ein detaillierteres Bild der Zusammenhänge mit psychometrischer Intelligenz ergab.
%
%
%
%
%
%
%\begin{itemize}
%	\item Multiple Regressionen deuten darauf hin, dass die \gls{ssauf} \gls{ms} erfasst
%	\item Diese Erkenntnis ist neu und deutet darauf hin, dass die Geschwindigkeit, mit der die sich bewegenden Muster wahrgenommen werden auch einen Einfluss darauf hat, wie gut (im Rahmen eines Intelligenztests) komplexe kognitive Leistung erbracht wird. 
%	Gestützt wird diese Interpretation mit den beobachteten bivariaten Produkt-Moment-Korrelationen zwischen den Bedingungen der \gls{ssauf} und psychometrischer Intelligenz. Die Bedingungen der \gls{ssauf} korrelierten mit Ausnahme des Zusammenhangs zwischen der $7.2^{\circ}$-Bedingung und dem \gls{zwert} des \gls{bist}s alle schwach negativ mit psychometrischer Intelligenz ($r=-.16$ bis $-.19$; siehe \autoref{tab:product_moment_correlations_manifest}). Diese Zusammenhänge deuten darauf hin, dass 
%	
%	die Geschwindigkeit, mit der die Muster erkannt wurden mit 
%	
%	\item SS-Bedingungen konsistent negativ mit I!
%	\item konsistent über alle modelle, zusammenhang da latent
%
%
%
%	\item 
%
%	\item Fixed-links modellierungen lohnen sich (wie auch bei AGK oder Speed prozessen -> LIT)
%\end{itemize}
%
%
%p-Wert problematisch:\\
%\citet{Gelman2006}\\
%\citet{Wasserstein2016}\\
%\citet{Nuzzo2014}
%\citet{Hayduk2014} Shame on disrespecting evividenc p 6 of 10
%
%
%fixed-links als Lösung für exponentielle Regression, da hats einfach ein paar Leute mit hohem RMSE gehabt. im sem drückt lässt sich der missfit quantifizieren (modelltest)
%












% =================================================================
% G L O S S A R Y   &   A C R O N Y M S
% =================================================================
%\printglossaries	% put this where you want your list of entries to appear 
% Important:
% 1. compile document with PdfLaTeX
% 2. run 'makeglossaries diss' in terminal
% 3. compile document with pdfLateX
% 4. -> glossaries should appear in pdf


% =================================================================
% R E F E R E N C E S 
% =================================================================
\cleardoublepage								% for hyperref to jump to the correct page, see
\phantomsection									% http://tex.stackexchange.com/questions/44088/when-do-i-need-to-invoke-phantomsection
\renewcommand\bibname{Literatur}				% rename bibliography
\addcontentsline{toc}{chapter}{Literatur}		% for a toc entry
\bibliography{bibliography.bib}					% provide .bib file


% =================================================================
% L I S T   O F   F I G U R E S
% =================================================================
%\cleardoublepage								% for hyperref to jump to the correct page, see
%\phantomsection									% http://tex.stackexchange.com/questions/44088/when-do-i-need-to-invoke-phantomsection
%\renewcommand\listfigurename{Abbildungen}		% define name of lof
%\addcontentsline{toc}{chapter}{Abbildungen}		% add lof to toc
%\listoffigures									% insert lof

% =================================================================
% L I S T   O F   T A B L E S
% =================================================================
%\cleardoublepage								% for hyperref to jump to the correct page, see
%\phantomsection									% http://tex.stackexchange.com/questions/44088/when-do-i-need-to-invoke-phantomsection
%\renewcommand\listtablename{Tabellen}			% define name of lot
%\addcontentsline{toc}{chapter}{Tabellen}		% add lot to toc
%\listoftables 									% insert lot

% =================================================================
% A P P E N D I X   A
% =================================================================
\appendix
% not sure if this code works -----------
\setcounter{figure}{0}
\renewcommand\thefigure{\Alph{appndx}\@arabic\c@figure}
%\addtocontents{toc}{\protect\setcounter{tocdepth}{0}}
%\addtocontents{lof}{\protect\setcounter{tocdepth}{0}}

\chapter[Anhang - Datenaufbereitung]{Anhang \label{cha:Anhang_A}}

% works --------------------------
\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}

Dieser Anhang beschreibt die Vorgehensweise bei der Datenaufbereitung, welche zum Ausschluss von \glspl{vp} geführt hat (vgl. \autoref{sec:Stichprobe}). Am Ende des Anhangs fasst \autoref{tab:Datenbereinigung} die Datenbereinigung zusammen.

\subsection*{Alter}
Trotz sorgfältiger Auswahl der \glspl{vp} hat sich nachträglich bei der Altersberechnung herausgestellt, dass drei \glspl{vp} zum Testzeitpunkt noch nicht $18$~Jahre alt waren. Sie wurden vor der Analyse entfernt.

\subsection*{Spatial-Suppression-Aufgabe}
Zu Beginn der Datenerhebung wurde die \gls{ssauf} mit einem Kontrast von $74\,\%$ dargeboten. Nach Inspektion der Daten der sieben ersten getesteten \glspl{vp} wurde in Absprache mit Duje Tadin entschieden, den Kontrast der Aufgabe auf $99\,\%$ zu erhöhen. Mit dieser Erhöhung des Kontrasts wurde sichergestellt, dass die über die vier Mustergrössen hinweg erwartete Verschlechterung der Wahrnehmungsleistung möglichst gross ausfällt \citep[für den Zusammenhang zwischen Kontrast und Wahrnehmungsleistung siehe][]{Tadin2003}. Den restlichen \glspl{vp} wurde die Aufgabe mit einem Kontrast von $99\,\%$ dargeboten und die Daten der ersten sieben \glspl{vp} wurden von der Analyse ausgeschlossen.

Der Code, welcher die Darbietungszeiten generierte, hatte eine programmierte Darbietungszeitlimite von $1000$~ms. Immer wenn der adaptive Alogrithmus des QUEST-Verfahrens \citep{Watson1983} eine Darbietungszeit von $> 1000$~ms ermittelte, wurde den \glspl{vp} deshalb der Stimulus mit einer Darbietungszeit von exakt $1000$~ms präsentiert. 
Die Daten von $12$~\glspl{vp} mussten vor der Analyse entfernt werden, weil sie bei den sechs Schätzungen der $82\,\%$-Er\-ken\-nungs\-schwel\-le innerhalb einer Mustergrösse mehr als ein Mal eine $82\,\%$-Er\-ken\-nungs\-schwel\-le von $> 1000$~ms erzielt hatten. Dasselbe Ausschlussverfahren verwendeten \citet{Melnick2013}.

Die Daten von zwei \glspl{vp} wurden von der Analyse ausgeschlossen, weil sie verglichen mit den restlichen \glspl{vp} in der $1.8^{\circ}$-Be\-ding\-ung eine gemittelte $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le hatten, die über das dreifache der \gls{sd} der $82\,\%$-$\log_{10}$-Er\-ken\-nungs\-schwel\-le der Gesamtstichprobe betrug. Diese drei \glspl{vp} wurden nicht zur Grundpopulation gezählt und vor der Analyse entfernt.

%\section{\gls{ha}}
%Bei der \gls{ha} mussten keine \glspl{vp} ausgeschlossen werden.

\subsection*{BIS-Test}
Bei den Subtests \gls{bd}, \gls{kw}, \gls{oe}, \gls{RZ}, \gls{tg}, \gls{uw} und \gls{xg} ist der Rohwert Null im Manual des \gls{bist}s \citep{Jaeger1997} keinem Punktwert zugeordnet. Vier \glspl{vp} erzielten beim Subtest \gls{xg} einen Rohwert von Null, was den Subtest nicht auswertbar machte. Die Daten dieser vier \glspl{vp} wurden vor der Analyse aufgrund dieses nicht auswertbaren Subtests entfernt. Eine \gls{vp} wurde von der Analyse ausgeschlossen, weil sie bei den \gls{b}-Subtests deutlich schlechter Abschnitt als der Rest der Stichprobe und damit einen Einfluss auf die berechneten Zusammenhänge gehabt hätte.

\begin{table}[htbp]
	\centering
	\captionsetup{labelsep = none}
	\caption[Übersicht über die Datenbereinigung]{\newline  \textit{Übersicht über die Datenbereinigung} \vspace{.2cm}}
	\label{tab:Datenbereinigung}
	\begin{adjustbox}{width=1\textwidth}
		\begin{threeparttable}
			\begin{tabular}{
					l
					l
					S[table-format = 3.0]
					S[table-format = 2.0]
					S[table-format = 2.0]
					c
					S[table-format = 3.0]
					S[table-format = 2.0]
					S[table-format = 2.0]
					}
				\hline
					&	&	\multicolumn{3}{c}{absolut}	&	&	\multicolumn{3}{c}{relativ (\%)} \\
				\cline{3-5}
				\cline{7-9}
				Beschrieb & \multicolumn{1}{c}{Korrektur für} &{\textit{N}} & {D} & {D kum.}	&	&	{\textit{N}} & {D} & {D kum.}\\
				\hline
				
				Getestet	&	-								&	206	&		&		&&	100	&		&		\\
							&	Alter							&	203	&	-3	&	-3	&&	99	&	-2	&	-2	\\
							&	Spatial-Suppression-Aufgabe		&	182	&	-21	&	-24	&&	88	&	-10	&	-12	\\
							&	BIS-Test						&	177	&	-5	&	-29	&&	86	&	-2	&	-14	\\
				Analysiert	&	-								&	177	&		&		&&	86	&		&		\\
				\hline
			\end{tabular}

			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkungen.} \textit{N} = Stichprobengrösse; D = Differenz; D kum. = kumulierte Differenz.
			\end{tablenotes}
		\end{threeparttable}
	\end{adjustbox}
\end{table}


% =================================================================
% A P P E N D I X   B
% =================================================================
\chapter[Anhang - Nonparametrische Analysen]{Anhang \label{cha:Anhang_B}}
% works --------------------------
\setcounter{table}{0}
\renewcommand{\thetable}{B\arabic{table}}

Dieser Anhang beinhaltet Ergebnisse der Deskriptiv- und Inferenzstatistik, welche sich bei der Anwendung nonparametrischer Analyseverfahren ergeben haben. Die Ergebnisse dieser nonparametrischer Analyseverfahren wichen nicht bedeutend von den mit parametrischen Verfahren ermittelten Ergebnissen ab (vgl. \autoref{sec:Deskriptive_Statistik}).

\subsection*{Spatial-Suppression-Aufgabe}

Um zu prüfen, ob die experimentelle Manipulation (die Musterrösse) einen Einfluss auf die abhängige Variable (die $82\,\%$-Er\-ken\-nungs\-schwel\-le) ausübte, wurde ein Friedman-Test durchgeführt. Der Globaltest hat gezeigt, dass die Unterschiede zwischen den Bedingungen signifikant waren, $\upchi^2(3)=345.26$, $p<.001$. 
Um zu erfahren, welche Bedingungen sich voneinander unterschieden, wurden Post-hoc-Tests \citep{Galili2010, Hollander2014} gerechnet. Diese haben ergeben, dass sich von den (durch die vier Bedingungen bestimmten) sechs Einzelvergleichen nur die $1.8^{\circ}$- und $3.6^{\circ}$-Bedingung nicht signifikant voneinander unterschieden ($p=.09$). Die restlichen fünf Einzelvergleiche waren mit $p<.001$ alle statistisch signifikant.

\subsection*{Hick-Aufgabe}

Um zu testen, ob die experimentelle Manipulation (die Anzahl Antwortalternativen) einen Einfluss auf die abhängige Variable (die Reaktionszeit) ausübte, wurde ein Friedman-Test durchgeführt. Der Globaltest belegte, dass die Unterschiede zwischen den Bedingungen signifikant waren, $\upchi^2(3)=516.12$, $p<.001$. Welche Bedingungen sich voneinander unterschieden, wurde mit Post-hoc-Tests \citep{Galili2010, Hollander2014} geprüft. Diese haben gezeigt, dass sich alle Bedingungen signifikant voneinander unterschieden (alle $p\textnormal{s}<.001$). 

\subsection*{BIS-Test}

Die Zusammenhänge der Subtests wurden mit Spearmans Rangkorrelationen bestimmt und sind in \autoref{tab:bis_subtest_description_subtest_correlations_parametric_and_nonparametric} unterhalb der Diagonale abgetragen. Oberhalb der Diagonale sind die Differenzen zwischen den Produkt-Moment-Korrelationen und Spearmans Rangkorrelationen abgetragen.

\subsection*{Zusammenhangsmasse}

Die Zusammenhänge der Subtests wurden mit Spearmans Rangkorrelationen bestimmt und sind in \autoref{tab:correlations_between_manifest_parametric_and_nonparametric} unterhalb der Diagonale abgetragen. Oberhalb der Diagonale sind die Differenzen zwischen den Produkt-Moment-Korrelationen und Spearmans Rangkorrelationen abgetragen.

\begin{sidewaystable}[htbp]
	\captionsetup{labelsep = none}
	\caption[Spearmans Rangkorrelationen zwischen den Subtests des \gls{bist}s]{\newline  \textit{Spearmans Rangkorrelationen (unterhalb der Diagonale) zwischen den Subtests des \gls{bist}s. Oberhalb der Diagonale sind die Differenzen zwischen der Produkt-Moment-Korrelation und Spearmans Rangkorrelation abgetragen} \vspace{.2cm}}
	\label{tab:bis_subtest_description_subtest_correlations_parametric_and_nonparametric}
	\sisetup{table-space-text-post = $^{*ab}$  }
	\begin{adjustbox}{width=1\textwidth,totalheight=1\textheight,keepaspectratio}
		\begin{threeparttable}
			\begin{tabular}{
					l
					l
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					>{\centering\arraybackslash}p{1.2cm}
				}
				\hline
				&	\multicolumn{1}{c}{Subtest}&	{1}	&	{2}	&	{3}	&	{4}	&	{5}	&	{6}	&	{7}	&	{8}	&	{9}	&	{10}&	{11}&	{12}&	{13}&	{14}&	{15}&	{16}&	{17}&	{18}	\\
				\hline
				
1	&	OG	&					&	.02				&	.05			&.00	&.04	&-.05	&.01	&-.12	&-.02	&.04	&.03	&-.01	&-.02	&.00	&.01	&-.02	&.04	&-.03	\\
2	&	ZN	&	.25{$^{***}$}	&					&	.00			&.01	&.00	&.02	&.00	&.00	&.01	&.04	&.02	&-.03	&.01	&.01	&.00	&.03	&.06	&.04	\\
3	&	AN	&	.26{$^{***}$}	&	.42{$^{***}$}	&				&-.03	&.02	&-.02	&.03	&-.12	&-.01	&.01	&.01	&-.03	&-.01	&.05	&.00	&.01	&.05	&.02	\\
4	&	XG	&	.21{$^{**}$}	&	.55{$^{***}$}	&	.35{$^{***}$}	&	&.01	&.01	&-.04	&-.08	&.00	&.01	&.02	&-.05	&.00	&.00	&-.03	&.01	&.01	&.03	\\
5	&	WA	&	.31{$^{***}$}	&	.41{$^{***}$}	&	.47{$^{***}$}	&	.34{$^{***}$}	&&-.01	&.03	&-.03	&.01	&.01	&.01	&-.02	&-.01	&.06	&.01	&.01	&.05&.00\\
6	&	ZP	&	.27{$^{***}$}	&	.15{$^a$}		&	.15{$^{*}$}	&	.30{$^{***}$}	&	.17{$^{*}$}		&	&	-.03&-.04	&.00	&.02	&-.01	&-.03	&-.02	&.01	&.00	&.03	&-.02	&.02	\\
7	&	TM	&	.29{$^{***}$}	&	.26{$^{***}$}	&	.41{$^{***}$}	&	.36{$^{***}$}	&	.48{$^{***}$}	&	.24{$^{**}$}	&	&-.07	&.00	&.02	&.02	&-.04	&-.03	&.05	&.02	&.01	&.01	&.02	\\
8	&	BD	&	.19{$^{*}$}		&	.08				&	.17{$^{*}$}		&	.19{$^{*}$}		&	.02				&	.08				&	.10	&	&-.05	&.02	&-.05	&-.07	&-.05	&-.05	&-.04	&-.02	&-.12	&-.06	\\
9	&	SC	&	.16{$^{*}$}		&	.51{$^{***}$}	&	.35{$^{***}$}	&	.48{$^{***}$}	&	.22{$^{**}$}	&	.17{$^{*}$}		&	.32{$^{***}$}	&	.25{$^{***}$}	&	&.01	&.01	&.01&.00&-.03	&.02&.01	&.01&.01\\
10	&	ST	&	.34{$^{***}$}	&	.15	{$^{*}$}	&	.23{$^{**}$}	&	.30{$^{***}$}	&	.31{$^{***}$}	&	.22{$^{**}$}	&	.37{$^{***}$}	&	-.03			&	.22{$^{**}$}	&		&.04&.02&.00&-.05&.03&.02&.04&.03\\
11	&	CH	&	.33{$^{***}$}	&	.49{$^{***}$}	&	.51{$^{***}$}	&	.29{$^{***}$}	&	.50{$^{***}$}	&	.14				&	.30				&	.12				&	.31{$^{***}$}	&	.13	&	&-.01&.01&.01&.00&.02&.07&.02	\\
12	&	TG	&	.33{$^{***}$}	&	.36{$^{***}$}	&	.30{$^{***}$}	&	.48{$^{***}$}	&	.45{$^{***}$}	&	.19{$^{*}$}		&	.47{$^{***}$}	&	.18{$^{*}$}		&	.26{$^{***}$}&	.36{$^{***}$}	&	.23{$^{**}$}	&	&-.08&.00&-.05&.02&.00&.00	\\
13	&	RZ	&	.32{$^{***}$}	&	.52{$^{***}$}	&	.42{$^{***}$}	&	.55{$^{***}$}	&	.44{$^{***}$}	&	.29{$^{***}$}	&	.45{$^{***}$}	&	.13				&	.44{$^{***}$}&	.34{$^{***}$}	&	.37{$^{***}$}	&	.41{$^{***}$}&&-.03&.01&.01&.02&.01	\\
14	&	WM	&	.41{$^{***}$}	&	.10				&	.24{$^{**}$}	&	.18{$^{*}$}		&	.20{$^{**}$}	&	.26{$^{***}$}	&	.34{$^{***}$}	&	.13				&	.13			&	.45{$^{***}$}	&	.16{$^{*}$}		&	.18{$^{*}$}		&	.15{$^{*}$}	&&-.01&.01&-.02&-.03	\\
15	&	KW	&	.26{$^{***}$}	&	.24{$^{***}$}	&	.28{$^{***}$}	&	.39{$^{***}$}	&	.39{$^{***}$}	&	.24{$^{**}$}	&	.54{$^{***}$}	&	.19{$^{*}$}		&	.26{$^{***}$}&	.49{$^{***}$}	&	.21{$^{**}$}	&	.60{$^{***}$}	&	.35{$^{***}$}	&	.34{$^{***}$}	&&.03&.04&-.01	\\
16	&	ZZ	&	.31{$^{***}$}	&	.02				&	.03				&	.20{$^{**}$}	&	.00				&	.34{$^{***}$}	&	.09				&	.11				&	.04			&	.28{$^{***}$}	&	.05				&	.05				&	.08				&	.38{$^{***}$}	&	.10	&&.02&.01	\\
17	&	OE	&	.06				&	-.01			&	-.01			&	.07				&	-.05			&	.04				&	.12				&	.46{$^{***}$}	&	.15{$^{*}$}&	-.01			&	-.13			&	.15{$^{*}$}		&	.13					&	.03	&	.13		& -.05&&.02	\\
18	&	WE	&	.42{$^{***}$}	&	.27{$^{***}$}	&	.26{$^{***}$}	&	.19{$^{*}$}		&	.29{$^{***}$}	&	.25{$^{***}$}	&	.06				&	.04				&	.14			&	.21{$^{**}$}	&	.25{$^{**}$}	&	.20{$^{**}$}	&	.33{$^{***}$}	&.19{$^{*}$}&	.23{$^{**}$}&.18{$^{*}$}&-.12&\\
\hline			
			\end{tabular}
			
			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkung.} Siehe \autoref{tab:bis_subtest_description} für eine Beschreibung der Subtests.
				\item {$^a$}Der exakte Zusammenhang betrug $r_{s}=.147$, $p=.051$. Alle restlichen in der Tabelle mit $r_{s}=.15$ bezeichneten Korrelationskoeffizienten wiesen \textit{p}-Werte $<.05$ auf.
				\item {$^{*}$}$p<.05$. {$^{**}$}$p<.01$. {$^{***}$}$p<.001$ (zweiseitig).
			\end{tablenotes}
		\end{threeparttable}
	\end{adjustbox}
\end{sidewaystable}

\begin{sidewaystable}[htbp]
	\centering
	\captionsetup{labelsep = none}
	\caption[Spearmans Rangkorrelationen zwischen der \gls{ssauf}, dem \gls{si}, der \gls{ha}, dem \textit{z}-Wert und dem \gls{gfaktor} des \gls{bist}ss]{\newline  \textit{Spearmans Rangkorrelationen (unterhalb der Diagonale) zwischen den Bedingungen der \gls{ssauf}, dem \gls{si}, den Bedingungen der \gls{ha}, dem \textit{z}-Wert und dem \gls{gfaktor} des \gls{bist}s. Oberhalb der Diagonale sind die Differenzen zwischen der Produkt-Moment-Korrelation und Spearmans Rangkorrelation abgetragen} \vspace{.2cm}}
	\label{tab:correlations_between_manifest_parametric_and_nonparametric}
	\sisetup{table-space-text-post = $^{***}$}
%	\begin{adjustbox}{width=.85\textwidth, keepaspectratio}
		\begin{threeparttable}
			\begin{tabular}{
					l
					l
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					p{.001cm}
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					p{.001cm}
					S[table-format = 0.2, add-integer-zero=false]
					S[table-format = 0.2, add-integer-zero=false]
					>{\centering\arraybackslash}p{1.2cm}
				}
				\hline
				
				
				&	& 	\multicolumn{5}{c}{\gls{ssauf}}	&	&	\multicolumn{4}{c}{\gls{ha}}	&	&	\multicolumn{2}{c}{\gls{bist}}	\\
				
				\cline{3-7}
				\cline{9-12}
				\cline{14-15}
				
				&	\multicolumn{1}{c}{Mass}			&	{1}				&	{2}				&	{3}				&	 {4}	& {5}& 	& {6}	& {7}	& {8}	&{9}&&{10}&{11} \\
				\hline
1	&	$1.8^{\circ}$	&					&	.01				&	.00	&	-.01	&	.05	&&	.05	&	.06	&	.01	&	.07	&&	-.02	&-.01\\
2	&	$3.6^{\circ}$	&	.84{$^{***}$}	&					&	.01	&	-.04	&	.02	&&	.05	&	.05	&	-.03&	.04	&&	-.05	&-.02\\
3	&	$5.4^{\circ}$	&	.73{$^{***}$}	&	.86{$^{***}$}	&		&	-.01	&	.08	&&	.09	&	.10	&	.01	&	.10	&&	-.07	&-.06\\
4	&	$7.2^{\circ}$	&	.55{$^{***}$}	&	.76{$^{***}$}	&	.88{$^{***}$}	&&	.13	&&	.02	&	.07	&	.00	&	.08	&&	-.06	&-.06\\
5	&	SI 				&	-.33{$^{***}$}	&	.03				&	.26{$^{***}$}	&	.53{$^{***}$}&&&.00&.05&.02 &	.05 &&	-.04 	&-.03 \\
\rule{0pt}{4ex}%  EXTRA vertical height
6	&	0-bit			&	.12				&	.19{$^{**}$}	&	.16{$^{*}$}	&	.12		&.01&	&		&.04&.06&.12&&-.04&-.04\\
7	&	1-bit			&	.03				&	.06				&	.03			&	.00		&-.05&	&.72{$^{***}$}	&	&.01	&.03	&	&.05&.04		\\
8	&	2-bit			&	.11				&	.11				&	.07			&	.04		&-.08&	&.52{$^{***}$}	&	.71{$^{***}$}	&	&.02	&	&.03&.04\\
9	&	2.58-bit		&	.07				&	.05				&	.02			&	-.01	&-.09&	&.40{$^{***}$}	&	.63{$^{***}$}	&	.81{$^{***}$}	&	&	&.03&.03		\\
\rule{0pt}{4ex}%  EXTRA vertical height
10	&	\textit{z}-Wert	&	-.14			&	-.12			&	-.09		&	-.06	&.04&	&	-.15{$^{*}$}	&	-.32{$^{***}$}	&	-.31{$^{***}$}	&	-.31{$^{***}$}	&				&	&.00	\\
11	&	\gls{gfaktor}	&	-.18{$^{*}$}	&	-.18{$^{*}$}	&	-.14		&	-.11	&.03&	&	-.15{$^{*}$}	&	-.29{$^{***}$}	&	-.29{$^{***}$}	&	-.28{$^{***}$}	&				&	.97{$^{***}$} & 	\\
				\hline
				
			\end{tabular}

			\begin{tablenotes}[flushleft]
				\footnotesize				% font size
				\setlength\labelsep{0pt}	% no indent on second line
				\item \textit{Anmerkungen}. SI = \gls{si}. \gls{zwert} = Mittelwert aus allen 18 \textit{z}-standardisierten Subtests.
				\item {$^{*}$}$p<.05$. {$^{**}$}$p<.01$. {$^{***}$}$p<.001$ (zweiseitig).
			\end{tablenotes}
		\end{threeparttable}
%	\end{adjustbox}
\end{sidewaystable}


% =================================================================
% A P P E N D I X   C
% =================================================================
\chapter[Anhang - Online-Material]{Anhang}

Der \LaTeX-Code für die Reproduktion dieses Dokuments ist verfügbar unter \url{https://github.com/pipomas/PhD_thesis}.
Der R-Code für die Reproduktion der berichteten Ergebnisse ist verfügbar unter \url{https://github.com/pipomas/PhD_data}.


% =================================================================
% S T A T E M E N T
% =================================================================
\cleardoublepage

\includepdf[pages={1}]{png/confirmation_blank}

\end{document}


